> dat <- na.omit(read.csv("mice_pheno.csv"))
> head(dat)
  Sex Diet Bodyweight
1   F   hf      31.94
2   F   hf      32.48
3   F   hf      22.82
4   F   hf      19.92
5   F   hf      32.22
6   F   hf      27.50

 ##If a list of numbers has a distribution that is well approximated by the normal distribution, what proportion of these numbers are within one standard deviation away from the list’s average? 


 ## 68% 


 ** What proportion of these numbers are within two standard deviations away from the list’s average? ** 


 ## 95% 


 **What proportion of these numbers are within three standard deviations away from the list’s average? ** 


 ## 99.7% 


 ** Define y to be the weights of males on the control diet. What proportion of the mice are within one standard deviation away from the average weight (remember to use popsd for the population sd) ** 

> y <- filter(dat, Sex == "M" & Diet == "chow") %>% select(Bodyweight) %>% 
+ unlist()
> head(y)
Bodyweight1 Bodyweight2 Bodyweight3 Bodyweight4 Bodyweight5 Bodyweight6 
      45.23       23.73       34.03       24.98       28.56       29.32 

 ## use popsd() to calculate 1sd if we have the entire population (mice_pheno.csv is full dataset), otherwise use sd() if we have sample of a larger population 

> library(rafalib)
> popsd(y)
[1] 4.420501

 ## 1 sd = 4.420501 

> mean(y)
[1] 30.96381

 ## average male control diet bodyweight = 30.96381 


 ## filter the data values that are +- 4.420501 away from the mean. This selects mice bodyweight values that fall within this range. calculate what % of mice fall in this interval compared to the total with mean() 

> m <- mean(y)
> n <- popsd(y)
> mean(dat >= m - n & dat <= m + n)
[1] 0.1458581
> mean(y >= m - n & dat <= m + n)
[1] 0.2358304
> mean(y >= m - n & y <= m + n)
[1] 0.6950673

 ## refer to filtered male, control diet mice variable *y*, not unfiltered dataset *dat* 


 ##i.e. 69.5% of male, control diet mice bodyweight values fall within 1 sd range 


 ** What proportion of these numbers are within two standard deviations away from the list’s average? ** 

> n <- popsd(y) * 2

 ## i.e. popsd() returns 1sd value, therefore *2 gives 2sd values 

> `?`(popsd())
> mean(y >= m - n & y <= m + n)
[1] 0.9461883

 ## 94.6% of male control diet bodyweight values fall within 2 sd from the mean 


 **What proportion of these numbers are within three standard deviations away from the list’s average? ** 

> n <- popsd(y) * 3
> mean(y >= m - n & y <= m + n)
[1] 0.9910314

 ## 99/1% 


 ** Note that the numbers for the normal distribution and our weights are relatively close. Also, notice that we are indirectly comparing quantiles of the normal distribution to quantiles of the mouse weight distribution. We can actually compare all quantiles using a qqplot. Which of the following best describes the qq-plot comparing mouse weights to the normal distribution? ** 


 ##qqnorm to compare against normal distribution (CDF), qqplot to compare between 2 datasets (we only have 1 i.e. y 

> `?`(qqnorm)
> qqnorm(y)
> qqline(y)
> `?`(qwnorm)
No documentation for ‘qwnorm’ in specified packages and libraries:
you could try ‘??qwnorm’
> `?`(qqnorm)

 ##C) The mouse weights are well approximated by the normal distribution, although the larger values (right tail) are larger than predicted by the normal. This is consistent with the differences seen between question 3 and 6 


 ## i.e. values on right tail are larger than expected (if assuming normal distribution). The sd calculations above show that y dataset is very close to a normal distribution, but with more sd away (2 and 3 sd), it is further from the expected/theoretical normal distribution. i.e. 3sd CDF = 99.7%, but y dataset is 99.1%, i.e. less than expected data falls within the 3sd range (bc of extreme values, hence the deviating values from the right tail) 


 **Create the above qq-plot for the four populations: male/females on each of the two diets. What is the most likely explanation for the mouse weights being well approximated? What is the best explanation for all these being well approximated by the normal distribution? ** 

> z <- filter(dat, Sex == "F" & Diet == "chow") %>% select(Bodyweight) %>% 
+ unlist()
> head(z)
Bodyweight1 Bodyweight2 Bodyweight3 Bodyweight4 Bodyweight5 Bodyweight6 
      27.03       24.80       27.02       28.07       23.55       22.72 
> qqline(z)
> qqnorm(z)
> qqline(z)

 ## female control diet mice are also close to normal distibution. Some extreme values on the tails. Appears that right tail (larger values) are more extreme in female control diet compared to male control diet 

> qqnorm(y)
> qqline(y)
> qqnorm(z)
> qqline(y)
> qqline(z)
> yhf <- filter(dat, Sex == "M" & Diet == "hf") %>% select(Bodyweight)
> yhf <- unlist(yhf)
> head(yhf)
Bodyweight1 Bodyweight2 Bodyweight3 Bodyweight4 Bodyweight5 Bodyweight6 
      27.81       29.45       35.11       31.25       38.26       29.06 
> qqnorm(yhf)
> zhf <- filter(dat, Sex == "F" & Diet == "hf") %>% select(Bodyweight) %>% 
+ unlist()
> head(zhf)
Bodyweight1 Bodyweight2 Bodyweight3 Bodyweight4 Bodyweight5 Bodyweight6 
      31.94       32.48       22.82       19.92       32.22       27.50 
> qqnorm(zhf)
> qqline(zhf)

 ## ANS: A The CLT tells us that sample averages are approximately normal. 


 ** Here we are going to use the function replicate to learn about the distribution of random variables. All the above exercises relate to the normal distribution as an approximation of the distribution of a fixed list of numbers or a population. We have not yet discussed probability in these exercises. If the distribution of a list of numbers is approximately normal, then if we pick a number at random from this distribution, it will follow a normal distribution. However, it is important to remember that stating that some quantity has a distribution does not necessarily imply this quantity is random. Also, keep in mind that this is not related to the central limit theorem. The central limit applies to averages of random variables. Let’s explore this concept. ** 

> txtStop
function() {
  removeTaskCallback('r2txt')
  if( R2txt.vars$closecon ) {
    close( R2txt.vars$con )
  }
  if( R2txt.vars$cmdfile && R2txt.vars$closecon2 ) {
    close( R2txt.vars$con2 )
  }
  options( prompt=R2txt.vars$prompt,
           continue=R2txt.vars$continue )
  if(R2txt.vars$res) {
      sink()
      close(R2txt.vars$outcon)
  }
  evalq( rm(list=ls()), envir=R2txt.vars )
  invisible(NULL)
}
<bytecode: 0x7fb07502d3c0>
<environment: namespace:TeachingDemos>
txt> txtStart("Ch1_Inference.txt", append = TRUE)
txt> `?`(sample)
txt> `?`(sample)
txt> `?`(replicate)
txt> `?`(replicate)
txt> set.seed(1)
txt> set.seed(1)
txt> avgs <- sample(y, 25) %>% mean() %>% replicate(1000)
txt> avgs <- sample(y, 25) %>% mean() %>% replicate(1000)
txt> head(avgs)
[1] 1000 1000 1000 1000 1000 1000
txt> head(avgs)
txt> avgs <- replicate(1000, mean(sample(y, 25)))
txt> avgs <- replicate(1000, mean(sample(y, 25)))
txt> head(avgs)
[1] 31.2988 31.1696 29.3772 31.9388 31.7060 29.7660
txt> head(avgs)

 ##`replicate() peforms the Monte Carlo simulation from earlier in the chapter. Take a sample of size 25 from male control diet mice (y), use mean() to get 1000 values of the average of each sample group, replicate 1000x to get 1000 averages 

txt> txtComment("##`replicate() peforms the Monte Carlo simulation from earlier in the chapter. Take a sample of size 25 from male control diet mice (y), use mean() to get 1000 values of the average of each sample group, replicate 1000x to get 1000 averages")
txt> avgs <- replicate(10000, mean(sample(y, 25)))
txt> avgs <- replicate(10000, mean(sample(y, 25)))
txt> hist(avgs)
txt> hist(avgs)
txt> qqnorm(avgs)
txt> qqnorm(avgs)
txt> qqline(avgs)
txt> qqline(avgs)
txt> `?`(sd)
txt> `?`(sd)
txt> sd(avgs)
[1] 0.8268776
txt> sd(avgs)
txt> set.seed(1)
txt> set.seed(1)
txt> avgs <- replicate(10000, mean(sample(y, 25)))
txt> avgs <- replicate(10000, mean(sample(y, 25)))
txt> hist(avgs)
txt> hist(avgs)
txt> qqnorm(avgs)
txt> qqnorm(avgs)
txt> qqline(avgs)
txt> qqline(avgs)
txt> sd(avgs)
[1] 0.8271233
txt> sd(avgs)
txt> mean(y)
[1] 30.96381
txt> mean(y)
txt> mean(avgs)
[1] 30.96856
txt> mean(avgs)
txt> `?`(sqrt)
txt> `?`(sqrt)
txt> `?`(popsd)
txt> `?`(popsd)
txt> popsd(avgs)
[1] 0.827082
txt> popsd(avgs)

 **According to the CLT, the answer to exercise 9 should be the same as mean(y). You should be able to confirm that these two numbers are very close. Which of the following does the CLT tell us should be close to your answer to exercise 10? 

txt> txtComment("**According to the CLT, the answer to exercise 9 should be the same as mean(y). You should be able to confirm that these two numbers are very close. Which of the following does the CLT tell us should be close to your answer to exercise 10?")

 ## CLT central limit theorem calculates the standard deviation of a group of sample averages by taking the population sd (popsd()) and dividing it by the square root of n (sampel size) 

txt> txtComment("## CLT central limit theorem calculates the standard deviation of a group of sample averages by taking the population sd (popsd()) and dividing it by the square root of n (sampel size)")

 ## therfore ANS = D) popsd(y)/sqrt(25) 

txt> txtComment("## therfore ANS = D) popsd(y)/sqrt(25)")

 ** (popsd(y)) which is why we can’t use the CLT directly. This is because we see a sample and not the entire distribution. We also can’t use popsd(avgs) because to construct averages, we have to take 10,000 samples and this is never practical. We usually just get one sample. Instead we have to estimate popsd(y). As described, what we use is the sample standard deviation. Set the seed at 1, using the replicate function, create 10,000 samples of 25 and now, instead of the sample average, keep the standard deviation. Look at the distribution of the sample standard deviations. It is a random variable. The real population SD is about 4.5. What proportion of the sample SDs are below 3.5? ** 

txt> txtComment("** (popsd(y)) which is why we can’t use the CLT directly. This is because we see a sample and not the entire distribution. We also can’t use popsd(avgs) because to construct averages, we have to take 10,000 samples and this is never practical. We usually just get one sample. Instead we have to estimate popsd(y). As described, what we use is the sample standard deviation. Set the seed at 1, using the replicate function, create 10,000 samples of 25 and now, instead of the sample average, keep the standard deviation. Look at the distribution of the sample standard deviations. It is a random variable. The real population SD is about 4.5. What proportion of the sample SDs are below 3.5? **")
txt> set.seed(1)
txt> set.seed(1)
txt> sds <- replicate(10000, sd(sample(y, 25)))
txt> sds <- replicate(10000, sd(sample(y, 25)))
txt> head(sds)
[1] 3.928546 5.454165 3.838789 3.838535 4.997106 4.898378
txt> head(sds)

 ## i.e. replacing mean() with sds() means for each value generated in the samples of group size 25, its standard deviation from the average/mean of dataset y is generated 

txt> txtComment("## i.e. replacing mean() with sds() means for each value generated in the samples of group size 25, its standard deviation from the average/mean of dataset y is generated")

 ## these are classed as random variables because the values generated are reliant on the random nature of sample generation. It wouldn't produce the same sets of sd values if we ran again w/ different seed 

txt> txtComment("## these are classed as random variables because the values generated are reliant on the random nature of sample generation. It wouldn't produce the same sets of sd values if we ran again w/ different seed")
txt> mean(sds <= 3.5)
[1] 0.0942
txt> mean(sds <= 3.5)

 ## 9% of values in male control diet mice bodyweight values are 3.5 sd below the mean 

txt> txtComment("## 9% of values in male control diet mice bodyweight values are 3.5 sd below the mean")

 ## if the real population is ~4.5, it would make sense that few (9%) of data is not 4.5 sd (?) 

txt> txtComment("## if the real population is ~4.5, it would make sense that few (9%) of data is not 4.5 sd (?)")
txt> sds <- replicate(10000, popsd(sample(y, 25)))
txt> sds <- replicate(10000, popsd(sample(y, 25)))
txt> head(sds)
[1] 4.016802 3.742225 4.033065 3.402931 4.143360 4.041522
txt> head(sds)
txt> mean(sds <= 3.5)
[1] 0.1108
txt> mean(sds <= 3.5)

 ## actaully use popsd()? proportion is 11% 

txt> txtComment("## actaully use popsd()? proportion is 11%")
txt> `?`(qt)
txt> `?`(qt)
txt> `?`(seq)
txt> `?`(seq)

 **What the answer to question 12 reveals is that the denominator of the t-test is a random variable. By decreasing the sample size, you can see how this variability can increase. It therefore adds variability. The smaller the sample size, the more variability is added. The normal distribution stops providing a useful approximation. When the distribution of the population values is approximately normal, as it is for the weights, the t-distribution provides a better approximation. We will see this later on. Here we will look at the difference between the t-distribution and normal. Use the function qt and qnorm to get the quantiles of x=seq(0.0001,0.9999,len=300). Do this for degrees of freedom 3, 10, 30, and 100. Which of the following is true? ** 

txt> txtComment("**What the answer to question 12 reveals is that the denominator of the t-test is a random variable. By decreasing the sample size, you can see how this variability can increase. It therefore adds variability. The smaller the sample size, the more variability is added. The normal distribution stops providing a useful approximation. When the distribution of the population values is approximately normal, as it is for the weights, the t-distribution provides a better approximation. We will see this later on. Here we will look at the difference between the t-distribution and normal. Use the function qt and qnorm to get the quantiles of x=seq(0.0001,0.9999,len=300). Do this for degrees of freedom 3, 10, 30, and 100. Which of the following is true? **")
txt> x = seq(1e-04, 0.9999, len = 300)
txt> x = seq(1e-04, 0.9999, len = 300)
txt> head(x)
[1] 0.000100000 0.003443813 0.006787625 0.010131438 0.013475251 0.016819064
txt> head(x)

 i.e. len=300 means 300 values, starting from 0.0001 up to 0.9999, in equal increments 

txt> txtComment("i.e. len=300 means 300 values, starting from 0.0001 up to 0.9999, in equal increments")
txt> dim(x)
NULL
txt> dim(x)
txt> length(x)
[1] 300
txt> length(x)
txt> `?`(qt)
txt> `?`(qt)
txt> qt(x, 3)
  [1] -22.203742273  -6.664348674  -5.233577197  -4.518726011  -4.059172734  -3.727266670  -3.470704908
  [8]  -3.263323229  -3.090301354  -2.942494303  -2.813893155  -2.700354695  -2.598910948  -2.507368823
 [15]  -2.424065585  -2.347712970  -2.277294188  -2.211993758  -2.151148443  -2.094212135  -2.040730233
 [22]  -1.990320584  -1.942659108  -1.897468777  -1.854511070  -1.813579263  -1.774493106  -1.737094556
 [29]  -1.701244333  -1.666819106  -1.633709186  -1.601816617  -1.571053586  -1.541341090  -1.512607813
 [36]  -1.484789176  -1.457826525  -1.431666443  -1.406260147  -1.381562978  -1.357533956  -1.334135392
 [43]  -1.311332548  -1.289093341  -1.267388085  -1.246189257  -1.225471300  -1.205210434  -1.185384506
 [50]  -1.165972841  -1.146956113  -1.128316238  -1.110036265  -1.092100286  -1.074493352  -1.057201399
 [57]  -1.040211180  -1.023510203  -1.007086672  -0.990929443  -0.975027971  -0.959372268  -0.943952869
 [64]  -0.928760792  -0.913787507  -0.899024906  -0.884465275  -0.870101269  -0.855925890  -0.841932461
 [71]  -0.828114612  -0.814466257  -0.800981578  -0.787655010  -0.774481227  -0.761455125  -0.748571813
 [78]  -0.735826597  -0.723214975  -0.710732619  -0.698375372  -0.686139236  -0.674020362  -0.662015047
 [85]  -0.650119720  -0.638330940  -0.626645390  -0.615059865  -0.603571273  -0.592176626  -0.580873033
 [92]  -0.569657702  -0.558527927  -0.547481089  -0.536514653  -0.525626159  -0.514813222  -0.504073527
 [99]  -0.493404829  -0.482804945  -0.472271754  -0.461803194  -0.451397259  -0.441051995  -0.430765503
[106]  -0.420535928  -0.410361464  -0.400240351  -0.390170868  -0.380151338  -0.370180121  -0.360255615
[113]  -0.350376253  -0.340540502  -0.330746862  -0.320993864  -0.311280067  -0.301604060  -0.291964459
[120]  -0.282359904  -0.272789060  -0.263250618  -0.253743289  -0.244265804  -0.234816916  -0.225395398
[127]  -0.216000040  -0.206629649  -0.197283049  -0.187959079  -0.178656593  -0.169374460  -0.160111560
[134]  -0.150866787  -0.141639045  -0.132427250  -0.123230327  -0.114047211  -0.104876846  -0.095718182
[141]  -0.086570179  -0.077431801  -0.068302020  -0.059179812  -0.050064158  -0.040954043  -0.031848455
[148]  -0.022746385  -0.013646827  -0.004548775   0.004548775   0.013646827   0.022746385   0.031848455
[155]   0.040954043   0.050064158   0.059179812   0.068302020   0.077431801   0.086570179   0.095718182
[162]   0.104876846   0.114047211   0.123230327   0.132427250   0.141639045   0.150866787   0.160111560
[169]   0.169374460   0.178656593   0.187959079   0.197283049   0.206629649   0.216000040   0.225395398
[176]   0.234816916   0.244265804   0.253743289   0.263250618   0.272789060   0.282359904   0.291964459
[183]   0.301604060   0.311280067   0.320993864   0.330746862   0.340540502   0.350376253   0.360255615
[190]   0.370180121   0.380151338   0.390170868   0.400240351   0.410361464   0.420535928   0.430765503
[197]   0.441051995   0.451397259   0.461803194   0.472271754   0.482804945   0.493404829   0.504073527
[204]   0.514813222   0.525626159   0.536514653   0.547481089   0.558527927   0.569657702   0.580873033
[211]   0.592176626   0.603571273   0.615059865   0.626645390   0.638330940   0.650119720   0.662015047
[218]   0.674020362   0.686139236   0.698375372   0.710732619   0.723214975   0.735826597   0.748571813
[225]   0.761455125   0.774481227   0.787655010   0.800981578   0.814466257   0.828114612   0.841932461
[232]   0.855925890   0.870101269   0.884465275   0.899024906   0.913787507   0.928760792   0.943952869
[239]   0.959372268   0.975027971   0.990929443   1.007086672   1.023510203   1.040211180   1.057201399
[246]   1.074493352   1.092100286   1.110036265   1.128316238   1.146956113   1.165972841   1.185384506
[253]   1.205210434   1.225471300   1.246189257   1.267388085   1.289093341   1.311332548   1.334135392
[260]   1.357533956   1.381562978   1.406260147   1.431666443   1.457826525   1.484789176   1.512607813
[267]   1.541341090   1.571053586   1.601816617   1.633709186   1.666819106   1.701244333   1.737094556
[274]   1.774493106   1.813579263   1.854511070   1.897468777   1.942659108   1.990320584   2.040730233
[281]   2.094212135   2.151148443   2.211993758   2.277294188   2.347712970   2.424065585   2.507368823
[288]   2.598910948   2.700354695   2.813893155   2.942494303   3.090301354   3.263323229   3.470704908
[295]   3.727266670   4.059172734   4.518726011   5.233577197   6.664348674  22.203742273
txt> qt(x, 3)
txt> qqnorm(x)
txt> qqnorm(x)
txt> qt(x, 3) %>% qqnorm()
txt> qt(x, 3) %>% qqnorm()
txt> qt(x, 10) %>% qqnorm()
txt> qt(x, 10) %>% qqnorm()
txt> qt(x, 30) %>% qqnorm()
txt> qt(x, 30) %>% qqnorm()
txt> qt(x, 100) %>% qqnorm()
txt> qt(x, 100) %>% qqnorm()

 ## the above exercise using replicate (Monte Carlo) leads to random variables. this means that the sd varies i.e. not fixed. with larger sample sizes, sd varies less. however, sd struggles with smaller samples i.e. will show larger variances. t-distribution with qt() takes into account the larger variability that sd struggles with in smaller samples by   

txt> txtComment("## the above exercise using replicate (Monte Carlo) leads to random variables. this means that the sd varies i.e. not fixed. with larger sample sizes, sd varies less. however, sd struggles with smaller samples i.e. will show larger variances. t-distribution with qt() takes into account the larger variability that sd struggles with in smaller samples by  ")

 ## elongating the tail ends, i.e. increasing the spread of the data to compensate for the higher variance. 

txt> txtComment("## elongating the tail ends, i.e. increasing the spread of the data to compensate for the higher variance.")

 ## and 'elongating the tails' means its making the distribution wider than normal to account/compensate for the larger variance seen in smaller samples 

txt> txtComment("## and 'elongating the tails' means its making the distribution wider than normal to account/compensate for the larger variance seen in smaller samples")

 ## the larger the sample, the less 'elongated tails' there are with t-distribution, because a larger sample means its closer to the population actual value, hence there's not much variability to account/compensate for, hence the more-linear curve 

txt> txtComment("## the larger the sample, the less 'elongated tails' there are with t-distribution, because a larger sample means its closer to the population actual value, hence there's not much variability to account/compensate for, hence the more-linear curve")

 ## the df (degrees of freedom) reflect this, df = sample sizes, the smaller the sample, the more elongated the tails are, i.e. qt() makes the distribution larger than normal to compensate for the higher variance in smaller samples 

txt> txtComment("## the df (degrees of freedom) reflect this, df = sample sizes, the smaller the sample, the more elongated the tails are, i.e. qt() makes the distribution larger than normal to compensate for the higher variance in smaller samples")
txt> qt(x, 3) %>% qqnorm()
txt> qt(x, 3) %>% qqnorm()
txt> qt(x, 10) %>% qqnorm()
txt> qt(x, 10) %>% qqnorm()
txt> qt(x, 30) %>% qqnorm()
txt> qt(x, 30) %>% qqnorm()
txt> qt(x, 100) %>% qqnorm()
txt> qt(x, 100) %>% qqnorm()

 ## ANS: C) The t-distribution has larger tails up until 30 degrees of freedom, at which point it is practically the same as the normal distribution. 

txt> txtComment("## ANS: C) The t-distribution has larger tails up until 30 degrees of freedom, at which point it is practically the same as the normal distribution.")
txt> txtStop
function() {
  removeTaskCallback('r2txt')
  if( R2txt.vars$closecon ) {
    close( R2txt.vars$con )
  }
  if( R2txt.vars$cmdfile && R2txt.vars$closecon2 ) {
    close( R2txt.vars$con2 )
  }
  options( prompt=R2txt.vars$prompt,
           continue=R2txt.vars$continue )
  if(R2txt.vars$res) {
      sink()
      close(R2txt.vars$outcon)
  }
  evalq( rm(list=ls()), envir=R2txt.vars )
  invisible(NULL)
}
<bytecode: 0x7fb07502d3c0>
<environment: namespace:TeachingDemos>
txt> txtStop
> library(rafalib)
> library(tidyverse)
> library(downloader)

 ## CLT: the more you sample and take its average, the more you cancel out / silence the extreme values. therefore CLT will tend towards a normal distribution bell curve if you take sample averages many times 

> dat <- read.csv("mice_pheno.csv")
> head(dat)
  Sex Diet Bodyweight
1   F   hf      31.94
2   F   hf      32.48
3   F   hf      22.82
4   F   hf      19.92
5   F   hf      32.22
6   F   hf      27.50
> controlPopulation <- filter(dat, Sex == "F" & Diet == "chow") %>% 
+ select(Bodyweight) %>% unlist()
> hfPopulation <- filter(dat, Sex == "F" & Diet == "hf") %>% select(Bodyweight) %>% 
+ unlist()
> sd_control <- popsd(controlPopulation)
> sd_hf <- popsd(controlPopulation)
> sd_control <- popsd(controlPopulation)
> sd_hf <- popsd(hfPopulation)
> `?`(function(N) n)
> Ns <- c(3, 12, 25, 50)
> B <- 10000
> res <- (sapply(Ns, function(n) {
+ replicate(B, mean(sample(hfPopulation, n)) - mean(sample(controlPopulation, 
+ 
+ n)))
+ }))

 ## i.e. sapply loops the following for each value in vector Ns. Ns holds sample size values - test to see how the sampling popsd values change depending on sample size 

> head(res)
          [,1]      [,2]   [,3]    [,4]
[1,] 3.4800000  1.975000 3.0380 2.27338
[2,] 1.5400000  3.928333 4.0436 4.36620
[3,] 3.4866667  3.211667 3.0672 2.71720
[4,] 0.4666667  3.135833 1.7496 3.00978
[5,] 5.5166667 -2.525000 1.8964 1.93980
[6,] 2.1633333  4.505000 2.9004 1.95480
> n <- 12
> head(res)
          [,1]      [,2]   [,3]    [,4]
[1,] 3.4800000  1.975000 3.0380 2.27338
[2,] 1.5400000  3.928333 4.0436 4.36620
[3,] 3.4866667  3.211667 3.0672 2.71720
[4,] 0.4666667  3.135833 1.7496 3.00978
[5,] 5.5166667 -2.525000 1.8964 1.93980
[6,] 2.1633333  4.505000 2.9004 1.95480

 ## function(n) opens loop to calculate the mean differences between control and hf diet mice bodyweight, repeated 10,000 times, for sample sizes listed in Ns: 3, 12, 25, 50 


 ## the 'n' inside sample(hfPopulation, n) is referring to the sample size as the loop cycles through each vector value in variable Ns e.g. 3 


 ## if the CLT is working, then the qq plots with larger sample sizes (i.e. n = 50) should have the most normal distribution i.e. closest to linear graph, i.e. reflecting that the larger the sample size, the more normal the distribution (because the extreme values are silenced, growing towards central tendency) 

> `?`(mypar)
> `?`(along)
> `?`(signif)

 ## the original population itself may already have a normal distribution, which will also be reflected in the sample CLT plots 

> `?`(var)

 ## variance of a sample mean (var(Y) is equal to the population variance, divided by the sample size (n); hence: variance of sample mean is equal to var(y) / n 


 ## when comparing the variance between 2 independent groups, you add their individual variances; i.e. the more groups you introduce, the larger the overall variance 


 ##square root that to get the standard error, i/e. sqrt(var(y)/n + var(x)/n) 


 ## then divide the mean difference between the sample averages of the 2 groups (numerator), by the above (denominator)^ 

> url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/femaleMiceWeights.csv"
> filename <- "femaleMiceWeights.csv"
> if (!file.exists("femaleMiceWeights.csv")) download(url, destfile = filename)
> if (!file.exists("femaleMiceWeights.csv")) download(url, destfile = filename)
> dat <- read.csv(filename)

 ** The CLT is a result from probability theory. Much of probability theory was originally inspired by gambling. This theory is still used in practice by casinos. For example, they can estimate how many people need to play slots for there to be a 99.9999% probability of earning enough money to cover expenses. Let’s try a simple example related to gambling. ** 


 ** Suppose we are interested in the proportion of times we see a 6 when rolling n=100 die. This is a random variable which we can simulate with x=sample(1:6, n, replace=TRUE) and the proportion we are interested in can be expressed as an average: mean(x==6). Because the die rolls are independent, the CLT applies. ** 


 **. We want to roll n dice 10,000 times and keep these proportions. This random variable (proportion of 6s) has mean p=1/6 and variance p*(1-p)/n. So according to CLT z = (mean(x==6) - p) / sqrt(p*(1-p)/n) should be normal with mean 0 and SD 1. Set the seed to 1, then use replicate to perform the simulation, and report what proportion of times z was larger than 2 in absolute value (CLT says it should be about 0.05). ** 

> set.seed(1)

 ## variance = p(1-p)/n; where p = probabilty 


 ## i.e. p = 1/6 times we will roll a 6. subtract from 1 to get the number of times we will not get a 6 (5/6). multiply the failure probability (5/6) by our wanted probability (1/6). multiplying two probabilities together means you expect both outcomes at the same time, but in this case it would mean getting a value that explains what the overall *uncertainty* is to achieve the 1/6 times of rolling a 6. multipling a small fraction (1/6) by a larger fraction (5/6) would give a relatively low number, i.e. explaining low variance in the data - this is because we expect more 'No 


 ## if we had a higher chance of rolling a 6, e.g. a biased dice with a 3/6 likelihood of rolling a 6, 3/6 times the dice would not roll a 6. Multiplying these fractions would give a larger number, hence explaining a larger variance of data (Yes and No to rolling a 6) 


 ## finally, variance equation p(1-6)/n includes n for sample size - this takes the average probability of getting a 6 on the dice. the larger the n value, the more amount of samples were collected, i.e. more likely to silence out the 'noise' in the data, hence divindg variance by a large n will produce a smaller variance value 


 ## sqrt(p(1-p)/n) gives the standard error 

> `?`(replicate)
> set.seed(1)

 ** We want to roll n dice 10,000 times and keep these proportions. This random variable (proportion of 6s) has mean p=1/6 and variance p*(1-p)/n. So according to CLT z = (mean(x==6) - p) / sqrt(p*(1-p)/n) should be normal with mean 0 and SD 1. Set the seed to 1, then use replicate to perform the simulation, and report what proportion of times z was larger than 2 in absolute value (CLT says it should be about 0.05). **  

> x = sample(1:6, 10000, replace = TRUE)
> txtStop
function() {
  removeTaskCallback('r2txt')
  if( R2txt.vars$closecon ) {
    close( R2txt.vars$con )
  }
  if( R2txt.vars$cmdfile && R2txt.vars$closecon2 ) {
    close( R2txt.vars$con2 )
  }
  options( prompt=R2txt.vars$prompt,
           continue=R2txt.vars$continue )
  if(R2txt.vars$res) {
      sink()
      close(R2txt.vars$outcon)
  }
  evalq( rm(list=ls()), envir=R2txt.vars )
  invisible(NULL)
}
<bytecode: 0x7fac73c8f6d0>
<environment: namespace:TeachingDemos>
txt> txtStart("Ch1_Inference.txt", append = TRUE)

 ## variance p*(1-p)/n explains the spread of the data. dividing by the sample size explains the 'noise', i.e. the larger the sample, the larger the divisible factor, hence a lower variation. 

txt> txtComment("## variance p*(1-p)/n explains the spread of the data. dividing by the sample size explains the 'noise', i.e. the larger the sample, the larger the divisible factor, hence a lower variation.")

 ## variance units is sigma^2, i.e. squared to remove any negative values for a standardised variance value. 

txt> txtComment("## variance units is sigma^2, i.e. squared to remove any negative values for a standardised variance value.")

 ## therefore, sqrt(variance) gives the standard error, i.e. the value of 1 standard deviation is x amount from the population mean 

txt> txtComment("## therefore, sqrt(variance) gives the standard error, i.e. the value of 1 standard deviation is x amount from the population mean")

 ## the z-score standardises the whole data so that you can compare to other datasets. different datasets have different means and sd. z-score standardises sample data to mean = 0 and to 1 sd. this produces a bell curve / z-score that can be compared to other standardised datasets 

txt> txtComment("## the z-score standardises the whole data so that you can compare to other datasets. different datasets have different means and sd. z-score standardises sample data to mean = 0 and to 1 sd. this produces a bell curve / z-score that can be compared to other standardised datasets")

 ## (mean(x==6) - p) selects the number of times the die rolled a 6, divided by the total number of rolls in x dataset, i.e. the average number of times 6 was rolled. 

txt> txtComment("## (mean(x==6) - p) selects the number of times the die rolled a 6, divided by the total number of rolls in x dataset, i.e. the average number of times 6 was rolled.")

 ## (- p) subtracts the probability from the above mean value^ to shift the average mean value to 0, hence standardising the data 

txt> txtComment("## (- p) subtracts the probability from the above mean value^ to shift the average mean value to 0, hence standardising the data")

 ## CLT should be normal (as each die roll is independent) with mean 0 and SD 1. 'normal' i.e. standard bell curve and normal distribution, expected variation, silenced the noise (outliers) 

txt> txtComment("## CLT should be normal (as each die roll is independent) with mean 0 and SD 1. 'normal' i.e. standard bell curve and normal distribution, expected variation, silenced the noise (outliers)")

 ** We want to roll n dice 10,000 times and keep these proportions. This random variable (proportion of 6s) has mean p=1/6 and variance p*(1-p)/n. So according to CLT z = (mean(x==6) - p) / sqrt(p*(1-p)/n) should be normal with mean 0 and SD 1. Set the seed to 1, then use replicate to perform the simulation, and report what proportion of times z was larger than 2 in absolute value (CLT says it should be about 0.05). ** 

txt> txtComment("** We want to roll n dice 10,000 times and keep these proportions. This random variable (proportion of 6s) has mean p=1/6 and variance p*(1-p)/n. So according to CLT z = (mean(x==6) - p) / sqrt(p*(1-p)/n) should be normal with mean 0 and SD 1. Set the seed to 1, then use replicate to perform the simulation, and report what proportion of times z was larger than 2 in absolute value (CLT says it should be about 0.05). **")
txt> set.seed(1)
txt> set.seed(1)
txt> p = 1/6
txt> p = 1/6
txt> sample(1:6, replace = TRUE)
[1] 1 4 1 2 5 3
txt> sample(1:6, replace = TRUE)
txt> mean(sample(1:6, replace = TRUE))
[1] 3.333333
txt> mean(sample(1:6, replace = TRUE))
txt> mean(sample(1:6, replace = TRUE))
[1] 3.666667
txt> mean(sample(1:6, replace = TRUE))
txt> mean(sample(1:6, replace = TRUE))
[1] 3.833333
txt> mean(sample(1:6, replace = TRUE))

 ## the expected mean is around 3.5 for rolling a 6 sided dice. we need to replicate calculating the mean of a sample 10,000 times 

txt> txtComment("## the expected mean is around 3.5 for rolling a 6 sided dice. we need to replicate calculating the mean of a sample 10,000 times")
txt> x <- mean(sample(1:6, replace = TRUE))
txt> x <- mean(sample(1:6, replace = TRUE))
txt> x
[1] 3.333333
txt> x
txt> x
[1] 3.333333
txt> x
txt> x
[1] 3.333333
txt> x
txt> x = mean(sample(1:6, replace = TRUE))
txt> x = mean(sample(1:6, replace = TRUE))
txt> x
[1] 3
txt> x
txt> x
[1] 3
txt> x
txt> x
[1] 3
txt> x
txt> x <- replicate(10000, mean(sample(1:6, replace = TRUE)))
txt> x <- replicate(10000, mean(sample(1:6, replace = TRUE)))
txt> head(x)
[1] 4.000000 3.166667 3.500000 4.333333 4.166667 3.000000
txt> head(x)
txt> set.seed(1)
txt> set.seed(1)
txt> x <- replicate(10000, mean(sample(1:6, replace = TRUE)))
txt> x <- replicate(10000, mean(sample(1:6, replace = TRUE)))
txt> head(x)
[1] 2.666667 3.333333 3.666667 3.833333 3.333333 3.000000
txt> head(x)

 ## actualy, don't include mean in the replicate simulation yet, bc we need to do mean() to calculate the z-score. formula wants to select x == 6, but can't because x variable only has means / no 6 integer 

txt> txtComment("## actualy, don't include mean in the replicate simulation yet, bc we need to do mean() to calculate the z-score. formula wants to select x == 6, but can't because x variable only has means / no 6 integer")
txt> set.seed(1)
txt> set.seed(1)
txt> x <- replicate(10000, sample(1:6, replace = TRUE))
txt> x <- replicate(10000, sample(1:6, replace = TRUE))
txt> head(x)
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15] [,16] [,17] [,18]
[1,]    1    6    5    5    5    1    6    1    2     5     3     1     4     4     1     3     2     2
     [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34]
[1,]     4     3     4     1     3     6     3     4     2     3     1     5     6     1     5     1
     [,35] [,36] [,37] [,38] [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]
[1,]     4     5     5     5     4     6     3     5     5     4     1     6     2     2     3     6
     [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62] [,63] [,64] [,65] [,66]
[1,]     5     5     3     5     1     5     2     5     3     5     2     3     6     2     1     1
     [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74] [,75] [,76] [,77] [,78] [,79] [,80] [,81] [,82]
[1,]     6     2     1     2     2     5     1     6     6     1     4     4     2     3     3     6
     [,83] [,84] [,85] [,86] [,87] [,88] [,89] [,90] [,91] [,92] [,93] [,94] [,95] [,96] [,97] [,98]
[1,]     2     4     6     2     2     5     3     1     3     4     3     1     1     2     3     1
     [,99] [,100] [,101] [,102] [,103] [,104] [,105] [,106] [,107] [,108] [,109] [,110] [,111] [,112]
[1,]     2      5      5      1      4      1      4      2      6      6      5      6      3      6
     [,113] [,114] [,115] [,116] [,117] [,118] [,119] [,120] [,121] [,122] [,123] [,124] [,125] [,126]
[1,]      4      3      6      6      4      5      1      2      4      5      2      2      5      5
     [,127] [,128] [,129] [,130] [,131] [,132] [,133] [,134] [,135] [,136] [,137] [,138] [,139] [,140]
[1,]      4      1      3      4      2      5      1      4      2      5      2      3      2      1
     [,141] [,142] [,143] [,144] [,145] [,146] [,147] [,148] [,149] [,150] [,151] [,152] [,153] [,154]
[1,]      4      2      6      4      4      5      3      2      6      5      3      6      2      4
     [,155] [,156] [,157] [,158] [,159] [,160] [,161] [,162] [,163] [,164] [,165] [,166] [,167] [,168]
[1,]      6      5      2      6      5      2      5      2      5      1      1      6      5      6
     [,169] [,170] [,171] [,172] [,173] [,174] [,175] [,176] [,177] [,178] [,179] [,180] [,181] [,182]
[1,]      3      6      4      6      5      5      1      6      3      3      6      2      2      1
     [,183] [,184] [,185] [,186] [,187] [,188] [,189] [,190] [,191] [,192] [,193] [,194] [,195] [,196]
[1,]      6      6      4      1      5      5      6      4      3      6      4      4      3      2
     [,197] [,198] [,199] [,200] [,201] [,202] [,203] [,204] [,205] [,206] [,207] [,208] [,209] [,210]
[1,]      2      5      1      4      6      1      2      5      3      1      1      6      2      5
     [,211] [,212] [,213] [,214] [,215] [,216] [,217] [,218] [,219] [,220] [,221] [,222] [,223] [,224]
[1,]      2      3      3      2      1      2      4      2      6      1      4      1      2      3
     [,225] [,226] [,227] [,228] [,229] [,230] [,231] [,232] [,233] [,234] [,235] [,236] [,237] [,238]
[1,]      4      5      3      4      4      6      3      5      3      1      5      1      4      6
     [,239] [,240] [,241] [,242] [,243] [,244] [,245] [,246] [,247] [,248] [,249] [,250] [,251] [,252]
[1,]      6      6      6      4      5      1      1      6      1      6      1      6      3      3
     [,253] [,254] [,255] [,256] [,257] [,258] [,259] [,260] [,261] [,262] [,263] [,264] [,265] [,266]
[1,]      4      2      2      3      3      1      2      5      3      5      6      5      5      3
     [,267] [,268] [,269] [,270] [,271] [,272] [,273] [,274] [,275] [,276] [,277] [,278] [,279] [,280]
[1,]      5      5      5      5      6      6      2      2      6      3      5      1      5      5
     [,281] [,282] [,283] [,284] [,285] [,286] [,287] [,288] [,289] [,290] [,291] [,292] [,293] [,294]
[1,]      2      6      4      4      2      2      2      6      1      2      5      3      4      3
     [,295] [,296] [,297] [,298] [,299] [,300] [,301] [,302] [,303] [,304] [,305] [,306] [,307] [,308]
[1,]      5      4      1      2      3      6      2      2      5      1      4      2      5      5
     [,309] [,310] [,311] [,312] [,313] [,314] [,315] [,316] [,317] [,318] [,319] [,320] [,321] [,322]
[1,]      6      6      6      6      2      1      4      3      2      1      6      5      6      5
     [,323] [,324] [,325] [,326] [,327] [,328] [,329] [,330] [,331] [,332] [,333] [,334] [,335] [,336]
[1,]      5      6      2      2      2      2      5      3      4      4      4      1      1      4
     [,337] [,338] [,339] [,340] [,341] [,342] [,343] [,344] [,345] [,346] [,347] [,348] [,349] [,350]
[1,]      5      4      3      3      1      2      2      5      3      3      4      3      1      6
     [,351] [,352] [,353] [,354] [,355] [,356] [,357] [,358] [,359] [,360] [,361] [,362] [,363] [,364]
[1,]      4      2      3      2      1      5      5      3      3      3      2      4      6      4
     [,365] [,366] [,367] [,368] [,369] [,370] [,371] [,372] [,373] [,374] [,375] [,376] [,377] [,378]
[1,]      6      5      6      6      3      4      6      3      6      1      3      6      2      2
     [,379] [,380] [,381] [,382] [,383] [,384] [,385] [,386] [,387] [,388] [,389] [,390] [,391] [,392]
[1,]      3      4      4      2      2      6      4      5      1      4      2      2      2      6
     [,393] [,394] [,395] [,396] [,397] [,398] [,399] [,400] [,401] [,402] [,403] [,404] [,405] [,406]
[1,]      2      2      5      2      5      5      2      1      6      2      4      4      6      4
     [,407] [,408] [,409] [,410] [,411] [,412] [,413] [,414] [,415] [,416] [,417] [,418] [,419] [,420]
[1,]      4      4      5      1      4      5      5      6      1      3      6      4      2      5
     [,421] [,422] [,423] [,424] [,425] [,426] [,427] [,428] [,429] [,430] [,431] [,432] [,433] [,434]
[1,]      4      3      5      2      1      5      5      2      2      1      6      5      2      2
     [,435] [,436] [,437] [,438] [,439] [,440] [,441] [,442] [,443] [,444] [,445] [,446] [,447] [,448]
[1,]      2      4      3      1      1      5      4      6      5      6      3      4      4      4
     [,449] [,450] [,451] [,452] [,453] [,454] [,455] [,456] [,457] [,458] [,459] [,460] [,461] [,462]
[1,]      4      4      5      3      3      1      2      5      6      6      3      2      4      4
     [,463] [,464] [,465] [,466] [,467] [,468] [,469] [,470] [,471] [,472] [,473] [,474] [,475] [,476]
[1,]      5      3      4      2      5      5      3      1      4      1      5      1      1      6
     [,477] [,478] [,479] [,480] [,481] [,482] [,483] [,484] [,485] [,486] [,487] [,488] [,489] [,490]
[1,]      2      5      5      6      2      2      5      4      5      1      6      5      2      4
     [,491] [,492] [,493] [,494] [,495] [,496] [,497] [,498] [,499] [,500] [,501] [,502] [,503] [,504]
[1,]      1      4      1      3      5      3      3      4      5      6      4      3      3      5
     [,505] [,506] [,507] [,508] [,509] [,510] [,511] [,512] [,513] [,514] [,515] [,516] [,517] [,518]
[1,]      6      6      4      2      2      6      1      3      1      5      1      5      4      4
     [,519] [,520] [,521] [,522] [,523] [,524] [,525] [,526] [,527] [,528] [,529] [,530] [,531] [,532]
[1,]      6      5      3      3      1      3      4      3      6      6      1      5      6      5
     [,533] [,534] [,535] [,536] [,537] [,538] [,539] [,540] [,541] [,542] [,543] [,544] [,545] [,546]
[1,]      6      6      5      5      3      1      6      4      3      1      1      5      5      5
     [,547] [,548] [,549] [,550] [,551] [,552] [,553] [,554] [,555] [,556] [,557] [,558] [,559] [,560]
[1,]      4      1      5      4      6      2      1      5      3      2      2      2      3      6
     [,561] [,562] [,563] [,564] [,565] [,566] [,567] [,568] [,569] [,570] [,571] [,572] [,573] [,574]
[1,]      2      1      2      4      3      5      5      5      4      6      1      6      5      1
     [,575] [,576] [,577] [,578] [,579] [,580] [,581] [,582] [,583] [,584] [,585] [,586] [,587] [,588]
[1,]      3      4      4      3      5      3      1      6      1      4      5      4      6      2
     [,589] [,590] [,591] [,592] [,593] [,594] [,595] [,596] [,597] [,598] [,599] [,600] [,601] [,602]
[1,]      5      1      6      4      3      1      4      3      4      2      1      2      1      4
     [,603] [,604] [,605] [,606] [,607] [,608] [,609] [,610] [,611] [,612] [,613] [,614] [,615] [,616]
[1,]      4      2      2      1      5      6      6      1      4      1      2      4      2      1
     [,617] [,618] [,619] [,620] [,621] [,622] [,623] [,624] [,625] [,626] [,627] [,628] [,629] [,630]
[1,]      2      2      6      4      4      3      6      5      3      6      1      6      1      2
     [,631] [,632] [,633] [,634] [,635] [,636] [,637] [,638] [,639] [,640] [,641] [,642] [,643] [,644]
[1,]      5      4      2      1      3      5      4      6      2      2      4      4      3      3
     [,645] [,646] [,647] [,648] [,649] [,650] [,651] [,652] [,653] [,654] [,655] [,656] [,657] [,658]
[1,]      4      4      5      3      1      3      5      5      2      1      5      1      1      1
     [,659] [,660] [,661] [,662] [,663] [,664] [,665] [,666] [,667] [,668] [,669] [,670] [,671] [,672]
[1,]      1      1      5      5      3      6      6      5      4      6      3      5      1      6
     [,673] [,674] [,675] [,676] [,677] [,678] [,679] [,680] [,681] [,682] [,683] [,684] [,685] [,686]
[1,]      2      3      2      1      6      5      4      2      6      2      3      2      5      6
     [,687] [,688] [,689] [,690] [,691] [,692] [,693] [,694] [,695] [,696] [,697] [,698] [,699] [,700]
[1,]      1      4      4      2      2      2      2      4      1      3      5      3      6      3
     [,701] [,702] [,703] [,704] [,705] [,706] [,707] [,708] [,709] [,710] [,711] [,712] [,713] [,714]
[1,]      6      2      4      4      4      5      2      1      4      2      1      4      2      1
     [,715] [,716] [,717] [,718] [,719] [,720] [,721] [,722] [,723] [,724] [,725] [,726] [,727] [,728]
[1,]      1      1      2      6      1      3      6      5      3      3      6      4      2      4
     [,729] [,730] [,731] [,732] [,733] [,734] [,735] [,736] [,737] [,738] [,739] [,740] [,741] [,742]
[1,]      1      1      4      6      2      3      4      4      1      4      3      3      5      4
     [,743] [,744] [,745] [,746] [,747] [,748] [,749] [,750] [,751] [,752] [,753] [,754] [,755] [,756]
[1,]      1      2      5      4      2      4      4      4      6      6      2      5      5      5
     [,757] [,758] [,759] [,760] [,761] [,762] [,763] [,764] [,765] [,766] [,767] [,768] [,769] [,770]
[1,]      1      5      1      3      2      1      2      3      3      5      6      4      5      2
     [,771] [,772] [,773] [,774] [,775] [,776] [,777] [,778] [,779] [,780] [,781] [,782] [,783] [,784]
[1,]      2      2      5      6      1      3      3      6      6      3      1      1      3      3
     [,785] [,786] [,787] [,788] [,789] [,790] [,791] [,792] [,793] [,794] [,795] [,796] [,797] [,798]
[1,]      5      5      2      1      6      4      5      3      2      2      6      1      3      1
     [,799] [,800] [,801] [,802] [,803] [,804] [,805] [,806] [,807] [,808] [,809] [,810] [,811] [,812]
[1,]      5      4      3      2      1      3      6      2      3      1      3      4      2      6
     [,813] [,814] [,815] [,816] [,817] [,818] [,819] [,820] [,821] [,822] [,823] [,824] [,825] [,826]
[1,]      6      3      1      6      3      2      4      6      1      5      1      3      2      2
     [,827] [,828] [,829] [,830] [,831] [,832] [,833] [,834] [,835] [,836] [,837] [,838] [,839] [,840]
[1,]      2      1      5      2      1      6      3      6      3      1      6      1      1      6
     [,841] [,842] [,843] [,844] [,845] [,846] [,847] [,848] [,849] [,850] [,851] [,852] [,853] [,854]
[1,]      5      3      4      1      2      6      4      4      6      5      1      2      2      4
     [,855] [,856] [,857] [,858] [,859] [,860] [,861] [,862] [,863] [,864] [,865] [,866] [,867] [,868]
[1,]      2      5      4      1      5      2      6      2      5      4      1      3      4      4
     [,869] [,870] [,871] [,872] [,873] [,874] [,875] [,876] [,877] [,878] [,879] [,880] [,881] [,882]
[1,]      4      3      1      3      6      6      2      1      1      4      6      2      2      4
     [,883] [,884] [,885] [,886] [,887] [,888] [,889] [,890] [,891] [,892] [,893] [,894] [,895] [,896]
[1,]      2      2      2      5      6      6      2      4      4      1      1      5      1      3
     [,897] [,898] [,899] [,900] [,901] [,902] [,903] [,904] [,905] [,906] [,907] [,908] [,909] [,910]
[1,]      4      3      5      5      1      2      4      6      1      2      3      1      5      1
     [,911] [,912] [,913] [,914] [,915] [,916] [,917] [,918] [,919] [,920] [,921] [,922] [,923] [,924]
[1,]      4      1      6      5      3      1      5      4      1      2      2      2      2      5
     [,925] [,926] [,927] [,928] [,929] [,930] [,931] [,932] [,933] [,934] [,935] [,936] [,937] [,938]
[1,]      5      5      2      4      6      4      5      4      4      1      6      2      6      5
     [,939] [,940] [,941] [,942] [,943] [,944] [,945] [,946] [,947] [,948] [,949] [,950] [,951] [,952]
[1,]      5      5      3      4      1      1      2      4      6      6      2      3      6      5
     [,953] [,954] [,955] [,956] [,957] [,958] [,959] [,960] [,961] [,962] [,963] [,964] [,965] [,966]
[1,]      4      1      6      5      1      2      6      4      3      2      5      1      2      2
     [,967] [,968] [,969] [,970] [,971] [,972] [,973] [,974] [,975] [,976] [,977] [,978] [,979] [,980]
[1,]      4      1      6      6      5      1      2      5      6      3      3      4      3      3
     [,981] [,982] [,983] [,984] [,985] [,986] [,987] [,988] [,989] [,990] [,991] [,992] [,993] [,994]
[1,]      4      3      3      1      4      2      6      2      1      1      3      5      6      6
     [,995] [,996] [,997] [,998] [,999] [,1000]
[1,]      3      4      1      5      3       3
 [ reached 'max' / getOption("max.print") -- omitted 5 rows and 9000 columns ]
txt> head(x)

 ## now raw values can be used to calculate mean in the z score formula 

txt> txtComment("## now raw values can be used to calculate mean in the z score formula")
txt> z <- (mean(x == 6) - p)/sqrt(p * (1 - p)/10000)
txt> z <- (mean(x == 6) - p)/sqrt(p * (1 - p)/10000)
txt> z
[1] -0.008944272
txt> z

 ## mean() is another way of defining 'proportion' bc it's the wanted value divided by the overall number of values in the dataset. same with p: 1 divided by 6 total numbers in the dice. by subtracting p from x, you are *comparing how far the observed proportion/probability is from the expected proportion/probability* 

txt> txtComment("## mean() is another way of defining 'proportion' bc it's the wanted value divided by the overall number of values in the dataset. same with p: 1 divided by 6 total numbers in the dice. by subtracting p from x, you are *comparing how far the observed proportion/probability is from the expected proportion/probability*")

 ## therefore, our observed probability was slightly less than the expected mean of 1/6 (0.16666), hence the negative z score 

txt> txtComment("## therefore, our observed probability was slightly less than the expected mean of 1/6 (0.16666), hence the negative z score")

 **and report what proportion of times z was larger than 2 in absolute value (CLT says it should be about 0.05)** 

txt> txtComment("**and report what proportion of times z was larger than 2 in absolute value (CLT says it should be about 0.05)**")
txt> mean(z > 2)
[1] 0
txt> mean(z > 2)
txt> head(z)
[1] -0.008944272
txt> head(z)
txt> x <- sample(1:6, 10000, replace = TRUE)
txt> x <- sample(1:6, 10000, replace = TRUE)
txt> head(x)
[1] 5 2 4 4 1 6
txt> head(x)
txt> set.seed(1)
txt> set.seed(1)
txt> x <- sample(1:6, 10000, replace = TRUE)
txt> x <- sample(1:6, 10000, replace = TRUE)
txt> head(x)
[1] 1 4 1 2 5 3
txt> head(x)
txt> head(x)
[1] 1 4 1 2 5 3
txt> head(x)
txt> x = sample(1:6, 10000, replace = TRUE)
txt> x = sample(1:6, 10000, replace = TRUE)
txt> head(x)
[1] 1 6 1 4 1 3
txt> head(x)
txt> head(x)
[1] 1 6 1 4 1 3
txt> head(x)
txt> x <- replicate(10000, sample(1:6, replace = TRUE))
txt> x <- replicate(10000, sample(1:6, replace = TRUE))
txt> head(x)
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15] [,16] [,17] [,18]
[1,]    5    6    3    4    1    6    5    5    4     1     2     1     4     6     6     3     3     1
     [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34]
[1,]     6     1     4     5     2     5     1     5     3     3     2     3     6     2     3     1
     [,35] [,36] [,37] [,38] [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]
[1,]     2     2     4     6     1     2     5     1     5     4     4     4     4     2     5     4
     [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62] [,63] [,64] [,65] [,66]
[1,]     6     2     3     1     1     6     6     1     2     4     3     6     1     6     2     1
     [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74] [,75] [,76] [,77] [,78] [,79] [,80] [,81] [,82]
[1,]     5     3     1     3     2     1     6     5     5     2     1     4     5     6     1     1
     [,83] [,84] [,85] [,86] [,87] [,88] [,89] [,90] [,91] [,92] [,93] [,94] [,95] [,96] [,97] [,98]
[1,]     4     3     2     4     4     1     5     2     5     4     2     2     1     5     1     1
     [,99] [,100] [,101] [,102] [,103] [,104] [,105] [,106] [,107] [,108] [,109] [,110] [,111] [,112]
[1,]     2      6      6      4      3      6      3      3      5      2      2      6      5      3
     [,113] [,114] [,115] [,116] [,117] [,118] [,119] [,120] [,121] [,122] [,123] [,124] [,125] [,126]
[1,]      1      6      5      6      3      2      6      5      4      2      6      2      2      6
     [,127] [,128] [,129] [,130] [,131] [,132] [,133] [,134] [,135] [,136] [,137] [,138] [,139] [,140]
[1,]      5      6      1      5      6      1      5      5      4      1      4      1      5      5
     [,141] [,142] [,143] [,144] [,145] [,146] [,147] [,148] [,149] [,150] [,151] [,152] [,153] [,154]
[1,]      1      2      6      3      5      3      3      5      4      1      6      2      1      6
     [,155] [,156] [,157] [,158] [,159] [,160] [,161] [,162] [,163] [,164] [,165] [,166] [,167] [,168]
[1,]      1      1      1      5      3      5      1      4      4      6      3      4      3      1
     [,169] [,170] [,171] [,172] [,173] [,174] [,175] [,176] [,177] [,178] [,179] [,180] [,181] [,182]
[1,]      1      4      1      2      1      1      6      2      3      4      1      1      3      5
     [,183] [,184] [,185] [,186] [,187] [,188] [,189] [,190] [,191] [,192] [,193] [,194] [,195] [,196]
[1,]      4      6      5      4      4      6      1      1      3      6      4      4      3      5
     [,197] [,198] [,199] [,200] [,201] [,202] [,203] [,204] [,205] [,206] [,207] [,208] [,209] [,210]
[1,]      1      4      1      1      2      1      1      1      5      4      1      6      1      5
     [,211] [,212] [,213] [,214] [,215] [,216] [,217] [,218] [,219] [,220] [,221] [,222] [,223] [,224]
[1,]      1      1      6      1      2      6      2      4      4      2      4      1      4      6
     [,225] [,226] [,227] [,228] [,229] [,230] [,231] [,232] [,233] [,234] [,235] [,236] [,237] [,238]
[1,]      6      6      6      2      6      3      5      6      5      6      4      6      6      1
     [,239] [,240] [,241] [,242] [,243] [,244] [,245] [,246] [,247] [,248] [,249] [,250] [,251] [,252]
[1,]      6      6      6      5      2      4      5      2      2      4      3      3      5      6
     [,253] [,254] [,255] [,256] [,257] [,258] [,259] [,260] [,261] [,262] [,263] [,264] [,265] [,266]
[1,]      6      1      6      6      3      4      3      3      3      5      6      1      1      3
     [,267] [,268] [,269] [,270] [,271] [,272] [,273] [,274] [,275] [,276] [,277] [,278] [,279] [,280]
[1,]      6      4      6      4      6      6      2      3      1      6      5      4      2      2
     [,281] [,282] [,283] [,284] [,285] [,286] [,287] [,288] [,289] [,290] [,291] [,292] [,293] [,294]
[1,]      4      5      4      3      5      5      5      3      4      4      1      4      3      2
     [,295] [,296] [,297] [,298] [,299] [,300] [,301] [,302] [,303] [,304] [,305] [,306] [,307] [,308]
[1,]      2      5      6      2      4      1      3      1      6      3      2      3      4      2
     [,309] [,310] [,311] [,312] [,313] [,314] [,315] [,316] [,317] [,318] [,319] [,320] [,321] [,322]
[1,]      5      3      5      6      6      3      2      3      4      2      2      6      3      4
     [,323] [,324] [,325] [,326] [,327] [,328] [,329] [,330] [,331] [,332] [,333] [,334] [,335] [,336]
[1,]      4      5      5      1      2      5      3      4      1      5      5      5      4      3
     [,337] [,338] [,339] [,340] [,341] [,342] [,343] [,344] [,345] [,346] [,347] [,348] [,349] [,350]
[1,]      5      4      1      4      3      4      3      4      2      6      4      2      4      3
     [,351] [,352] [,353] [,354] [,355] [,356] [,357] [,358] [,359] [,360] [,361] [,362] [,363] [,364]
[1,]      5      3      1      4      4      3      1      3      6      3      2      6      6      4
     [,365] [,366] [,367] [,368] [,369] [,370] [,371] [,372] [,373] [,374] [,375] [,376] [,377] [,378]
[1,]      4      1      5      1      6      5      6      4      1      1      3      6      6      2
     [,379] [,380] [,381] [,382] [,383] [,384] [,385] [,386] [,387] [,388] [,389] [,390] [,391] [,392]
[1,]      4      5      5      1      4      5      6      6      6      2      1      6      5      3
     [,393] [,394] [,395] [,396] [,397] [,398] [,399] [,400] [,401] [,402] [,403] [,404] [,405] [,406]
[1,]      2      4      5      4      5      6      5      4      1      1      4      2      5      4
     [,407] [,408] [,409] [,410] [,411] [,412] [,413] [,414] [,415] [,416] [,417] [,418] [,419] [,420]
[1,]      3      3      5      3      6      6      4      2      1      2      5      2      6      1
     [,421] [,422] [,423] [,424] [,425] [,426] [,427] [,428] [,429] [,430] [,431] [,432] [,433] [,434]
[1,]      1      3      6      4      6      2      4      5      1      1      2      3      2      2
     [,435] [,436] [,437] [,438] [,439] [,440] [,441] [,442] [,443] [,444] [,445] [,446] [,447] [,448]
[1,]      1      6      4      2      6      4      4      5      4      2      5      2      1      6
     [,449] [,450] [,451] [,452] [,453] [,454] [,455] [,456] [,457] [,458] [,459] [,460] [,461] [,462]
[1,]      3      1      2      6      1      5      3      5      3      4      6      6      4      4
     [,463] [,464] [,465] [,466] [,467] [,468] [,469] [,470] [,471] [,472] [,473] [,474] [,475] [,476]
[1,]      4      1      6      3      4      2      6      2      3      1      5      2      4      2
     [,477] [,478] [,479] [,480] [,481] [,482] [,483] [,484] [,485] [,486] [,487] [,488] [,489] [,490]
[1,]      2      3      4      3      2      6      4      4      4      6      3      3      5      5
     [,491] [,492] [,493] [,494] [,495] [,496] [,497] [,498] [,499] [,500] [,501] [,502] [,503] [,504]
[1,]      2      2      4      6      5      1      3      6      4      3      2      5      4      2
     [,505] [,506] [,507] [,508] [,509] [,510] [,511] [,512] [,513] [,514] [,515] [,516] [,517] [,518]
[1,]      5      3      6      6      2      6      4      3      3      4      3      4      6      2
     [,519] [,520] [,521] [,522] [,523] [,524] [,525] [,526] [,527] [,528] [,529] [,530] [,531] [,532]
[1,]      4      4      1      6      3      6      6      5      5      1      5      6      1      2
     [,533] [,534] [,535] [,536] [,537] [,538] [,539] [,540] [,541] [,542] [,543] [,544] [,545] [,546]
[1,]      5      1      2      2      3      3      1      3      2      1      3      2      2      4
     [,547] [,548] [,549] [,550] [,551] [,552] [,553] [,554] [,555] [,556] [,557] [,558] [,559] [,560]
[1,]      3      6      5      4      4      3      2      6      4      4      4      5      1      4
     [,561] [,562] [,563] [,564] [,565] [,566] [,567] [,568] [,569] [,570] [,571] [,572] [,573] [,574]
[1,]      1      3      5      5      4      6      5      3      2      1      2      1      1      4
     [,575] [,576] [,577] [,578] [,579] [,580] [,581] [,582] [,583] [,584] [,585] [,586] [,587] [,588]
[1,]      4      6      4      1      2      6      6      1      2      1      5      1      5      3
     [,589] [,590] [,591] [,592] [,593] [,594] [,595] [,596] [,597] [,598] [,599] [,600] [,601] [,602]
[1,]      1      5      6      5      4      3      1      3      6      3      1      2      1      2
     [,603] [,604] [,605] [,606] [,607] [,608] [,609] [,610] [,611] [,612] [,613] [,614] [,615] [,616]
[1,]      3      5      2      5      1      4      2      5      2      2      6      1      3      5
     [,617] [,618] [,619] [,620] [,621] [,622] [,623] [,624] [,625] [,626] [,627] [,628] [,629] [,630]
[1,]      1      4      2      4      5      6      2      6      4      2      5      1      1      6
     [,631] [,632] [,633] [,634] [,635] [,636] [,637] [,638] [,639] [,640] [,641] [,642] [,643] [,644]
[1,]      3      2      5      5      5      6      2      1      1      3      5      6      1      5
     [,645] [,646] [,647] [,648] [,649] [,650] [,651] [,652] [,653] [,654] [,655] [,656] [,657] [,658]
[1,]      5      1      4      4      6      1      5      6      4      6      2      4      6      5
     [,659] [,660] [,661] [,662] [,663] [,664] [,665] [,666] [,667] [,668] [,669] [,670] [,671] [,672]
[1,]      2      1      6      4      5      4      5      1      2      3      5      1      1      2
     [,673] [,674] [,675] [,676] [,677] [,678] [,679] [,680] [,681] [,682] [,683] [,684] [,685] [,686]
[1,]      5      5      5      6      6      3      2      2      5      3      1      2      2      3
     [,687] [,688] [,689] [,690] [,691] [,692] [,693] [,694] [,695] [,696] [,697] [,698] [,699] [,700]
[1,]      4      6      2      2      2      5      1      6      5      4      6      3      3      2
     [,701] [,702] [,703] [,704] [,705] [,706] [,707] [,708] [,709] [,710] [,711] [,712] [,713] [,714]
[1,]      1      5      3      5      1      3      1      3      4      1      4      3      6      3
     [,715] [,716] [,717] [,718] [,719] [,720] [,721] [,722] [,723] [,724] [,725] [,726] [,727] [,728]
[1,]      3      2      4      1      4      5      4      6      3      5      4      5      6      2
     [,729] [,730] [,731] [,732] [,733] [,734] [,735] [,736] [,737] [,738] [,739] [,740] [,741] [,742]
[1,]      2      5      5      1      2      3      2      4      3      4      2      2      5      2
     [,743] [,744] [,745] [,746] [,747] [,748] [,749] [,750] [,751] [,752] [,753] [,754] [,755] [,756]
[1,]      5      1      2      2      1      3      3      4      2      4      4      5      3      3
     [,757] [,758] [,759] [,760] [,761] [,762] [,763] [,764] [,765] [,766] [,767] [,768] [,769] [,770]
[1,]      4      5      6      4      4      3      1      6      5      2      5      5      5      1
     [,771] [,772] [,773] [,774] [,775] [,776] [,777] [,778] [,779] [,780] [,781] [,782] [,783] [,784]
[1,]      5      1      6      2      2      2      3      3      3      1      3      4      3      1
     [,785] [,786] [,787] [,788] [,789] [,790] [,791] [,792] [,793] [,794] [,795] [,796] [,797] [,798]
[1,]      6      3      2      3      2      5      6      4      4      6      4      3      3      3
     [,799] [,800] [,801] [,802] [,803] [,804] [,805] [,806] [,807] [,808] [,809] [,810] [,811] [,812]
[1,]      6      6      1      6      3      2      3      3      6      2      2      1      6      3
     [,813] [,814] [,815] [,816] [,817] [,818] [,819] [,820] [,821] [,822] [,823] [,824] [,825] [,826]
[1,]      4      4      2      3      3      3      5      6      3      5      2      2      5      1
     [,827] [,828] [,829] [,830] [,831] [,832] [,833] [,834] [,835] [,836] [,837] [,838] [,839] [,840]
[1,]      5      1      3      1      5      6      4      3      4      6      4      6      2      3
     [,841] [,842] [,843] [,844] [,845] [,846] [,847] [,848] [,849] [,850] [,851] [,852] [,853] [,854]
[1,]      1      3      5      6      3      6      1      2      6      3      6      4      4      1
     [,855] [,856] [,857] [,858] [,859] [,860] [,861] [,862] [,863] [,864] [,865] [,866] [,867] [,868]
[1,]      3      3      6      6      1      1      1      1      1      6      3      6      5      5
     [,869] [,870] [,871] [,872] [,873] [,874] [,875] [,876] [,877] [,878] [,879] [,880] [,881] [,882]
[1,]      2      5      3      6      4      6      4      2      5      3      1      4      6      1
     [,883] [,884] [,885] [,886] [,887] [,888] [,889] [,890] [,891] [,892] [,893] [,894] [,895] [,896]
[1,]      5      3      4      5      1      2      6      1      1      6      6      6      5      6
     [,897] [,898] [,899] [,900] [,901] [,902] [,903] [,904] [,905] [,906] [,907] [,908] [,909] [,910]
[1,]      6      4      3      5      1      1      2      3      6      2      6      5      5      2
     [,911] [,912] [,913] [,914] [,915] [,916] [,917] [,918] [,919] [,920] [,921] [,922] [,923] [,924]
[1,]      1      3      2      4      6      3      4      6      2      2      1      2      2      1
     [,925] [,926] [,927] [,928] [,929] [,930] [,931] [,932] [,933] [,934] [,935] [,936] [,937] [,938]
[1,]      3      3      6      4      4      4      3      5      6      5      2      3      2      6
     [,939] [,940] [,941] [,942] [,943] [,944] [,945] [,946] [,947] [,948] [,949] [,950] [,951] [,952]
[1,]      5      4      5      2      5      4      5      6      5      4      6      3      1      6
     [,953] [,954] [,955] [,956] [,957] [,958] [,959] [,960] [,961] [,962] [,963] [,964] [,965] [,966]
[1,]      1      2      5      1      1      1      1      4      4      4      2      2      2      1
     [,967] [,968] [,969] [,970] [,971] [,972] [,973] [,974] [,975] [,976] [,977] [,978] [,979] [,980]
[1,]      6      1      3      3      2      6      5      6      1      1      4      4      6      1
     [,981] [,982] [,983] [,984] [,985] [,986] [,987] [,988] [,989] [,990] [,991] [,992] [,993] [,994]
[1,]      1      6      5      1      3      5      6      6      4      6      6      2      4      1
     [,995] [,996] [,997] [,998] [,999] [,1000]
[1,]      6      1      3      1      2       4
 [ reached 'max' / getOption("max.print") -- omitted 5 rows and 9000 columns ]
txt> head(x)
txt> set.seed(1)
txt> set.seed(1)
txt> x <- replicate(10000, sample(1:6, replace = TRUE))
txt> x <- replicate(10000, sample(1:6, replace = TRUE))
txt> z <- (mean(x == 6) - p)/sqrt(p * (1 - p)/10000)
txt> z <- (mean(x == 6) - p)/sqrt(p * (1 - p)/10000)
txt> z
[1] -0.008944272
txt> z

 ## cannot answer last part of q because i didn't do sampling size correctly: we roll dice n times (n = 100), and perform the *simulation 10,000* times 

txt> txtComment("## cannot answer last part of q because i didn't do sampling size correctly: we roll dice n times (n = 100), and perform the *simulation 10,000* times")
txt> set.seed(1)
txt> set.seed(1)
txt> x <- sample(1:6, 100, replace = TRUE)
txt> x <- sample(1:6, 100, replace = TRUE)

 ## then get the mean of each sample, repeated 10000 times 

txt> txtComment("## then get the mean of each sample, repeated 10000 times")
txt> replicate(10000, mean(x == 6))
   [1] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
  [20] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
  [39] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
  [58] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
  [77] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
  [96] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [115] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [134] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [153] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [172] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [191] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [210] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [229] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [248] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [267] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [286] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [305] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [324] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [343] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [362] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [381] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [400] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [419] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [438] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [457] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [476] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [495] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [514] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [533] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [552] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [571] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [590] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [609] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [628] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [647] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [666] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [685] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [704] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [723] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [742] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [761] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [780] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [799] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [818] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [837] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [856] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [875] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [894] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [913] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [932] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [951] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [970] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [989] 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 [ reached 'max' / getOption("max.print") -- omitted 9000 entries ]
txt> replicate(10000, mean(x == 6))
txt> Ns <- 1:6
txt> Ns <- 1:6
txt> Ns
[1] 1 2 3 4 5 6
txt> Ns
txt> set.seed(1)
txt> set.seed(1)
txt> res <- sapply(Ns, function(n) {
txt+ replicate(10000, mean(sample(1:6, 100, replace = TRUE)))
txt+ })
txt> res <- sapply(Ns, function(n) {
txt+ replicate(10000, mean(sample(1:6, 100, replace = TRUE)))
txt+ })
txt> head(res)
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,] 3.52 3.57 3.35 3.36 3.48 3.54
[2,] 3.33 3.35 3.55 3.69 3.48 3.39
[3,] 3.64 3.58 3.43 3.55 3.60 3.41
[4,] 3.34 3.70 3.33 3.47 3.80 3.36
[5,] 3.63 3.34 3.35 3.63 3.62 3.36
[6,] 3.61 3.23 3.49 3.51 3.68 3.68
txt> head(res)

 ## still can't calculate z score because no integer values to select x == 6 

txt> txtComment("## still can't calculate z score because no integer values to select x == 6")

 ## need to integrate z formula into function(n) 

txt> txtComment("## need to integrate z formula into function(n)")

 ## need to replicate the following 10,000x in {sub} curly brackets: create sample(1:6), roll dice 100x --> then calculate the mean value of each of those 100 die rolls (mean==6) --> then use that to calculate z score  

txt> txtComment("## need to replicate the following 10,000x in {sub
txt+ } curly brackets: create sample(1:6), roll dice 100x --> then calculate the mean value of each of those 100 die rolls (mean==6) --> then use that to calculate z score ")
txt> res <- replicate(10000, {
txt+ x <- sample(1:6, 100, replace = TRUE)
txt+ a <- mean(x == 6)
txt+ z <- (a - p)/sqrt(p * (1 - p)/n)
txt+ })
txt> res <- replicate(10000, {
txt+ x <- sample(1:6, 100, replace = TRUE)
txt+ a <- mean(x == 6)
txt+ z <- (a - p)/sqrt(p * (1 - p)/n)
txt+ })
txt> head(res)
[1] 0.49574187 0.96049987 0.03098387 0.49574187 0.21688707 0.49574187
txt> head(res)

 ## now we have 10,000 z scores 

txt> txtComment("## now we have 10,000 z scores")

 ## in the replicate() simulation:
replicate(10000, { ... will open a curly brackets to tell R to repeat the following 10,000 times
x <- sample(1:6, 100, replace = TRUE)... will define x as the data frame of 100 different values, all ranging from integers 1-6 (with hopefully 1/6 of them being 6s)
a <- mean(x==6)... this pulls the average number of 6s (to confirm if we hopefully have about 1/6 of them as 6s). this will also be used for the z score formula next
z <- (a-p)... i.e. see how far the observed proportion is from the expected proportion (1/6)
/ sqrt(p*p(1-p)/n)... divide the above by the standard error to get the standardised z score, of mean = 0 and SD 1
 

txt> txtComment("## in the replicate() simulation:\nreplicate(10000, { ... will open a curly brackets to tell R to repeat the following 10,000 times\nx <- sample(1:6, 100, replace = TRUE)... will define x as the data frame of 100 different values, all ranging from integers 1-6 (with hopefully 1/6 of them being 6s)\na <- mean(x==6)... this pulls the average number of 6s (to confirm if we hopefully have about 1/6 of them as 6s). this will also be used for the z score formula next\nz <- (a-p)... i.e. see how far the observed proportion is from the expected proportion (1/6)\n/ sqrt(p*p(1-p)/n)... divide the above by the standard error to get the standardised z score, of mean = 0 and SD 1\n")

 ** and report what proportion of times z was larger than 2 in absolute value (CLT says it should be about 0.05).** 

txt> txtComment("** and report what proportion of times z was larger than 2 in absolute value (CLT says it should be about 0.05).**")

 ## the above res variable gave a value of 10,000 different z scores. use it to filter the values that res > 2 

txt> txtComment("## the above res variable gave a value of 10,000 different z scores. use it to filter the values that res > 2")
txt> res > 2
   [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
  [17] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
  [33] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
  [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
  [65] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
  [81] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
  [97] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [113] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [129] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [145] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [161] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [177] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [193] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [209] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [225] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [241] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [257] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [273] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [289] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [305] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [321] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [337] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [353] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [369] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [385] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [401] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [417] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [433] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [449] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [465] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [481] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [497] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [513] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [529] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [545] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [561] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [577] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [593] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [609] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [625] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [641] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [657] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [673] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [689] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [705] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [721] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [737] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [753] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [769] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [785] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [801] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [817] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [833] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [849] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [865] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [881] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [897] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [913] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [929] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [945] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [961] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [977] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [993] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
 [ reached 'max' / getOption("max.print") -- omitted 9000 entries ]
txt> res > 2
txt> sum(res > 2)
[1] 0
txt> sum(res > 2)
txt> head(res)
[1] 0.49574187 0.96049987 0.03098387 0.49574187 0.21688707 0.49574187
txt> head(res)
txt> mean(res > 2)
[1] 0
txt> mean(res > 2)
txt> mean(abs(res > 2))
[1] 0
txt> mean(abs(res > 2))
txt> set.seed(1)
txt> set.seed(1)
txt> replicate(10000, {
txt+ x <- sample(1:6, 100, replace = TRUE)
txt+ a <- mean(x == 6)
txt+ z <- (a - p)/sqrt(p * (1 - p)/n)
txt+ })
   [1]  0.40279027 -0.34082253  0.12393547 -0.52672574  0.12393547  0.03098387 -0.15491933  0.40279027
   [9] -0.06196773 -0.24787093  0.21688707 -0.24787093 -0.06196773 -0.06196773  0.30983867  0.03098387
  [17]  0.30983867 -0.06196773 -0.34082253 -0.52672574 -0.15491933 -0.43377413  0.40279027 -0.06196773
  [25] -0.06196773 -0.06196773 -0.43377413 -0.15491933  0.30983867  0.68164507  0.68164507  0.68164507
  [33] -0.24787093 -0.34082253  0.40279027  0.21688707  0.96049987  0.03098387  0.21688707 -0.61967734
  [41] -0.06196773  0.30983867  0.12393547  0.03098387 -0.06196773 -0.06196773 -0.06196773 -0.52672574
  [49] -0.15491933 -0.15491933 -0.06196773  0.21688707 -0.15491933 -0.06196773  0.03098387 -0.06196773
  [57]  0.40279027  0.21688707 -0.34082253  0.77459667  0.12393547  0.12393547  0.21688707  0.58869347
  [65] -0.24787093 -0.15491933  0.49574187 -0.71262894  0.03098387  0.49574187 -0.24787093 -0.43377413
  [73] -0.43377413 -0.15491933 -0.24787093  0.03098387 -0.15491933  0.12393547 -0.34082253 -0.06196773
  [81] -0.52672574 -0.52672574 -0.34082253 -0.52672574 -0.06196773  0.21688707  0.21688707  0.77459667
  [89] -0.34082253 -0.34082253 -0.15491933  0.58869347  0.49574187 -0.43377413  0.03098387 -0.15491933
  [97] -0.06196773 -0.15491933  0.03098387 -0.15491933  0.30983867  0.03098387 -0.15491933 -0.34082253
 [105] -0.15491933  0.12393547 -0.06196773 -0.71262894 -1.08443534 -0.15491933  0.30983867 -0.52672574
 [113]  0.21688707 -0.06196773  0.03098387  0.03098387 -0.52672574  0.68164507  0.58869347 -0.34082253
 [121]  0.12393547 -0.15491933 -0.06196773  0.03098387 -0.34082253 -0.71262894 -0.43377413 -0.34082253
 [129] -0.43377413 -0.06196773  0.58869347  0.03098387 -0.52672574  0.12393547 -0.34082253 -0.15491933
 [137]  0.21688707  0.12393547  0.21688707  0.86754827 -0.34082253 -0.24787093  0.12393547  0.30983867
 [145] -0.15491933 -0.61967734 -0.24787093  0.49574187  0.03098387  0.40279027 -0.34082253 -0.52672574
 [153]  0.49574187 -0.52672574 -0.06196773  0.21688707 -0.61967734  0.12393547 -0.06196773  0.21688707
 [161]  0.12393547 -0.52672574 -0.24787093 -0.43377413  0.30983867 -0.80558054  0.03098387 -0.80558054
 [169]  0.40279027  0.49574187 -0.24787093  0.12393547  0.21688707 -0.43377413  0.12393547 -0.15491933
 [177]  0.68164507  0.77459667 -0.06196773 -0.61967734 -0.52672574  0.49574187  0.30983867  0.03098387
 [185]  0.58869347  0.21688707 -0.24787093  0.12393547 -0.34082253 -0.71262894  0.40279027  0.03098387
 [193]  0.30983867  0.21688707 -0.24787093 -0.34082253 -0.15491933 -0.06196773 -0.15491933  0.12393547
 [201] -0.34082253  0.03098387 -0.24787093  0.12393547  0.03098387 -0.15491933  0.03098387  0.49574187
 [209] -0.34082253 -0.15491933 -0.06196773  0.03098387  0.21688707  0.58869347  0.49574187  0.68164507
 [217] -0.15491933 -0.15491933  0.03098387 -0.15491933 -0.06196773  0.40279027 -0.06196773  0.21688707
 [225] -0.52672574 -0.34082253 -0.34082253 -0.06196773 -0.15491933 -0.06196773  0.30983867  0.68164507
 [233] -0.06196773 -0.52672574  0.30983867  0.21688707 -0.15491933  0.03098387  0.03098387 -0.52672574
 [241]  0.03098387 -0.43377413 -0.06196773 -0.06196773 -0.15491933 -0.24787093 -0.52672574  0.03098387
 [249]  0.03098387  0.40279027 -0.34082253  0.12393547 -0.61967734  0.40279027 -0.15491933  0.03098387
 [257]  0.21688707  0.03098387  0.21688707  0.40279027  0.03098387 -0.52672574 -0.24787093 -0.52672574
 [265]  0.12393547  0.30983867  0.03098387 -0.06196773  0.12393547 -0.06196773  0.58869347  0.12393547
 [273]  0.12393547  0.58869347 -0.34082253  0.12393547  0.03098387  0.21688707 -0.71262894  0.58869347
 [281] -0.43377413 -0.15491933  0.49574187 -0.61967734  0.12393547  0.12393547 -0.15491933  0.12393547
 [289] -0.52672574  0.40279027 -0.80558054 -0.24787093 -0.24787093  0.49574187 -0.15491933  0.12393547
 [297] -0.06196773  0.68164507 -0.15491933 -0.61967734  0.21688707  1.51820947 -0.43377413  0.30983867
 [305]  0.30983867  0.03098387  0.40279027  0.03098387 -0.34082253 -0.15491933 -0.24787093 -0.15491933
 [313]  0.03098387  0.03098387 -0.34082253  0.03098387 -0.43377413 -0.52672574  0.03098387 -0.43377413
 [321] -0.15491933 -0.06196773  0.40279027  0.03098387 -0.61967734  0.49574187  0.77459667 -0.34082253
 [329] -0.06196773 -0.15491933 -0.15491933 -0.34082253 -0.15491933  0.03098387  0.30983867 -0.43377413
 [337]  0.12393547  0.40279027 -0.15491933  0.12393547  1.05345147 -0.34082253 -0.24787093 -0.15491933
 [345] -0.24787093  0.12393547 -0.24787093  0.03098387 -0.34082253 -0.06196773 -0.24787093  0.21688707
 [353] -0.52672574  0.49574187 -0.24787093 -0.24787093  0.21688707 -0.15491933 -0.71262894  0.40279027
 [361] -0.34082253 -0.24787093  0.03098387  0.40279027 -0.34082253  0.21688707 -0.34082253  0.40279027
 [369] -0.15491933 -0.15491933  0.21688707  0.58869347 -0.24787093  0.68164507  0.12393547  0.86754827
 [377] -0.24787093  0.30983867  0.12393547  0.40279027  0.40279027  0.58869347  0.21688707  0.03098387
 [385] -0.06196773  0.21688707 -0.24787093  0.03098387 -0.24787093  0.58869347 -0.24787093  0.30983867
 [393]  0.30983867  0.21688707  0.40279027  1.14640307 -0.06196773 -0.43377413  0.03098387 -0.06196773
 [401]  0.58869347  0.49574187 -0.34082253  0.40279027 -0.06196773 -0.43377413  0.21688707 -0.61967734
 [409] -0.15491933  0.58869347 -0.15491933  0.12393547 -0.06196773 -0.52672574  0.86754827 -0.06196773
 [417]  0.68164507 -0.06196773 -0.06196773 -0.06196773 -0.34082253 -0.34082253 -0.15491933 -0.52672574
 [425] -0.06196773  0.12393547  0.21688707  0.03098387  0.12393547 -0.61967734 -0.43377413 -0.15491933
 [433]  0.03098387 -0.43377413  0.40279027 -0.15491933 -0.06196773  0.49574187  0.03098387  0.30983867
 [441]  0.40279027  0.58869347 -0.24787093  0.12393547 -0.61967734 -0.43377413  0.03098387  0.03098387
 [449]  0.03098387 -0.06196773  0.96049987 -0.15491933  0.49574187  0.12393547 -0.34082253  0.40279027
 [457] -0.15491933  0.40279027  0.58869347  0.21688707 -0.06196773 -0.24787093  0.12393547  0.77459667
 [465]  0.12393547  0.12393547  0.12393547  0.77459667  0.49574187  0.21688707  0.49574187 -0.15491933
 [473] -0.71262894  0.58869347  0.49574187 -0.71262894  0.21688707  0.03098387  0.49574187 -0.24787093
 [481] -0.06196773  0.49574187  0.21688707  0.12393547  0.12393547  0.03098387  0.30983867  0.30983867
 [489] -0.06196773 -0.15491933  0.12393547  0.30983867  0.30983867  0.68164507  0.12393547 -0.06196773
 [497]  0.03098387  0.12393547  0.03098387 -0.34082253 -0.24787093 -0.71262894 -0.15491933 -0.06196773
 [505] -0.06196773  0.49574187  0.12393547  0.30983867  0.40279027 -0.61967734  0.21688707 -0.15491933
 [513] -0.24787093 -0.24787093  0.12393547 -0.34082253  0.21688707  0.03098387 -0.24787093 -0.15491933
 [521]  0.12393547 -0.34082253 -0.34082253 -0.43377413  0.21688707  0.03098387 -0.52672574  0.03098387
 [529] -0.43377413  0.49574187  0.40279027 -0.15491933 -0.15491933 -0.24787093  0.40279027 -0.24787093
 [537]  0.03098387  0.03098387 -0.34082253  0.03098387  0.12393547  0.12393547 -0.24787093 -0.06196773
 [545]  0.40279027  0.03098387 -0.24787093  0.21688707  0.40279027  0.58869347 -0.24787093  0.58869347
 [553] -0.34082253  0.21688707 -0.52672574  0.21688707 -0.15491933  0.68164507  0.40279027  0.21688707
 [561] -0.34082253  0.21688707 -0.80558054 -0.24787093 -0.24787093 -0.15491933 -0.06196773 -0.99148374
 [569]  0.03098387  0.40279027 -0.15491933 -0.15491933 -0.24787093 -0.24787093 -0.43377413 -0.06196773
 [577] -0.24787093  0.12393547  0.12393547 -0.71262894  0.40279027  0.21688707  0.49574187  0.12393547
 [585]  0.49574187  0.12393547 -0.06196773 -0.15491933 -0.43377413 -0.34082253 -0.34082253 -0.34082253
 [593] -0.15491933 -0.15491933  0.21688707 -0.06196773 -0.61967734  0.30983867  0.12393547  0.12393547
 [601]  0.12393547  0.03098387  0.03098387 -0.06196773  0.21688707 -0.71262894 -0.52672574 -0.15491933
 [609]  0.03098387  0.30983867  0.21688707 -0.06196773  0.03098387 -0.52672574  0.12393547  0.68164507
 [617] -0.43377413  0.12393547  0.40279027 -0.06196773  0.12393547 -0.24787093 -0.06196773  0.21688707
 [625] -0.52672574 -0.43377413 -0.52672574  0.21688707  0.40279027 -0.06196773  0.03098387 -0.06196773
 [633] -0.06196773  0.03098387  0.77459667  0.40279027  0.49574187 -0.06196773 -0.43377413 -0.24787093
 [641]  0.21688707  0.12393547  0.03098387  0.21688707 -0.61967734 -0.52672574 -0.43377413 -0.15491933
 [649]  0.30983867 -0.24787093  0.68164507  0.12393547  0.21688707 -0.24787093 -0.24787093 -0.06196773
 [657]  0.12393547 -0.06196773  0.30983867  0.12393547 -0.34082253 -0.06196773  0.30983867  0.68164507
 [665]  0.03098387 -0.61967734 -0.15491933 -0.24787093 -0.15491933  0.58869347  0.03098387  0.12393547
 [673] -0.06196773 -0.15491933 -0.06196773  0.21688707 -0.15491933  0.03098387 -0.71262894  0.40279027
 [681] -0.34082253  0.03098387  0.03098387  0.21688707  0.21688707  0.12393547  0.12393547  0.68164507
 [689] -0.43377413 -0.34082253 -0.52672574 -0.06196773  0.58869347  0.12393547  0.12393547 -0.24787093
 [697]  0.40279027  0.21688707 -0.06196773 -0.43377413 -0.24787093 -0.06196773  0.12393547  0.03098387
 [705] -0.06196773  0.21688707 -0.24787093  0.03098387 -0.24787093 -0.06196773 -0.06196773 -0.34082253
 [713] -0.34082253  0.30983867  0.12393547  0.03098387  0.03098387 -0.06196773 -0.15491933  0.49574187
 [721] -0.34082253  0.12393547 -0.52672574 -0.15491933  0.21688707 -0.06196773 -0.52672574  0.03098387
 [729]  0.21688707 -0.06196773  0.21688707 -0.71262894 -0.34082253 -0.15491933 -0.34082253 -0.34082253
 [737] -0.15491933 -0.06196773 -0.06196773 -0.06196773  0.30983867  0.03098387 -0.34082253 -0.61967734
 [745]  0.30983867 -0.24787093  0.21688707  0.40279027 -0.24787093  0.12393547  0.30983867  0.12393547
 [753]  0.12393547 -0.06196773  0.03098387  0.30983867  0.03098387  0.12393547  0.49574187 -0.24787093
 [761] -0.15491933 -0.15491933  0.12393547  0.21688707 -0.43377413  0.40279027  0.40279027 -0.06196773
 [769] -0.24787093  0.68164507  0.77459667 -0.06196773 -0.24787093  0.12393547  0.49574187 -0.15491933
 [777]  0.03098387 -0.15491933  0.03098387 -0.34082253  0.12393547  0.03098387  0.77459667  0.12393547
 [785]  0.21688707  0.03098387 -0.15491933 -0.34082253  0.12393547  0.40279027  0.21688707  0.30983867
 [793] -0.61967734  0.30983867  0.58869347 -0.15491933  0.40279027  0.12393547 -0.24787093 -0.71262894
 [801]  0.40279027 -0.06196773  0.21688707 -0.24787093  0.12393547 -0.15491933  0.12393547 -0.24787093
 [809] -0.24787093 -0.06196773  0.49574187  0.03098387  0.30983867 -0.34082253  0.21688707 -0.43377413
 [817] -0.06196773 -0.52672574  0.03098387  0.30983867  0.30983867  0.21688707 -0.52672574  0.49574187
 [825]  0.03098387  0.03098387  0.21688707  0.40279027 -0.15491933  0.58869347 -0.24787093  0.49574187
 [833]  0.03098387 -0.24787093 -0.43377413  0.58869347 -0.34082253 -0.15491933 -0.15491933 -0.24787093
 [841] -0.24787093  0.77459667  0.03098387  0.12393547 -0.06196773 -0.15491933  0.03098387 -0.34082253
 [849]  0.21688707 -0.52672574 -0.06196773  0.12393547  0.21688707  0.49574187  0.30983867  0.12393547
 [857] -0.52672574  0.03098387 -0.15491933 -0.15491933 -0.34082253 -0.15491933 -0.15491933  0.77459667
 [865]  1.14640307 -0.06196773 -0.15491933 -0.43377413  0.21688707 -0.24787093 -0.43377413  0.30983867
 [873] -0.06196773  0.30983867  0.40279027 -0.34082253  0.21688707 -0.06196773 -0.06196773 -0.34082253
 [881]  0.21688707  0.30983867 -0.15491933 -0.06196773 -0.06196773  0.21688707  0.21688707 -0.34082253
 [889]  0.21688707  0.12393547  0.49574187  0.68164507  0.21688707  0.21688707  0.49574187  0.49574187
 [897] -0.24787093  0.30983867 -0.61967734  0.77459667  0.21688707  0.49574187  0.68164507  0.49574187
 [905] -0.15491933  0.12393547  0.12393547 -0.34082253 -0.15491933  0.12393547  0.12393547  0.40279027
 [913]  0.03098387  0.40279027  0.30983867 -0.34082253  0.12393547  0.12393547  0.21688707  0.68164507
 [921] -0.61967734  0.21688707 -0.43377413  0.21688707 -0.43377413 -0.15491933 -0.71262894  0.03098387
 [929] -0.52672574  0.03098387 -0.89853214  0.12393547  0.68164507 -0.15491933  0.40279027 -0.34082253
 [937] -0.15491933  0.03098387  0.03098387 -0.06196773  0.21688707  0.12393547 -0.43377413 -0.06196773
 [945]  0.30983867 -0.06196773 -0.06196773  0.21688707 -0.15491933 -0.06196773  0.30983867 -0.15491933
 [953] -0.24787093  0.12393547  0.03098387  0.49574187 -0.24787093 -0.06196773  0.03098387  0.03098387
 [961]  0.40279027 -0.24787093 -0.15491933  0.12393547  0.40279027  0.40279027  0.30983867 -0.24787093
 [969] -0.24787093 -0.24787093  0.03098387 -0.34082253 -0.15491933 -0.43377413 -0.06196773 -0.06196773
 [977]  0.49574187  0.12393547 -0.43377413 -0.15491933  0.40279027  0.21688707  0.58869347 -0.24787093
 [985]  0.40279027  0.21688707 -0.24787093  0.40279027 -0.61967734  0.12393547  0.30983867  0.03098387
 [993] -0.61967734  0.21688707 -0.15491933 -0.24787093 -0.52672574  0.12393547 -0.06196773  0.21688707
 [ reached 'max' / getOption("max.print") -- omitted 9000 entries ]
txt> replicate(10000, {
txt+ x <- sample(1:6, 100, replace = TRUE)
txt+ a <- mean(x == 6)
txt+ z <- (a - p)/sqrt(p * (1 - p)/n)
txt+ })
txt> set.seed(1)
txt> set.seed(1)
txt> res <- replicate(10000, {
txt+ x <- sample(1:6, 100, replace = TRUE)
txt+ a <- mean(x == 6)
txt+ z <- (a - p)/sqrt(p * (1 - p)/n)
txt+ })
txt> res <- replicate(10000, {
txt+ x <- sample(1:6, 100, replace = TRUE)
txt+ a <- mean(x == 6)
txt+ z <- (a - p)/sqrt(p * (1 - p)/n)
txt+ })
txt> head(res)
[1]  0.40279027 -0.34082253  0.12393547 -0.52672574  0.12393547  0.03098387
txt> head(res)
txt> mean(res > 2)
[1] 0
txt> mean(res > 2)
txt> abs(res)
   [1] 0.40279027 0.34082253 0.12393547 0.52672574 0.12393547 0.03098387 0.15491933 0.40279027
   [9] 0.06196773 0.24787093 0.21688707 0.24787093 0.06196773 0.06196773 0.30983867 0.03098387
  [17] 0.30983867 0.06196773 0.34082253 0.52672574 0.15491933 0.43377413 0.40279027 0.06196773
  [25] 0.06196773 0.06196773 0.43377413 0.15491933 0.30983867 0.68164507 0.68164507 0.68164507
  [33] 0.24787093 0.34082253 0.40279027 0.21688707 0.96049987 0.03098387 0.21688707 0.61967734
  [41] 0.06196773 0.30983867 0.12393547 0.03098387 0.06196773 0.06196773 0.06196773 0.52672574
  [49] 0.15491933 0.15491933 0.06196773 0.21688707 0.15491933 0.06196773 0.03098387 0.06196773
  [57] 0.40279027 0.21688707 0.34082253 0.77459667 0.12393547 0.12393547 0.21688707 0.58869347
  [65] 0.24787093 0.15491933 0.49574187 0.71262894 0.03098387 0.49574187 0.24787093 0.43377413
  [73] 0.43377413 0.15491933 0.24787093 0.03098387 0.15491933 0.12393547 0.34082253 0.06196773
  [81] 0.52672574 0.52672574 0.34082253 0.52672574 0.06196773 0.21688707 0.21688707 0.77459667
  [89] 0.34082253 0.34082253 0.15491933 0.58869347 0.49574187 0.43377413 0.03098387 0.15491933
  [97] 0.06196773 0.15491933 0.03098387 0.15491933 0.30983867 0.03098387 0.15491933 0.34082253
 [105] 0.15491933 0.12393547 0.06196773 0.71262894 1.08443534 0.15491933 0.30983867 0.52672574
 [113] 0.21688707 0.06196773 0.03098387 0.03098387 0.52672574 0.68164507 0.58869347 0.34082253
 [121] 0.12393547 0.15491933 0.06196773 0.03098387 0.34082253 0.71262894 0.43377413 0.34082253
 [129] 0.43377413 0.06196773 0.58869347 0.03098387 0.52672574 0.12393547 0.34082253 0.15491933
 [137] 0.21688707 0.12393547 0.21688707 0.86754827 0.34082253 0.24787093 0.12393547 0.30983867
 [145] 0.15491933 0.61967734 0.24787093 0.49574187 0.03098387 0.40279027 0.34082253 0.52672574
 [153] 0.49574187 0.52672574 0.06196773 0.21688707 0.61967734 0.12393547 0.06196773 0.21688707
 [161] 0.12393547 0.52672574 0.24787093 0.43377413 0.30983867 0.80558054 0.03098387 0.80558054
 [169] 0.40279027 0.49574187 0.24787093 0.12393547 0.21688707 0.43377413 0.12393547 0.15491933
 [177] 0.68164507 0.77459667 0.06196773 0.61967734 0.52672574 0.49574187 0.30983867 0.03098387
 [185] 0.58869347 0.21688707 0.24787093 0.12393547 0.34082253 0.71262894 0.40279027 0.03098387
 [193] 0.30983867 0.21688707 0.24787093 0.34082253 0.15491933 0.06196773 0.15491933 0.12393547
 [201] 0.34082253 0.03098387 0.24787093 0.12393547 0.03098387 0.15491933 0.03098387 0.49574187
 [209] 0.34082253 0.15491933 0.06196773 0.03098387 0.21688707 0.58869347 0.49574187 0.68164507
 [217] 0.15491933 0.15491933 0.03098387 0.15491933 0.06196773 0.40279027 0.06196773 0.21688707
 [225] 0.52672574 0.34082253 0.34082253 0.06196773 0.15491933 0.06196773 0.30983867 0.68164507
 [233] 0.06196773 0.52672574 0.30983867 0.21688707 0.15491933 0.03098387 0.03098387 0.52672574
 [241] 0.03098387 0.43377413 0.06196773 0.06196773 0.15491933 0.24787093 0.52672574 0.03098387
 [249] 0.03098387 0.40279027 0.34082253 0.12393547 0.61967734 0.40279027 0.15491933 0.03098387
 [257] 0.21688707 0.03098387 0.21688707 0.40279027 0.03098387 0.52672574 0.24787093 0.52672574
 [265] 0.12393547 0.30983867 0.03098387 0.06196773 0.12393547 0.06196773 0.58869347 0.12393547
 [273] 0.12393547 0.58869347 0.34082253 0.12393547 0.03098387 0.21688707 0.71262894 0.58869347
 [281] 0.43377413 0.15491933 0.49574187 0.61967734 0.12393547 0.12393547 0.15491933 0.12393547
 [289] 0.52672574 0.40279027 0.80558054 0.24787093 0.24787093 0.49574187 0.15491933 0.12393547
 [297] 0.06196773 0.68164507 0.15491933 0.61967734 0.21688707 1.51820947 0.43377413 0.30983867
 [305] 0.30983867 0.03098387 0.40279027 0.03098387 0.34082253 0.15491933 0.24787093 0.15491933
 [313] 0.03098387 0.03098387 0.34082253 0.03098387 0.43377413 0.52672574 0.03098387 0.43377413
 [321] 0.15491933 0.06196773 0.40279027 0.03098387 0.61967734 0.49574187 0.77459667 0.34082253
 [329] 0.06196773 0.15491933 0.15491933 0.34082253 0.15491933 0.03098387 0.30983867 0.43377413
 [337] 0.12393547 0.40279027 0.15491933 0.12393547 1.05345147 0.34082253 0.24787093 0.15491933
 [345] 0.24787093 0.12393547 0.24787093 0.03098387 0.34082253 0.06196773 0.24787093 0.21688707
 [353] 0.52672574 0.49574187 0.24787093 0.24787093 0.21688707 0.15491933 0.71262894 0.40279027
 [361] 0.34082253 0.24787093 0.03098387 0.40279027 0.34082253 0.21688707 0.34082253 0.40279027
 [369] 0.15491933 0.15491933 0.21688707 0.58869347 0.24787093 0.68164507 0.12393547 0.86754827
 [377] 0.24787093 0.30983867 0.12393547 0.40279027 0.40279027 0.58869347 0.21688707 0.03098387
 [385] 0.06196773 0.21688707 0.24787093 0.03098387 0.24787093 0.58869347 0.24787093 0.30983867
 [393] 0.30983867 0.21688707 0.40279027 1.14640307 0.06196773 0.43377413 0.03098387 0.06196773
 [401] 0.58869347 0.49574187 0.34082253 0.40279027 0.06196773 0.43377413 0.21688707 0.61967734
 [409] 0.15491933 0.58869347 0.15491933 0.12393547 0.06196773 0.52672574 0.86754827 0.06196773
 [417] 0.68164507 0.06196773 0.06196773 0.06196773 0.34082253 0.34082253 0.15491933 0.52672574
 [425] 0.06196773 0.12393547 0.21688707 0.03098387 0.12393547 0.61967734 0.43377413 0.15491933
 [433] 0.03098387 0.43377413 0.40279027 0.15491933 0.06196773 0.49574187 0.03098387 0.30983867
 [441] 0.40279027 0.58869347 0.24787093 0.12393547 0.61967734 0.43377413 0.03098387 0.03098387
 [449] 0.03098387 0.06196773 0.96049987 0.15491933 0.49574187 0.12393547 0.34082253 0.40279027
 [457] 0.15491933 0.40279027 0.58869347 0.21688707 0.06196773 0.24787093 0.12393547 0.77459667
 [465] 0.12393547 0.12393547 0.12393547 0.77459667 0.49574187 0.21688707 0.49574187 0.15491933
 [473] 0.71262894 0.58869347 0.49574187 0.71262894 0.21688707 0.03098387 0.49574187 0.24787093
 [481] 0.06196773 0.49574187 0.21688707 0.12393547 0.12393547 0.03098387 0.30983867 0.30983867
 [489] 0.06196773 0.15491933 0.12393547 0.30983867 0.30983867 0.68164507 0.12393547 0.06196773
 [497] 0.03098387 0.12393547 0.03098387 0.34082253 0.24787093 0.71262894 0.15491933 0.06196773
 [505] 0.06196773 0.49574187 0.12393547 0.30983867 0.40279027 0.61967734 0.21688707 0.15491933
 [513] 0.24787093 0.24787093 0.12393547 0.34082253 0.21688707 0.03098387 0.24787093 0.15491933
 [521] 0.12393547 0.34082253 0.34082253 0.43377413 0.21688707 0.03098387 0.52672574 0.03098387
 [529] 0.43377413 0.49574187 0.40279027 0.15491933 0.15491933 0.24787093 0.40279027 0.24787093
 [537] 0.03098387 0.03098387 0.34082253 0.03098387 0.12393547 0.12393547 0.24787093 0.06196773
 [545] 0.40279027 0.03098387 0.24787093 0.21688707 0.40279027 0.58869347 0.24787093 0.58869347
 [553] 0.34082253 0.21688707 0.52672574 0.21688707 0.15491933 0.68164507 0.40279027 0.21688707
 [561] 0.34082253 0.21688707 0.80558054 0.24787093 0.24787093 0.15491933 0.06196773 0.99148374
 [569] 0.03098387 0.40279027 0.15491933 0.15491933 0.24787093 0.24787093 0.43377413 0.06196773
 [577] 0.24787093 0.12393547 0.12393547 0.71262894 0.40279027 0.21688707 0.49574187 0.12393547
 [585] 0.49574187 0.12393547 0.06196773 0.15491933 0.43377413 0.34082253 0.34082253 0.34082253
 [593] 0.15491933 0.15491933 0.21688707 0.06196773 0.61967734 0.30983867 0.12393547 0.12393547
 [601] 0.12393547 0.03098387 0.03098387 0.06196773 0.21688707 0.71262894 0.52672574 0.15491933
 [609] 0.03098387 0.30983867 0.21688707 0.06196773 0.03098387 0.52672574 0.12393547 0.68164507
 [617] 0.43377413 0.12393547 0.40279027 0.06196773 0.12393547 0.24787093 0.06196773 0.21688707
 [625] 0.52672574 0.43377413 0.52672574 0.21688707 0.40279027 0.06196773 0.03098387 0.06196773
 [633] 0.06196773 0.03098387 0.77459667 0.40279027 0.49574187 0.06196773 0.43377413 0.24787093
 [641] 0.21688707 0.12393547 0.03098387 0.21688707 0.61967734 0.52672574 0.43377413 0.15491933
 [649] 0.30983867 0.24787093 0.68164507 0.12393547 0.21688707 0.24787093 0.24787093 0.06196773
 [657] 0.12393547 0.06196773 0.30983867 0.12393547 0.34082253 0.06196773 0.30983867 0.68164507
 [665] 0.03098387 0.61967734 0.15491933 0.24787093 0.15491933 0.58869347 0.03098387 0.12393547
 [673] 0.06196773 0.15491933 0.06196773 0.21688707 0.15491933 0.03098387 0.71262894 0.40279027
 [681] 0.34082253 0.03098387 0.03098387 0.21688707 0.21688707 0.12393547 0.12393547 0.68164507
 [689] 0.43377413 0.34082253 0.52672574 0.06196773 0.58869347 0.12393547 0.12393547 0.24787093
 [697] 0.40279027 0.21688707 0.06196773 0.43377413 0.24787093 0.06196773 0.12393547 0.03098387
 [705] 0.06196773 0.21688707 0.24787093 0.03098387 0.24787093 0.06196773 0.06196773 0.34082253
 [713] 0.34082253 0.30983867 0.12393547 0.03098387 0.03098387 0.06196773 0.15491933 0.49574187
 [721] 0.34082253 0.12393547 0.52672574 0.15491933 0.21688707 0.06196773 0.52672574 0.03098387
 [729] 0.21688707 0.06196773 0.21688707 0.71262894 0.34082253 0.15491933 0.34082253 0.34082253
 [737] 0.15491933 0.06196773 0.06196773 0.06196773 0.30983867 0.03098387 0.34082253 0.61967734
 [745] 0.30983867 0.24787093 0.21688707 0.40279027 0.24787093 0.12393547 0.30983867 0.12393547
 [753] 0.12393547 0.06196773 0.03098387 0.30983867 0.03098387 0.12393547 0.49574187 0.24787093
 [761] 0.15491933 0.15491933 0.12393547 0.21688707 0.43377413 0.40279027 0.40279027 0.06196773
 [769] 0.24787093 0.68164507 0.77459667 0.06196773 0.24787093 0.12393547 0.49574187 0.15491933
 [777] 0.03098387 0.15491933 0.03098387 0.34082253 0.12393547 0.03098387 0.77459667 0.12393547
 [785] 0.21688707 0.03098387 0.15491933 0.34082253 0.12393547 0.40279027 0.21688707 0.30983867
 [793] 0.61967734 0.30983867 0.58869347 0.15491933 0.40279027 0.12393547 0.24787093 0.71262894
 [801] 0.40279027 0.06196773 0.21688707 0.24787093 0.12393547 0.15491933 0.12393547 0.24787093
 [809] 0.24787093 0.06196773 0.49574187 0.03098387 0.30983867 0.34082253 0.21688707 0.43377413
 [817] 0.06196773 0.52672574 0.03098387 0.30983867 0.30983867 0.21688707 0.52672574 0.49574187
 [825] 0.03098387 0.03098387 0.21688707 0.40279027 0.15491933 0.58869347 0.24787093 0.49574187
 [833] 0.03098387 0.24787093 0.43377413 0.58869347 0.34082253 0.15491933 0.15491933 0.24787093
 [841] 0.24787093 0.77459667 0.03098387 0.12393547 0.06196773 0.15491933 0.03098387 0.34082253
 [849] 0.21688707 0.52672574 0.06196773 0.12393547 0.21688707 0.49574187 0.30983867 0.12393547
 [857] 0.52672574 0.03098387 0.15491933 0.15491933 0.34082253 0.15491933 0.15491933 0.77459667
 [865] 1.14640307 0.06196773 0.15491933 0.43377413 0.21688707 0.24787093 0.43377413 0.30983867
 [873] 0.06196773 0.30983867 0.40279027 0.34082253 0.21688707 0.06196773 0.06196773 0.34082253
 [881] 0.21688707 0.30983867 0.15491933 0.06196773 0.06196773 0.21688707 0.21688707 0.34082253
 [889] 0.21688707 0.12393547 0.49574187 0.68164507 0.21688707 0.21688707 0.49574187 0.49574187
 [897] 0.24787093 0.30983867 0.61967734 0.77459667 0.21688707 0.49574187 0.68164507 0.49574187
 [905] 0.15491933 0.12393547 0.12393547 0.34082253 0.15491933 0.12393547 0.12393547 0.40279027
 [913] 0.03098387 0.40279027 0.30983867 0.34082253 0.12393547 0.12393547 0.21688707 0.68164507
 [921] 0.61967734 0.21688707 0.43377413 0.21688707 0.43377413 0.15491933 0.71262894 0.03098387
 [929] 0.52672574 0.03098387 0.89853214 0.12393547 0.68164507 0.15491933 0.40279027 0.34082253
 [937] 0.15491933 0.03098387 0.03098387 0.06196773 0.21688707 0.12393547 0.43377413 0.06196773
 [945] 0.30983867 0.06196773 0.06196773 0.21688707 0.15491933 0.06196773 0.30983867 0.15491933
 [953] 0.24787093 0.12393547 0.03098387 0.49574187 0.24787093 0.06196773 0.03098387 0.03098387
 [961] 0.40279027 0.24787093 0.15491933 0.12393547 0.40279027 0.40279027 0.30983867 0.24787093
 [969] 0.24787093 0.24787093 0.03098387 0.34082253 0.15491933 0.43377413 0.06196773 0.06196773
 [977] 0.49574187 0.12393547 0.43377413 0.15491933 0.40279027 0.21688707 0.58869347 0.24787093
 [985] 0.40279027 0.21688707 0.24787093 0.40279027 0.61967734 0.12393547 0.30983867 0.03098387
 [993] 0.61967734 0.21688707 0.15491933 0.24787093 0.52672574 0.12393547 0.06196773 0.21688707
 [ reached 'max' / getOption("max.print") -- omitted 9000 entries ]
txt> abs(res)
txt> mean(abs(res > 2))
[1] 0
txt> mean(abs(res > 2))
txt> summary(res)
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-1.084435 -0.247871 -0.061968 -0.005026  0.216887  1.518209 
txt> summary(res)
txt> qqnorm(res)
txt> qqnorm(res)
txt> res <- abs(res)
txt> res <- abs(res)
txt> head(res)
[1] 0.40279027 0.34082253 0.12393547 0.52672574 0.12393547 0.03098387
txt> head(res)
txt> qqnorm(res)
txt> qqnorm(res)
txt> n = 100
txt> n = 100
txt> set.seed(1)
txt> set.seed(1)
txt> replicate(10000, {
txt+ x <- sample(1:6, n, replace = TRUE)
txt+ a <- mean(x == 6)
txt+ z <- (a - p)/sqrt(p * (1 - p)/n)
txt+ })
   [1]  1.16275535 -0.98386991  0.35777088 -1.52052622  0.35777088  0.08944272 -0.44721360  1.16275535
   [9] -0.17888544 -0.71554175  0.62609903 -0.71554175 -0.17888544 -0.17888544  0.89442719  0.08944272
  [17]  0.89442719 -0.17888544 -0.98386991 -1.52052622 -0.44721360 -1.25219807  1.16275535 -0.17888544
  [25] -0.17888544 -0.17888544 -1.25219807 -0.44721360  0.89442719  1.96773982  1.96773982  1.96773982
  [33] -0.71554175 -0.98386991  1.16275535  0.62609903  2.77272429  0.08944272  0.62609903 -1.78885438
  [41] -0.17888544  0.89442719  0.35777088  0.08944272 -0.17888544 -0.17888544 -0.17888544 -1.52052622
  [49] -0.44721360 -0.44721360 -0.17888544  0.62609903 -0.44721360 -0.17888544  0.08944272 -0.17888544
  [57]  1.16275535  0.62609903 -0.98386991  2.23606798  0.35777088  0.35777088  0.62609903  1.69941166
  [65] -0.71554175 -0.44721360  1.43108351 -2.05718254  0.08944272  1.43108351 -0.71554175 -1.25219807
  [73] -1.25219807 -0.44721360 -0.71554175  0.08944272 -0.44721360  0.35777088 -0.98386991 -0.17888544
  [81] -1.52052622 -1.52052622 -0.98386991 -1.52052622 -0.17888544  0.62609903  0.62609903  2.23606798
  [89] -0.98386991 -0.98386991 -0.44721360  1.69941166  1.43108351 -1.25219807  0.08944272 -0.44721360
  [97] -0.17888544 -0.44721360  0.08944272 -0.44721360  0.89442719  0.08944272 -0.44721360 -0.98386991
 [105] -0.44721360  0.35777088 -0.17888544 -2.05718254 -3.13049517 -0.44721360  0.89442719 -1.52052622
 [113]  0.62609903 -0.17888544  0.08944272  0.08944272 -1.52052622  1.96773982  1.69941166 -0.98386991
 [121]  0.35777088 -0.44721360 -0.17888544  0.08944272 -0.98386991 -2.05718254 -1.25219807 -0.98386991
 [129] -1.25219807 -0.17888544  1.69941166  0.08944272 -1.52052622  0.35777088 -0.98386991 -0.44721360
 [137]  0.62609903  0.35777088  0.62609903  2.50439613 -0.98386991 -0.71554175  0.35777088  0.89442719
 [145] -0.44721360 -1.78885438 -0.71554175  1.43108351  0.08944272  1.16275535 -0.98386991 -1.52052622
 [153]  1.43108351 -1.52052622 -0.17888544  0.62609903 -1.78885438  0.35777088 -0.17888544  0.62609903
 [161]  0.35777088 -1.52052622 -0.71554175 -1.25219807  0.89442719 -2.32551070  0.08944272 -2.32551070
 [169]  1.16275535  1.43108351 -0.71554175  0.35777088  0.62609903 -1.25219807  0.35777088 -0.44721360
 [177]  1.96773982  2.23606798 -0.17888544 -1.78885438 -1.52052622  1.43108351  0.89442719  0.08944272
 [185]  1.69941166  0.62609903 -0.71554175  0.35777088 -0.98386991 -2.05718254  1.16275535  0.08944272
 [193]  0.89442719  0.62609903 -0.71554175 -0.98386991 -0.44721360 -0.17888544 -0.44721360  0.35777088
 [201] -0.98386991  0.08944272 -0.71554175  0.35777088  0.08944272 -0.44721360  0.08944272  1.43108351
 [209] -0.98386991 -0.44721360 -0.17888544  0.08944272  0.62609903  1.69941166  1.43108351  1.96773982
 [217] -0.44721360 -0.44721360  0.08944272 -0.44721360 -0.17888544  1.16275535 -0.17888544  0.62609903
 [225] -1.52052622 -0.98386991 -0.98386991 -0.17888544 -0.44721360 -0.17888544  0.89442719  1.96773982
 [233] -0.17888544 -1.52052622  0.89442719  0.62609903 -0.44721360  0.08944272  0.08944272 -1.52052622
 [241]  0.08944272 -1.25219807 -0.17888544 -0.17888544 -0.44721360 -0.71554175 -1.52052622  0.08944272
 [249]  0.08944272  1.16275535 -0.98386991  0.35777088 -1.78885438  1.16275535 -0.44721360  0.08944272
 [257]  0.62609903  0.08944272  0.62609903  1.16275535  0.08944272 -1.52052622 -0.71554175 -1.52052622
 [265]  0.35777088  0.89442719  0.08944272 -0.17888544  0.35777088 -0.17888544  1.69941166  0.35777088
 [273]  0.35777088  1.69941166 -0.98386991  0.35777088  0.08944272  0.62609903 -2.05718254  1.69941166
 [281] -1.25219807 -0.44721360  1.43108351 -1.78885438  0.35777088  0.35777088 -0.44721360  0.35777088
 [289] -1.52052622  1.16275535 -2.32551070 -0.71554175 -0.71554175  1.43108351 -0.44721360  0.35777088
 [297] -0.17888544  1.96773982 -0.44721360 -1.78885438  0.62609903  4.38269324 -1.25219807  0.89442719
 [305]  0.89442719  0.08944272  1.16275535  0.08944272 -0.98386991 -0.44721360 -0.71554175 -0.44721360
 [313]  0.08944272  0.08944272 -0.98386991  0.08944272 -1.25219807 -1.52052622  0.08944272 -1.25219807
 [321] -0.44721360 -0.17888544  1.16275535  0.08944272 -1.78885438  1.43108351  2.23606798 -0.98386991
 [329] -0.17888544 -0.44721360 -0.44721360 -0.98386991 -0.44721360  0.08944272  0.89442719 -1.25219807
 [337]  0.35777088  1.16275535 -0.44721360  0.35777088  3.04105245 -0.98386991 -0.71554175 -0.44721360
 [345] -0.71554175  0.35777088 -0.71554175  0.08944272 -0.98386991 -0.17888544 -0.71554175  0.62609903
 [353] -1.52052622  1.43108351 -0.71554175 -0.71554175  0.62609903 -0.44721360 -2.05718254  1.16275535
 [361] -0.98386991 -0.71554175  0.08944272  1.16275535 -0.98386991  0.62609903 -0.98386991  1.16275535
 [369] -0.44721360 -0.44721360  0.62609903  1.69941166 -0.71554175  1.96773982  0.35777088  2.50439613
 [377] -0.71554175  0.89442719  0.35777088  1.16275535  1.16275535  1.69941166  0.62609903  0.08944272
 [385] -0.17888544  0.62609903 -0.71554175  0.08944272 -0.71554175  1.69941166 -0.71554175  0.89442719
 [393]  0.89442719  0.62609903  1.16275535  3.30938061 -0.17888544 -1.25219807  0.08944272 -0.17888544
 [401]  1.69941166  1.43108351 -0.98386991  1.16275535 -0.17888544 -1.25219807  0.62609903 -1.78885438
 [409] -0.44721360  1.69941166 -0.44721360  0.35777088 -0.17888544 -1.52052622  2.50439613 -0.17888544
 [417]  1.96773982 -0.17888544 -0.17888544 -0.17888544 -0.98386991 -0.98386991 -0.44721360 -1.52052622
 [425] -0.17888544  0.35777088  0.62609903  0.08944272  0.35777088 -1.78885438 -1.25219807 -0.44721360
 [433]  0.08944272 -1.25219807  1.16275535 -0.44721360 -0.17888544  1.43108351  0.08944272  0.89442719
 [441]  1.16275535  1.69941166 -0.71554175  0.35777088 -1.78885438 -1.25219807  0.08944272  0.08944272
 [449]  0.08944272 -0.17888544  2.77272429 -0.44721360  1.43108351  0.35777088 -0.98386991  1.16275535
 [457] -0.44721360  1.16275535  1.69941166  0.62609903 -0.17888544 -0.71554175  0.35777088  2.23606798
 [465]  0.35777088  0.35777088  0.35777088  2.23606798  1.43108351  0.62609903  1.43108351 -0.44721360
 [473] -2.05718254  1.69941166  1.43108351 -2.05718254  0.62609903  0.08944272  1.43108351 -0.71554175
 [481] -0.17888544  1.43108351  0.62609903  0.35777088  0.35777088  0.08944272  0.89442719  0.89442719
 [489] -0.17888544 -0.44721360  0.35777088  0.89442719  0.89442719  1.96773982  0.35777088 -0.17888544
 [497]  0.08944272  0.35777088  0.08944272 -0.98386991 -0.71554175 -2.05718254 -0.44721360 -0.17888544
 [505] -0.17888544  1.43108351  0.35777088  0.89442719  1.16275535 -1.78885438  0.62609903 -0.44721360
 [513] -0.71554175 -0.71554175  0.35777088 -0.98386991  0.62609903  0.08944272 -0.71554175 -0.44721360
 [521]  0.35777088 -0.98386991 -0.98386991 -1.25219807  0.62609903  0.08944272 -1.52052622  0.08944272
 [529] -1.25219807  1.43108351  1.16275535 -0.44721360 -0.44721360 -0.71554175  1.16275535 -0.71554175
 [537]  0.08944272  0.08944272 -0.98386991  0.08944272  0.35777088  0.35777088 -0.71554175 -0.17888544
 [545]  1.16275535  0.08944272 -0.71554175  0.62609903  1.16275535  1.69941166 -0.71554175  1.69941166
 [553] -0.98386991  0.62609903 -1.52052622  0.62609903 -0.44721360  1.96773982  1.16275535  0.62609903
 [561] -0.98386991  0.62609903 -2.32551070 -0.71554175 -0.71554175 -0.44721360 -0.17888544 -2.86216701
 [569]  0.08944272  1.16275535 -0.44721360 -0.44721360 -0.71554175 -0.71554175 -1.25219807 -0.17888544
 [577] -0.71554175  0.35777088  0.35777088 -2.05718254  1.16275535  0.62609903  1.43108351  0.35777088
 [585]  1.43108351  0.35777088 -0.17888544 -0.44721360 -1.25219807 -0.98386991 -0.98386991 -0.98386991
 [593] -0.44721360 -0.44721360  0.62609903 -0.17888544 -1.78885438  0.89442719  0.35777088  0.35777088
 [601]  0.35777088  0.08944272  0.08944272 -0.17888544  0.62609903 -2.05718254 -1.52052622 -0.44721360
 [609]  0.08944272  0.89442719  0.62609903 -0.17888544  0.08944272 -1.52052622  0.35777088  1.96773982
 [617] -1.25219807  0.35777088  1.16275535 -0.17888544  0.35777088 -0.71554175 -0.17888544  0.62609903
 [625] -1.52052622 -1.25219807 -1.52052622  0.62609903  1.16275535 -0.17888544  0.08944272 -0.17888544
 [633] -0.17888544  0.08944272  2.23606798  1.16275535  1.43108351 -0.17888544 -1.25219807 -0.71554175
 [641]  0.62609903  0.35777088  0.08944272  0.62609903 -1.78885438 -1.52052622 -1.25219807 -0.44721360
 [649]  0.89442719 -0.71554175  1.96773982  0.35777088  0.62609903 -0.71554175 -0.71554175 -0.17888544
 [657]  0.35777088 -0.17888544  0.89442719  0.35777088 -0.98386991 -0.17888544  0.89442719  1.96773982
 [665]  0.08944272 -1.78885438 -0.44721360 -0.71554175 -0.44721360  1.69941166  0.08944272  0.35777088
 [673] -0.17888544 -0.44721360 -0.17888544  0.62609903 -0.44721360  0.08944272 -2.05718254  1.16275535
 [681] -0.98386991  0.08944272  0.08944272  0.62609903  0.62609903  0.35777088  0.35777088  1.96773982
 [689] -1.25219807 -0.98386991 -1.52052622 -0.17888544  1.69941166  0.35777088  0.35777088 -0.71554175
 [697]  1.16275535  0.62609903 -0.17888544 -1.25219807 -0.71554175 -0.17888544  0.35777088  0.08944272
 [705] -0.17888544  0.62609903 -0.71554175  0.08944272 -0.71554175 -0.17888544 -0.17888544 -0.98386991
 [713] -0.98386991  0.89442719  0.35777088  0.08944272  0.08944272 -0.17888544 -0.44721360  1.43108351
 [721] -0.98386991  0.35777088 -1.52052622 -0.44721360  0.62609903 -0.17888544 -1.52052622  0.08944272
 [729]  0.62609903 -0.17888544  0.62609903 -2.05718254 -0.98386991 -0.44721360 -0.98386991 -0.98386991
 [737] -0.44721360 -0.17888544 -0.17888544 -0.17888544  0.89442719  0.08944272 -0.98386991 -1.78885438
 [745]  0.89442719 -0.71554175  0.62609903  1.16275535 -0.71554175  0.35777088  0.89442719  0.35777088
 [753]  0.35777088 -0.17888544  0.08944272  0.89442719  0.08944272  0.35777088  1.43108351 -0.71554175
 [761] -0.44721360 -0.44721360  0.35777088  0.62609903 -1.25219807  1.16275535  1.16275535 -0.17888544
 [769] -0.71554175  1.96773982  2.23606798 -0.17888544 -0.71554175  0.35777088  1.43108351 -0.44721360
 [777]  0.08944272 -0.44721360  0.08944272 -0.98386991  0.35777088  0.08944272  2.23606798  0.35777088
 [785]  0.62609903  0.08944272 -0.44721360 -0.98386991  0.35777088  1.16275535  0.62609903  0.89442719
 [793] -1.78885438  0.89442719  1.69941166 -0.44721360  1.16275535  0.35777088 -0.71554175 -2.05718254
 [801]  1.16275535 -0.17888544  0.62609903 -0.71554175  0.35777088 -0.44721360  0.35777088 -0.71554175
 [809] -0.71554175 -0.17888544  1.43108351  0.08944272  0.89442719 -0.98386991  0.62609903 -1.25219807
 [817] -0.17888544 -1.52052622  0.08944272  0.89442719  0.89442719  0.62609903 -1.52052622  1.43108351
 [825]  0.08944272  0.08944272  0.62609903  1.16275535 -0.44721360  1.69941166 -0.71554175  1.43108351
 [833]  0.08944272 -0.71554175 -1.25219807  1.69941166 -0.98386991 -0.44721360 -0.44721360 -0.71554175
 [841] -0.71554175  2.23606798  0.08944272  0.35777088 -0.17888544 -0.44721360  0.08944272 -0.98386991
 [849]  0.62609903 -1.52052622 -0.17888544  0.35777088  0.62609903  1.43108351  0.89442719  0.35777088
 [857] -1.52052622  0.08944272 -0.44721360 -0.44721360 -0.98386991 -0.44721360 -0.44721360  2.23606798
 [865]  3.30938061 -0.17888544 -0.44721360 -1.25219807  0.62609903 -0.71554175 -1.25219807  0.89442719
 [873] -0.17888544  0.89442719  1.16275535 -0.98386991  0.62609903 -0.17888544 -0.17888544 -0.98386991
 [881]  0.62609903  0.89442719 -0.44721360 -0.17888544 -0.17888544  0.62609903  0.62609903 -0.98386991
 [889]  0.62609903  0.35777088  1.43108351  1.96773982  0.62609903  0.62609903  1.43108351  1.43108351
 [897] -0.71554175  0.89442719 -1.78885438  2.23606798  0.62609903  1.43108351  1.96773982  1.43108351
 [905] -0.44721360  0.35777088  0.35777088 -0.98386991 -0.44721360  0.35777088  0.35777088  1.16275535
 [913]  0.08944272  1.16275535  0.89442719 -0.98386991  0.35777088  0.35777088  0.62609903  1.96773982
 [921] -1.78885438  0.62609903 -1.25219807  0.62609903 -1.25219807 -0.44721360 -2.05718254  0.08944272
 [929] -1.52052622  0.08944272 -2.59383885  0.35777088  1.96773982 -0.44721360  1.16275535 -0.98386991
 [937] -0.44721360  0.08944272  0.08944272 -0.17888544  0.62609903  0.35777088 -1.25219807 -0.17888544
 [945]  0.89442719 -0.17888544 -0.17888544  0.62609903 -0.44721360 -0.17888544  0.89442719 -0.44721360
 [953] -0.71554175  0.35777088  0.08944272  1.43108351 -0.71554175 -0.17888544  0.08944272  0.08944272
 [961]  1.16275535 -0.71554175 -0.44721360  0.35777088  1.16275535  1.16275535  0.89442719 -0.71554175
 [969] -0.71554175 -0.71554175  0.08944272 -0.98386991 -0.44721360 -1.25219807 -0.17888544 -0.17888544
 [977]  1.43108351  0.35777088 -1.25219807 -0.44721360  1.16275535  0.62609903  1.69941166 -0.71554175
 [985]  1.16275535  0.62609903 -0.71554175  1.16275535 -1.78885438  0.35777088  0.89442719  0.08944272
 [993] -1.78885438  0.62609903 -0.44721360 -0.71554175 -1.52052622  0.35777088 -0.17888544  0.62609903
 [ reached 'max' / getOption("max.print") -- omitted 9000 entries ]
txt> replicate(10000, {
txt+ x <- sample(1:6, n, replace = TRUE)
txt+ a <- mean(x == 6)
txt+ z <- (a - p)/sqrt(p * (1 - p)/n)
txt+ })
txt> set.seed(1)
txt> set.seed(1)
txt> res <- replicate(10000, {
txt+ x <- sample(1:6, n, replace = TRUE)
txt+ a <- mean(x == 6)
txt+ z <- (a - p)/sqrt(p * (1 - p)/n)
txt+ })
txt> res <- replicate(10000, {
txt+ x <- sample(1:6, n, replace = TRUE)
txt+ a <- mean(x == 6)
txt+ z <- (a - p)/sqrt(p * (1 - p)/n)
txt+ })
txt> head(res)
[1]  1.16275535 -0.98386991  0.35777088 -1.52052622  0.35777088  0.08944272
txt> head(res)
txt> mean(abs(res > 2))
[1] 0.0219
txt> mean(abs(res > 2))

 ## qqnorm was looking weird, and couldn't get a proportion of z > 2 because of mistake - didn't define n as 100. now 0.02 looks closer to the CLT expected of 0.05 in the q 

txt> txtComment("## qqnorm was looking weird, and couldn't get a proportion of z > 2 because of mistake - didn't define n as 100. now 0.02 looks closer to the CLT expected of 0.05 in the q")
txt> qqnorm(res)
txt> qqnorm(res)
txt> mean(abs(res) > 2)
[1] 0.0431
txt> mean(abs(res) > 2)

 ## don't define res > 2 in abs()! 

txt> txtComment("## don't define res > 2 in abs()!")

 ## get the abs() value of res dataset first, then compare that to filter which of those abs(res) values are > 2 

txt> txtComment("## get the abs() value of res dataset first, then compare that to filter which of those abs(res) values are > 2")

 ## the reason why the value doubled from 0.02 to 0.04 was because I was only looking at one end of the tail (the positive end), because the abs() value couldnt correctly change the -2 values to positive to be taken into account in the res > 2 filter. 

txt> txtComment("## the reason why the value doubled from 0.02 to 0.04 was because I was only looking at one end of the tail (the positive end), because the abs() value couldnt correctly change the -2 values to positive to be taken into account in the res > 2 filter.")

txt> `?`(txt)
No documentation for ‘txt’ in specified packages and libraries:
you could try ‘??txt’

 **In the example used in exercise 1, the original data is binary (either 6 or not). In this case, the success probability also affects the appropriateness of the CLT. With very low probabilities, we need larger sample sizes for the CLT to “kick in”.

Run the simulation from exercise 1, but for different values of p and n. For which of the following is the normal approximation best?

A) p=0.5 and n=5
B) p=0.5 and n=30
C) p=0.01 and n=30
D) p=0.01 and n=100
 


 ## would expect lower probability to have lower variance in the data, vice versa. i.e. if p = 0.05, you would have 50/50 TRUE FALSE, but p = 0.05, you would have more TRUE than FALSE (vice versa), hence less variation and central tendency to one of the two. 


 ## a higher n sample size would mean a larger divisble factor in the z score formula, hence a smaller value for SD. this means that a larger n means less variance in the data (silences noise). CLT also 'kicks in' with a larger sample size i.e. achieves closer to a total normal distribution (asymptotic) 


 ##  D seems to be the most likely answer for the least variance, and most normal distribution? 

txt> res <- replicate(10000, {
txt+ x <- sample(1:6, 30, replace = TRUE)
txt+ a <- mean(x == 6)
txt+ z <- (a - 0.01)/sqrt(0.01 * (1 - 0.01)/30)
txt+ })
txt> res
   [1]  4.9543369  6.7892766 10.4591558  8.6242162  6.7892766  4.9543369  8.6242162 12.2940954  6.7892766
  [10]  6.7892766 17.7989142  8.6242162 14.1290350 15.9639746  6.7892766  8.6242162  4.9543369  3.1193973
  [19]  4.9543369  4.9543369  3.1193973 10.4591558 10.4591558  4.9543369  8.6242162  6.7892766 12.2940954
  [28]  8.6242162 10.4591558  6.7892766  8.6242162  6.7892766  8.6242162 15.9639746 15.9639746 12.2940954
  [37]  8.6242162 10.4591558 14.1290350  8.6242162 10.4591558 14.1290350 10.4591558 10.4591558  8.6242162
  [46]  6.7892766  3.1193973  6.7892766  8.6242162  8.6242162  4.9543369  6.7892766  6.7892766 14.1290350
  [55]  1.2844577  4.9543369  8.6242162  6.7892766  4.9543369  3.1193973  4.9543369  6.7892766 10.4591558
  [64] 10.4591558 12.2940954  8.6242162  8.6242162 10.4591558 14.1290350 12.2940954 14.1290350 10.4591558
  [73]  6.7892766 15.9639746  8.6242162  6.7892766 10.4591558 10.4591558 12.2940954  8.6242162  3.1193973
  [82]  6.7892766  8.6242162 10.4591558 10.4591558 14.1290350  4.9543369  6.7892766 14.1290350  6.7892766
  [91]  8.6242162  4.9543369 10.4591558  6.7892766  8.6242162  8.6242162  4.9543369 12.2940954  6.7892766
 [100]  4.9543369  8.6242162  8.6242162 10.4591558  6.7892766  8.6242162  4.9543369 12.2940954 10.4591558
 [109] 10.4591558  8.6242162  8.6242162  3.1193973 14.1290350  1.2844577  1.2844577  6.7892766  3.1193973
 [118]  4.9543369  8.6242162  1.2844577 10.4591558  4.9543369  4.9543369  6.7892766 12.2940954  3.1193973
 [127] 17.7989142  8.6242162  4.9543369  6.7892766  3.1193973 12.2940954 12.2940954  8.6242162 10.4591558
 [136]  3.1193973 10.4591558  6.7892766 12.2940954 14.1290350  8.6242162  3.1193973 17.7989142 12.2940954
 [145]  8.6242162  4.9543369 12.2940954  3.1193973 -0.5504819  8.6242162  6.7892766  4.9543369  8.6242162
 [154] 12.2940954 10.4591558 14.1290350 15.9639746  1.2844577 14.1290350 15.9639746  4.9543369  8.6242162
 [163]  8.6242162  6.7892766 10.4591558  6.7892766  6.7892766  4.9543369  8.6242162  3.1193973 -0.5504819
 [172]  8.6242162  8.6242162  4.9543369 10.4591558 14.1290350  3.1193973 15.9639746  8.6242162  4.9543369
 [181]  6.7892766  6.7892766  4.9543369  6.7892766 12.2940954 14.1290350  3.1193973 10.4591558  6.7892766
 [190] 12.2940954  8.6242162 12.2940954  8.6242162  8.6242162 15.9639746  1.2844577  4.9543369  8.6242162
 [199]  8.6242162  4.9543369 10.4591558 10.4591558  6.7892766 10.4591558  4.9543369  4.9543369 14.1290350
 [208]  8.6242162 10.4591558  4.9543369  3.1193973 12.2940954  6.7892766  3.1193973  8.6242162  8.6242162
 [217] 10.4591558 10.4591558 10.4591558  6.7892766 10.4591558  8.6242162  8.6242162 10.4591558 10.4591558
 [226] 14.1290350  8.6242162  8.6242162  4.9543369 -0.5504819  8.6242162  1.2844577  4.9543369  8.6242162
 [235] 17.7989142  6.7892766  8.6242162  8.6242162 10.4591558 14.1290350  4.9543369  4.9543369  8.6242162
 [244]  3.1193973 10.4591558 10.4591558  8.6242162  8.6242162  6.7892766  3.1193973  8.6242162  6.7892766
 [253] 14.1290350  4.9543369  6.7892766  4.9543369  8.6242162  4.9543369 12.2940954 12.2940954 12.2940954
 [262] 10.4591558 14.1290350  4.9543369 12.2940954  4.9543369  6.7892766  8.6242162  8.6242162  1.2844577
 [271]  8.6242162 14.1290350  6.7892766  4.9543369  3.1193973  3.1193973  6.7892766  6.7892766  8.6242162
 [280] 10.4591558 10.4591558  8.6242162 14.1290350  3.1193973  8.6242162  6.7892766 10.4591558  8.6242162
 [289] 14.1290350 10.4591558 12.2940954 10.4591558  8.6242162 10.4591558 14.1290350  6.7892766  8.6242162
 [298] 12.2940954 12.2940954 -0.5504819 10.4591558  8.6242162  8.6242162  8.6242162 10.4591558 10.4591558
 [307] 15.9639746  8.6242162 12.2940954 12.2940954  3.1193973  3.1193973 10.4591558 10.4591558 10.4591558
 [316]  4.9543369  6.7892766 12.2940954 15.9639746 10.4591558  3.1193973  4.9543369 10.4591558 10.4591558
 [325] 14.1290350 12.2940954  6.7892766 10.4591558 15.9639746 10.4591558  8.6242162  8.6242162  3.1193973
 [334]  1.2844577  6.7892766  6.7892766 10.4591558  8.6242162 12.2940954  6.7892766  6.7892766  6.7892766
 [343]  4.9543369  1.2844577  4.9543369  8.6242162  3.1193973  8.6242162 10.4591558 10.4591558 12.2940954
 [352] 10.4591558  3.1193973  6.7892766 14.1290350  4.9543369  8.6242162 10.4591558  4.9543369  6.7892766
 [361] 10.4591558  6.7892766 14.1290350 10.4591558  8.6242162 10.4591558  6.7892766 12.2940954  8.6242162
 [370]  3.1193973 -0.5504819  6.7892766 12.2940954  6.7892766  6.7892766 12.2940954 14.1290350 12.2940954
 [379]  3.1193973  1.2844577 14.1290350  8.6242162  6.7892766  6.7892766  8.6242162  3.1193973 14.1290350
 [388]  8.6242162  1.2844577 15.9639746  4.9543369  8.6242162  8.6242162 10.4591558  4.9543369  8.6242162
 [397] 10.4591558 12.2940954  3.1193973  8.6242162  8.6242162  6.7892766  4.9543369  8.6242162  4.9543369
 [406]  3.1193973  6.7892766 10.4591558  3.1193973  8.6242162 10.4591558  1.2844577  8.6242162  4.9543369
 [415]  6.7892766 17.7989142  6.7892766  8.6242162 12.2940954 12.2940954 14.1290350  8.6242162  6.7892766
 [424]  6.7892766  3.1193973 10.4591558  6.7892766  8.6242162 17.7989142  8.6242162  3.1193973  4.9543369
 [433] 12.2940954  8.6242162 10.4591558 10.4591558  4.9543369  8.6242162 12.2940954  4.9543369 12.2940954
 [442]  6.7892766 19.6338538  4.9543369  1.2844577 19.6338538 14.1290350 10.4591558 12.2940954 14.1290350
 [451]  6.7892766  6.7892766 10.4591558 14.1290350  6.7892766  8.6242162  4.9543369 10.4591558  4.9543369
 [460]  6.7892766  8.6242162 10.4591558  8.6242162 10.4591558 12.2940954  8.6242162 14.1290350  8.6242162
 [469]  4.9543369 -0.5504819 10.4591558  6.7892766  8.6242162 10.4591558  4.9543369  4.9543369 12.2940954
 [478] 12.2940954  6.7892766  6.7892766 10.4591558  1.2844577 10.4591558 14.1290350  8.6242162 14.1290350
 [487]  3.1193973  6.7892766  6.7892766  4.9543369 14.1290350  6.7892766 10.4591558 10.4591558  8.6242162
 [496]  8.6242162  6.7892766 10.4591558 10.4591558  6.7892766 10.4591558  8.6242162  8.6242162  4.9543369
 [505]  4.9543369  4.9543369  6.7892766  4.9543369  8.6242162  3.1193973  8.6242162  6.7892766 10.4591558
 [514]  6.7892766 12.2940954  6.7892766 15.9639746  4.9543369  6.7892766  4.9543369  4.9543369  8.6242162
 [523]  4.9543369  8.6242162 10.4591558  1.2844577  6.7892766  8.6242162 15.9639746  4.9543369  6.7892766
 [532]  8.6242162  1.2844577  6.7892766  8.6242162  3.1193973 10.4591558 12.2940954  1.2844577  8.6242162
 [541]  4.9543369  6.7892766  3.1193973  6.7892766  6.7892766  8.6242162 12.2940954 15.9639746  8.6242162
 [550]  3.1193973 12.2940954  4.9543369  8.6242162 10.4591558  8.6242162  4.9543369  4.9543369 15.9639746
 [559]  6.7892766  6.7892766 14.1290350 14.1290350 12.2940954  8.6242162  8.6242162  6.7892766 10.4591558
 [568]  6.7892766  1.2844577 12.2940954  6.7892766 17.7989142  6.7892766 12.2940954  8.6242162  4.9543369
 [577]  6.7892766 15.9639746 14.1290350  3.1193973  6.7892766  8.6242162  8.6242162  8.6242162  6.7892766
 [586] 12.2940954 10.4591558  3.1193973  3.1193973  8.6242162  8.6242162  8.6242162  6.7892766  6.7892766
 [595] 10.4591558  4.9543369 10.4591558 21.4687934  4.9543369  1.2844577  6.7892766  4.9543369  6.7892766
 [604]  8.6242162 17.7989142  8.6242162  8.6242162  1.2844577  6.7892766 10.4591558 14.1290350  8.6242162
 [613]  6.7892766 10.4591558 12.2940954  4.9543369 25.1386726  8.6242162  1.2844577  8.6242162 10.4591558
 [622]  6.7892766 15.9639746 15.9639746 10.4591558 12.2940954 14.1290350  4.9543369  4.9543369  3.1193973
 [631]  8.6242162  1.2844577 10.4591558  8.6242162  6.7892766  8.6242162  4.9543369  4.9543369 10.4591558
 [640] 17.7989142  8.6242162  3.1193973 10.4591558  6.7892766  3.1193973  6.7892766  4.9543369  6.7892766
 [649]  8.6242162 10.4591558  4.9543369  6.7892766  6.7892766  8.6242162  4.9543369 14.1290350  4.9543369
 [658]  8.6242162  6.7892766  4.9543369  6.7892766 10.4591558  6.7892766 10.4591558  6.7892766 12.2940954
 [667]  8.6242162  6.7892766 12.2940954 12.2940954  6.7892766 10.4591558  8.6242162 12.2940954  4.9543369
 [676] 10.4591558  4.9543369 12.2940954  6.7892766  4.9543369  3.1193973  8.6242162  4.9543369 10.4591558
 [685] 10.4591558  4.9543369  8.6242162  4.9543369  6.7892766 19.6338538 10.4591558 15.9639746  6.7892766
 [694]  1.2844577  8.6242162 14.1290350 15.9639746 12.2940954  6.7892766  6.7892766 10.4591558 10.4591558
 [703] 10.4591558 10.4591558  6.7892766  8.6242162  4.9543369 15.9639746 15.9639746  6.7892766 12.2940954
 [712]  6.7892766  8.6242162 12.2940954  8.6242162  8.6242162  6.7892766  8.6242162 17.7989142 10.4591558
 [721]  6.7892766 14.1290350 12.2940954  4.9543369  3.1193973  6.7892766 10.4591558 12.2940954  3.1193973
 [730]  8.6242162  4.9543369  6.7892766 14.1290350  1.2844577 15.9639746  4.9543369  8.6242162  3.1193973
 [739]  4.9543369 12.2940954  6.7892766  3.1193973  4.9543369  4.9543369  8.6242162 10.4591558 14.1290350
 [748] 12.2940954  8.6242162  8.6242162 12.2940954  8.6242162 10.4591558  8.6242162  6.7892766 10.4591558
 [757]  6.7892766  8.6242162 12.2940954  8.6242162  6.7892766  4.9543369 15.9639746  6.7892766  8.6242162
 [766]  4.9543369 12.2940954  8.6242162  4.9543369 15.9639746 10.4591558  8.6242162  4.9543369  4.9543369
 [775] 12.2940954  6.7892766 10.4591558  6.7892766  6.7892766  6.7892766 10.4591558  6.7892766  1.2844577
 [784]  6.7892766 14.1290350 12.2940954 10.4591558 10.4591558  1.2844577 10.4591558 10.4591558  8.6242162
 [793] 10.4591558  4.9543369  6.7892766  8.6242162 12.2940954  6.7892766  6.7892766  8.6242162  8.6242162
 [802]  6.7892766 10.4591558  3.1193973  8.6242162  4.9543369  8.6242162  4.9543369  4.9543369 14.1290350
 [811]  4.9543369  3.1193973  8.6242162  4.9543369  8.6242162  3.1193973  8.6242162 14.1290350  8.6242162
 [820] 10.4591558  1.2844577  8.6242162  8.6242162 10.4591558 15.9639746  8.6242162  6.7892766 10.4591558
 [829]  8.6242162  4.9543369 14.1290350 14.1290350  8.6242162 12.2940954  4.9543369 14.1290350  6.7892766
 [838]  8.6242162  4.9543369 10.4591558 12.2940954  3.1193973  6.7892766 12.2940954  3.1193973  6.7892766
 [847] 10.4591558 12.2940954  4.9543369  1.2844577  8.6242162 15.9639746 10.4591558  8.6242162  3.1193973
 [856]  8.6242162 12.2940954 10.4591558  4.9543369  4.9543369  3.1193973 10.4591558 10.4591558 10.4591558
 [865] 14.1290350 12.2940954 14.1290350 12.2940954 14.1290350  6.7892766  8.6242162  4.9543369  8.6242162
 [874] 12.2940954  3.1193973  3.1193973 12.2940954 14.1290350  8.6242162  4.9543369  4.9543369  6.7892766
 [883]  3.1193973  6.7892766 14.1290350  3.1193973  8.6242162  8.6242162 10.4591558  3.1193973  8.6242162
 [892] 15.9639746  8.6242162 14.1290350 10.4591558 12.2940954 12.2940954  6.7892766 -0.5504819  4.9543369
 [901] 12.2940954  6.7892766  4.9543369  4.9543369  4.9543369  4.9543369  8.6242162 14.1290350 12.2940954
 [910]  4.9543369 15.9639746 10.4591558  8.6242162  4.9543369 10.4591558 10.4591558  8.6242162  4.9543369
 [919]  4.9543369  6.7892766  8.6242162 15.9639746  3.1193973 10.4591558 14.1290350  6.7892766  8.6242162
 [928]  6.7892766 15.9639746 14.1290350  8.6242162  6.7892766  1.2844577  6.7892766 14.1290350 14.1290350
 [937] -0.5504819 10.4591558  3.1193973  6.7892766 10.4591558 10.4591558  6.7892766  8.6242162 14.1290350
 [946]  8.6242162 10.4591558  6.7892766  6.7892766 10.4591558  4.9543369  6.7892766 14.1290350  1.2844577
 [955]  6.7892766 10.4591558  6.7892766 10.4591558 12.2940954 10.4591558  8.6242162 10.4591558 12.2940954
 [964]  4.9543369 10.4591558 12.2940954 10.4591558 14.1290350 12.2940954  8.6242162  6.7892766 -0.5504819
 [973] 12.2940954  4.9543369  4.9543369  6.7892766  6.7892766  8.6242162 14.1290350  3.1193973  6.7892766
 [982] 14.1290350  8.6242162 10.4591558 14.1290350  8.6242162 10.4591558 15.9639746 14.1290350  8.6242162
 [991]  4.9543369  1.2844577 10.4591558 10.4591558  3.1193973 12.2940954 10.4591558 10.4591558  8.6242162
[1000] 10.4591558
 [ reached 'max' / getOption("max.print") -- omitted 9000 entries ]
txt> mean(abs(res) > 2)
[1] 0.9682
txt> qqnorm(res)
txt> res2 <- replicate(10000, {
txt+ x <- sample(1:6, 30, replace = TRUE)
txt+ })
txt> res2 <- replicate(1000, {
txt+ a <- mean(x == 6)
txt+ x <- sample(1:6, 5, replace = TRUE)
txt+ })
txt> qqnorm(res2)
txt> qqnorm(res)

 ## res2 (p - 0.5, n = 35) had the longest 'tail' ends, i.e. large quantities of noise and variance. therefore, res1 (p = 0.01, n = 30) had the least deviating 'tail' ends, therefore closer to a normal distribution 


 ** As we have already seen, the CLT also applies to averages of quantitative data. A major difference with binary data, for which we know the variance is p(1−p)
, is that with quantitative data we need to estimate the population standard deviation.

In several previous exercises we have illustrated statistical concepts with the unrealistic situation of having access to the entire population. In practice, we do not have access to entire populations. Instead, we obtain one random sample and need to reach conclusions analyzing that data. dat is an example of a typical simple dataset representing just one sample. We have 12 measurements for each of two populations:

We think of X as a random sample from the population of all mice in the control diet and Y
 as a random sample from the population of all mice in the high fat diet.

Define the parameter μx
 as the average of the control population. We estimate this parameter with the sample average X¯
. What is the sample average? **  

txt> dat
   Diet Bodyweight
1  chow      21.51
2  chow      28.14
3  chow      24.04
4  chow      23.45
5  chow      23.68
6  chow      19.79
7  chow      28.40
8  chow      20.98
9  chow      22.51
10 chow      20.10
11 chow      26.91
12 chow      26.25
13   hf      25.71
14   hf      26.37
15   hf      22.80
16   hf      25.34
17   hf      24.97
18   hf      28.14
19   hf      29.58
20   hf      30.92
21   hf      34.02
22   hf      21.90
23   hf      31.53
24   hf      20.73

 ## dat dataset is only a small dataset of 24 variables. this is considered a sample dataset, and can be represent as X or Y 

txt> X <- filter(dat, Diet == "chow")
txt> Y <- filter(dat, Diet == "hf")
txt> X <- filter(dat, Diet == "chow")
txt> X <- filter(dat, Diet == "chow") %>% select(Bodyweight) %>% unlist()
txt> Y <- filter(dat, Diet == "hf") %>% select(Bodyweight) %>% unlist()

 ## parameters μX is the mean of sample X (control), therefore mean(X) 

txt> mean(X)
[1] 23.81333

 ## correction, we can't calculate μx (lower case x = entire population) because we don't have the entire dataset of the population, we only have the sample (dat). we calculated μX above i.e. the average of the control population sample as μX instead of estimate what μx could be 


 ** We don’t know μX
 , but want to use X¯
 to understand μX
. Which of the following uses CLT to understand how well X¯
 approximates μX
 ?
A) X¯
 follows a normal distribution with mean 0 and standard deviation 1.
B) μX
 follows a normal distribution with mean X¯
 and standard deviation σx12√
 where σx
 is the population standard deviation.
C) X¯
 follows a normal distribution with mean μX
 and standard deviation σx
 where σx
 is the population standard deviation.
D) X¯
 follows a normal distribution with mean μX
 and standard deviation σx12√
 where σx
 is the population standard deviation.
** 


 ## ans D: X bar (sample mean) will follow a normal distribution with mean μX and SD defined by sqrt(p*(1-p)/n). It's not B because X bar is a random variable, i.e. not fixed, therefore it makes more sense for X bar to follow a more 'stable' or fixed variable such as the mean of the entire dataset (μX) rather than the other way around. 


 ** The result above tells us the distribution of the following random variable: Z=12‾‾‾√X¯−μXσX
. What does the CLT tell us is the mean of Z
 (you don’t need code)? ** 


 ## with z-score, mean = 0 and sd = 1 

txt> p <- popsd(X)
txt> p
[1] 2.893862
txt> p/sqrt(12)
[1] 0.8353861

 ## dividng popsd / sqrt(n) gives the standard error. the sd (in popsd) is used to see how individual data points vary around the mean, however standard error is used to calculate how sample averages vary around the mean. this would mean taking a small sample size from the bodyweight values of mice > take an average > repeat several times > plot on graph > then use standard error = popsd / sqrt(n) to calculate how far away the sample averages are from the mean  


 **The result of 4 and 5 tell us that we know the distribution of the difference between our estimate and what we want to estimate, but don’t know. However, the equation involves the population standard deviation σX
, which we don’t know. Given what we discussed, what is your estimate of sigmaX? 


 ## sigmaX is the (population) standard deviation. we don't know popsd because we don't have the entire population data, just a sample of 12 mice. therefore, we need to estimate popsd with sd(). this still returns a value with units sigmaX (popsd), but it introduces a lot more uncertainty (bc the SD formula has n-1(?)) to take into account the estimated variability. 


 ## we can't use CLT to estimate because CLT requires that we know popsd (which is very uncommon to have). t-test uses sd() instead because it adapts to only sample datasets, and therefore produces a p-value that also takes into account the uncertainty 


 ## popsd is the true spread of data (but we don't have the entire population data)/ standard error = popsd / sqrt(n). standard error is how far away the sample averages vary away from each other. standard error is also used synonymously with standard deviation? 


 ## that is why in the question it says 'However, the equation involves the population standard deviation σX, which we don’t know.', i.e. you can't calculate CLT without popsd. 


 ## therefore: use popsd() when you have the entire population dataset, but use sd() when you only have the sample dataset. sd() introduces more uncertainty to make an estimation of the true spread in popsd. sd() is also adopted in t-tests when investigating the significance of sample mean values 


 ** Use the CLT to approximate the probability that our estimate X¯
 is off by more than 5.21 ounces from μX ** 


 ## we already established that we cannot use CLT as we do not have popsd(). however, if we choose to use an estimate of popsd() with sd(), we can substitute sd() into the CLT equation. 


 ## the numerator in the z score formula is the 5.21 ounces from the popualtion mean. the numerator is the (sample mean (Xbar) - expected (population) mean). however, we don't know the population mean. so hypothetically, the q is asking what is the probability that the sample mean will be 5.21 ounces from the true mean? i.e. the q has assumed 


 ## therefore, 5.21 acts as the numerator 


 ## standard error sqrt(p(1-p)/n is used for binary data (rolling dice), but for quantitative data we use sd / sqrt(n) (where sd is the sigmaX) 


 ## therefore the updated z score formula is the sample and expected means, divided by the standard error. standard error is sd / sqrt(n), therefore the final z formula = 5.21 / (sd / sqrt(n)) 

txt> 5.21/(sd(X)/sqrt(12))
[1] 5.971126
txt> txtStop
function() {
  removeTaskCallback('r2txt')
  if( R2txt.vars$closecon ) {
    close( R2txt.vars$con )
  }
  if( R2txt.vars$cmdfile && R2txt.vars$closecon2 ) {
    close( R2txt.vars$con2 )
  }
  options( prompt=R2txt.vars$prompt,
           continue=R2txt.vars$continue )
  if(R2txt.vars$res) {
      sink()
      close(R2txt.vars$outcon)
  }
  evalq( rm(list=ls()), envir=R2txt.vars )
  invisible(NULL)
}
<bytecode: 0x7fac73c8f6d0>
<environment: namespace:TeachingDemos>


 ** Now we introduce the concept of a null hypothesis. We don’t know μx
 nor μy
. We want to quantify what the data say about the possibility that the diet has no effect: μx=μy
. If we use CLT, then we approximate the distribution of X¯
 as normal with mean μX
 and standard deviation σX
 and the distribution of Y¯
 as normal with mean μy
 and standard deviation σy
. This implies that the difference Y¯−X¯
 has mean 0
. We described that the standard deviation of this statistic (the standard error) is SE(X¯−Y¯)=σ2y/12+σ2x/12‾‾‾‾‾‾‾‾‾‾‾‾‾√
 and that we estimate the population standard deviations σx
 and σy
 with the sample estimates. What is the estimate of SE(X¯−Y¯)=σ2y/12+σ2x/12‾‾‾‾‾‾‾‾‾‾‾‾‾√
 ? **  

> `?`(`?`(see))
> `?`(se)
No documentation for ‘se’ in specified packages and libraries:
you could try ‘??se’
> `?`(`?`(se))

 ## in a null hypothesis, we are proving that there is no difference between two groups. in this example, the null hypothesis is that the bodyweight between the two control and high-fructose diet mice groups have no difference. this means that the Xbar is equal to Ybar (x = control, y = hf). x/y bar is the sample of X and Y because we do not literally have the entire population, hence the sample 'bar'. in a null hypothesis, we assume that if Xbar and Ybar both follow a normal distribution (i.e. reflective of the real populations X and Y) with meanx and sdy (vice versa with y), that the difference between Xbar and Ybar means are 0 - ie no difference (null hypothesis) 

> url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/femaleMiceWeights.csv"
> filename <- "femaleMiceWeights.csv"
> if (!file.exists("femaleMiceWeights.csv")) download(url, destfile = filename)
> dat <- read.csv(filename)
> head(dat)
  Diet Bodyweight
1 chow      21.51
2 chow      28.14
3 chow      24.04
4 chow      23.45
5 chow      23.68
6 chow      19.79
> dat
   Diet Bodyweight
1  chow      21.51
2  chow      28.14
3  chow      24.04
4  chow      23.45
5  chow      23.68
6  chow      19.79
7  chow      28.40
8  chow      20.98
9  chow      22.51
10 chow      20.10
11 chow      26.91
12 chow      26.25
13   hf      25.71
14   hf      26.37
15   hf      22.80
16   hf      25.34
17   hf      24.97
18   hf      28.14
19   hf      29.58
20   hf      30.92
21   hf      34.02
22   hf      21.90
23   hf      31.53
24   hf      20.73
> X <- filter(dat, Diet == "chow") %>% select(Bodyweight) %>% unlist()
> head(X)
Bodyweight1 Bodyweight2 Bodyweight3 Bodyweight4 Bodyweight5 Bodyweight6 
      21.51       28.14       24.04       23.45       23.68       19.79 
> Y <- filter(dat, Diet == "hf") %>% select(Bodyweight) %>% unlist()
> head(Y)
Bodyweight1 Bodyweight2 Bodyweight3 Bodyweight4 Bodyweight5 Bodyweight6 
      25.71       26.37       22.80       25.34       24.97       28.14 

 SE(X¯−Y¯)=σ2y/12+σ2x/12‾‾‾‾‾‾‾‾‾‾‾‾‾√ 


 ## sigma = population variance = popsd() 


 Standard error (SE) = sqrt(p(1-p)/n for binary data, but for quantitative data sd / sqrt(n) 


 ## the question appears to be using the quantitative data formula of sd / sqrt(n),  


 ## the above dat variable is a data sample of a larger population of mice, therefore we cannot use popsd(), and must use sd() to account for the larger variance in the data. 


 ## recap, sigma = standard deviation, sigma squared = variance. the above formula in the q is using sigma squared i.e. variance. however, since the formula is all under a square root, this means that we will need the sd anyway. the n (12) is also already under a sqrt root. therefore, we could do sd / sqrt(12), or, sqrt(variance / n)(?) 

> (sd(X)/sqrt(12)) + (sd(Y)/sqrt(12))
[1] 2.055409

 ## standard error of Xbar Ybar is equal to 2.06 


 ## since X and Y are samples from datasets x and y respectively, X and Y are random variables and will differ every time. therefore, standard error is used to calculate the variability between different sample means (bar = mean). standard deviation describes the variability between each individual observations within the same sample (ie how much variance in the sample from the mean) 


 ** So now we can compute Y¯−X¯
 as well as an estimate of this standard error and construct a t-statistic. What is this t-statistic? ** 


 ## t-statistic is a value that describes if the null is true - taking into account the observed difference between the two samples, divided by the standard error of the two samples. SE is calculated using the above formula, and got 2.06. if the null is true, then there shouldn't be any difference in means betwen the 2 samples anyway. finishing and using this formula: t-statistic = (Ybar - Xbar) / SE(Xbar - Ybar) 

> mean(Y) - mean(X)
[1] 3.020833
> (mean(Y) - mean(X))/2.06
[1] 1.466424

 ## t-statistic. = 1.47 


 ## the t-statistic takes the mean difference / standard error of the 2 samples to produce a *ratio* to describe how many SE the sample mean is from the actual population sd. because sd() is used in the standard error formula (?) 


 ## i.e. t-statistic is used to compare means. 


 ## techincally, the t-statistic numerator should be (Ybar - Xbar) - (μy−μx), where x and y are the entire population dataset, but we don't have the entire population, and we can assume that (μy−μx) = 0 because we are investigating that in the null hypothesis, that there is no difference between them. 


 ** If we apply the CLT, what is the distribution of this t-statistic?
A) Normal with mean 0 and standard deviation 1.
B) t-distributed with 22 degrees of freedom.
C) Normal with mean 0 and standard deviation σ2y/12+σ2x/12‾‾‾‾‾‾‾‾‾‾‾‾‾√
.
D) t-distributed with 12 degrees of freedom. ** 


 to use CLT, we need to know the entire population data - but we don't know. we calculated SE to provide an *estimate* of what the true standard error is. this is because in our standard error estimate we used sd(), which adds variability to take into account that we do not have the entire population. 


 ## ANS: D, degrees of freedom describes the variance (t-distribution). as we do not have the entire population dataset, we used sd().the formula for sd uses n-1 as the denominator, i.e. make a smaller denominator for a larger sd value (i.e. larger standard deviation aka larger variance). degrees of freedom is equal to n-1. therefore, as we are calculating the t-statistic using two samples (X and Y), the total sample size becomes (12-1 + 12-1) = 22 degrees of freedom 


 ** Now we are ready to compute a p-value using the CLT. What is the probability of observing a quantity as large as what we computed in 10, when the null distribution is true? ** 


 or is answer C?... 


  standard error is calculated using formula: 'SE(X¯−Y¯)=σ2y/12+σ2x/12‾‾‾‾‾‾‾‾‾‾‾‾‾√
 ?'. i instead simplified it by using values i already had, i.e. i did not have variance (sigma squared), but i did have standard deviation (sigma). therefore, i did sd / sqrt(n). 


 ## instead of translating the formmula, i could do var() to calculate sigma squared, this should give the same value as before (2.06) 

> (var(X)/sqrt(12)) + (var(Y)/sqrt(12))
[1] 7.484227
> sqrt(var(X)/(12)) + (var(Y)/(12))
[1] 2.27173
> var
function (x, y = NULL, na.rm = FALSE, use) 
{
    if (missing(use)) 
        use <- if (na.rm) 
            "na.or.complete"
        else "everything"
    na.method <- pmatch(use, c("all.obs", "complete.obs", "pairwise.complete.obs", 
        "everything", "na.or.complete"))
    if (is.na(na.method)) 
        stop("invalid 'use' argument")
    if (is.data.frame(x)) 
        x <- as.matrix(x)
    else if (!is.null(x)) 
        stopifnot(is.atomic(x))
    if (is.data.frame(y)) 
        y <- as.matrix(y)
    else if (!is.null(y)) 
        stopifnot(is.atomic(y))
    .Call(C_cov, x, y, na.method, FALSE)
}
<bytecode: 0x7f928cef0e98>
<environment: namespace:stats>
> `?`(var)

 slight difference why? maybe var() is more accurate, or my other above method was wrong 

> obs <- abs(mean(X) - mean(Y))
> obs
[1] 3.020833
> mean(X) - mean(Y)
[1] -3.020833
> se <- sqrt(var(X)/(12)) + (var(Y)/(12))
> tstat <- obs/se
> tstat
[1] 1.32975

 ## again, the t-statistic numerator should be sample mean differences (obs) - population mean difference. however, we do not have the entire population data. however, when investigating the null hypothesis, we can assume that pop mean difference = 0 


 ## t-statistic (uses the CLT), the null distribution is approximated by normal distribution with means 0 and variance 1. this is because that if the null hypothesis true, the t-statistic behaves like a normal distribution (i.e. no difference between sample means), therefore mean difference between the two groups = 0 (mean=0), and therefore have the same standard deviation (relatively to each other) (sd = 1). since we only have 1 sample from each group, we cannot calculate standard error. however, we can use standard deviation as an estimate to what standard deviation could be. therefore, although CLT uses standard error, we can use sd value as an estimate of se in the equation. 

> `?`(ppnorm)
No documentation for ‘ppnorm’ in specified packages and libraries:
you could try ‘??ppnorm’
> `?`(pnorm)

 ** the null distribution is approximated by normal distribution with means 0 and variance 1 ** 


 ** Now we are ready to compute a p-value using the CLT. What is the probability of observing a quantity as large as what we computed in 10, when the null distribution is true? ** 


 ## t-statistic is a value that explains the observed difference between the two sample populations, whilst factoring in the noise from the data via standard error. therefore, the lower the difference between the two sample populations, the more supportive it is of the null hypothesis (i.e. no difference), and therefore a lower tstat value. 


 the t-statistic value of 1.33 represents the difference in bodyweight between the two populations of mice on different diets. as above, this tstat value also factors in the noise from the data via standard error. 


 ## note 1.33 does *not* represent bodyweight directly, but rather a standardised unit to measure bodyweight difference, aka 1.33 standard errors 


 ## pnorm() helps explain how likely it would be that we would get 1.33 bodyweight difference between the two diet populations if we took another sample. we currently only have 1 sample from each group available, so we use pnorm() to produce a p-value explaining the probability that < 1.33 

> pnorm(tstat)
[1] 0.9081997

 ## as we are describing the null hypothesis, we do 1 - pnorm(tstat) to get what proportion of values would be above 1.33 

> 1 - pnorm(tstat)
[1] 0.0918003

 ## the null hypothesis explains that there shouldn't be a difference in the mean between the two samples. we used the t-statistics formula to estimate the difference between the means of the two diet samples, factoring in the 'noise' via se. we got a value of 1.33. if there was truly no difference, the t-statistic would have  = 0. if we hypothetically sampled from the two different diet populations again, any t-statistic value < 1.33 would further support the null. however, we want to see the probability that the t-statistic value is *above* > 1.33 - this is because this leans more towards that there is actually a difference between the two different samples (i.e. to reject the null). we get all the values that are > 1.33 by simply doing 1 - pnorm(tstat). this gives a one-sided tailed tests i.e. we're only looking at the higher end of the tail (qnorm distribution plot). we *2 factor in the other tail to get the final p-value to reject the null.  

> (1 - pnorm(tstat)) * 2
[1] 0.1836006

 ## 0.18 > 0.5, therefore we accept the null because the p-value is insigificant. the 0.18 explains that 18% of the time, i would see a difference between the two groups *by random chance*. this is too high of a likelihood to confirm for sure that there is actually a difference.   


 ## however if it were < 0.05, this would be a suitable threshold to explain that there is small enough of a chance i.e.  less than 5% chance that the significant difference I am seeing when comparing the two samples is due to random chance, so it's more acceptable 

> txtStop
function() {
  removeTaskCallback('r2txt')
  if( R2txt.vars$closecon ) {
    close( R2txt.vars$con )
  }
  if( R2txt.vars$cmdfile && R2txt.vars$closecon2 ) {
    close( R2txt.vars$con2 )
  }
  options( prompt=R2txt.vars$prompt,
           continue=R2txt.vars$continue )
  if(R2txt.vars$res) {
      sink()
      close(R2txt.vars$outcon)
  }
  evalq( rm(list=ls()), envir=R2txt.vars )
  invisible(NULL)
}
<bytecode: 0x7f92918a8f20>
<environment: namespace:TeachingDemos>

 **CLT provides an approximation for cases in which the sample size is large. In practice, we can’t check the assumption because we only get to see 1 outcome (which you computed above). As a result, if this approximation is off, so is our p-value. As described earlier, there is another approach that does not require a large sample size, but rather that the distribution of the population is approximately normal. We don’t get to see this distribution so it is again an assumption, although we can look at the distribution of the sample with qqnorm(X) and qqnorm(Y). If we are willing to assume this, then it follows that the t-statistic follows t-distribution. What is the p-value under the t-distribution approximation? Hint: use the t.test function. 


 ## with CLT, the more samples taken / larger sample size, there more closer the data reaches a normal distribution. however, where large sample is not possible, we use t-test. but a t-test assumes a normal distribution of the data 

> url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/femaleMiceWeights.csv"
> filename <- "femaleMiceWeights.csv"
> if (!file.exists("femaleMiceWeights.csv")) download(url, destfile = filename)
> dat <- read.csv(filename)
> `?`(t.test)
> X <- filter(dat, Diet == "chow") %>% select(Bodyweight) %>% unlist()
> head(X)
Bodyweight1 Bodyweight2 Bodyweight3 Bodyweight4 Bodyweight5 Bodyweight6 
      21.51       28.14       24.04       23.45       23.68       19.79 
> Y <- filter(dat, Diet == "hf") %>% select(Bodyweight) %>% unlist()
> t.test(X, Y)

	Welch Two Sample t-test

data:  X and Y
t = -2.0552, df = 20.236, p-value = 0.053
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -6.08463229  0.04296563
sample estimates:
mean of x mean of y 
 23.81333  26.83417 

> qqnorm(X)
> qqline(X)
> qqnorm(Y)
> qqline(Y)
> t.test(X)

	One Sample t-test

data:  X
t = 27.292, df = 11, p-value = 1.863e-11
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
 21.89290 25.73376
sample estimates:
mean of x 
 23.81333 

> t.test(X, Y)

	Welch Two Sample t-test

data:  X and Y
t = -2.0552, df = 20.236, p-value = 0.053
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -6.08463229  0.04296563
sample estimates:
mean of x mean of y 
 23.81333  26.83417 


 ## accept null hypothesis: there is no significant difference between hf and control chow diet on mice bodyweight (p > 0.05) 


 ** With the CLT distribution, we obtained a p-value smaller than 0.05 and with the t-distribution, one that is larger. They can’t both be right. What best describes the difference?
A) A sample size of 12 is not large enough, so we have to use the t-distribution approximation.
B) These are two different assumptions. The t-distribution accounts for the variability introduced by the estimation of the standard error and thus, under the null, large values are more probable under the null distribution.
C) The population data is probably not normally distributed so the t-distribution approximation is wrong.
D) Neither assumption is useful. Both are wrong. ** 


 ## C? difference between CLT and t.test is that we can only assume that the data follows a normal distribution, so if it doesn't, this differs from the CLT p value? 

> `?`(t.test)

 ## ANS: B. t.test considers higher uncertainty in the formula, hence makes the tails of the normal distribution larger, hence 'large values are more probable'. therefore, due to the increased variability and larger tails, this distorts the p-value to be less specific, hence a larger p-value, which means harder to conclude a significant p-value, i.e. more likely for values to fall in the null. 

> txtStop
function() {
  removeTaskCallback('r2txt')
  if( R2txt.vars$closecon ) {
    close( R2txt.vars$con )
  }
  if( R2txt.vars$cmdfile && R2txt.vars$closecon2 ) {
    close( R2txt.vars$con2 )
  }
  options( prompt=R2txt.vars$prompt,
           continue=R2txt.vars$continue )
  if(R2txt.vars$res) {
      sink()
      close(R2txt.vars$outcon)
  }
  evalq( rm(list=ls()), envir=R2txt.vars )
  invisible(NULL)
}
<bytecode: 0x7fdd6d11a628>
<environment: namespace:TeachingDemos>
> dat <- read.csv("femaleMiceWeights.csv")
> head(dat)
  Diet Bodyweight
1 chow      21.51
2 chow      28.14
3 chow      24.04
4 chow      23.45
5 chow      23.68
6 chow      19.79
> "dat"
[1] "dat"
> dat
   Diet Bodyweight
1  chow      21.51
2  chow      28.14
3  chow      24.04
4  chow      23.45
5  chow      23.68
6  chow      19.79
7  chow      28.40
8  chow      20.98
9  chow      22.51
10 chow      20.10
11 chow      26.91
12 chow      26.25
13   hf      25.71
14   hf      26.37
15   hf      22.80
16   hf      25.34
17   hf      24.97
18   hf      28.14
19   hf      29.58
20   hf      30.92
21   hf      34.02
22   hf      21.90
23   hf      31.53
24   hf      20.73
> control <- filter(dat, Diet == "chow") %>% select(Bodyweight) %>% 
+ unlist()
> treatment <- filter(dat, Diet == "hf") %>% select(Bodyweight) %>% 
+ unlist()
> diff <- mean(treatment) - mean(control)
> diff
[1] 3.020833
> abs(diff)
[1] 3.020833

 ## we don't have popsd, just a sample, so we use sd() to account for the extra variance 


 ## SE = popsd / √n 


 apply SE to diff - gives us the SE of variance between control vs treatment. otherwise SE on sample averages just gives variations of the sample control or treatment values itself 


 ## SE = √ sigma^1 / n 


 ## aka SE = variance / √n 

> se <- sqrt(var(treatment)/length(treatment) + var(control)/length(control))
> se
[1] 1.469867

 above is the standard error of variation between the two groups (control and treatment( 


 ## dividing the difference in sample averages by the standard error gives the bodyweight value equivalent to one standard error 

> tstat <- diff/se
> tstat
[1] 2.055174

 ## the above tstatistic value is a random variable - the diff value varies depending on the sample taken of the two groups, and the se value varies as a result 


 CLT would explain that with a larger sample size, the sample averages are normal, therefore the difference between these two samples are also normal, therefore CLT states that tstat sample average differences is normal with mean 0 and SE 1 


 ## but with tstat, how often does this random variable exceed/deviate far from the diff? this gives p-value 

> righttail <- 1 - pnorm(abs(tstat))
> lefttail <- pnorm(-abs(tstat))
> pval <- righttail + lefttail
> pval
[1] 0.0398622
> t.test(treatment, control)

	Welch Two Sample t-test

data:  treatment and control
t = 2.0552, df = 20.236, p-value = 0.053
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -0.04296563  6.08463229
sample estimates:
mean of x mean of y 
 26.83417  23.81333 


 ## CLT behind tstat assumes normal distribution - but hard to assume normal if we have a very small sample size (12) for treatment and control 


 use t.test which includes a 'degrees of freedom' parameter. they still assume normal distribution and apply CLT, but uses the extra dof parameter. and this gave a higher p-value to account for the higher uncertainty that comes with a smaller sample size  


 ## this is because the denominator for tstat is the SE, which is a random variable (includes n in the formula, hence accounts for sample size)) 


 ## note that t.test() is more likely to have false negatives as a result of increasing uncertainty, as seen with a higher p-value i.e. less likely to confirm a significant difference. vice versa with CLT - more likely to affirm a false positive 

> dat <- read.csv("mice_pheno.csv")
> head(dat)
  Sex Diet Bodyweight
1   F   hf      31.94
2   F   hf      32.48
3   F   hf      22.82
4   F   hf      19.92
5   F   hf      32.22
6   F   hf      27.50
> dat
    Sex Diet Bodyweight
1     F   hf     31.940
2     F   hf     32.480
3     F   hf     22.820
4     F   hf     19.920
5     F   hf     32.220
6     F   hf     27.500
7     F   hf     27.560
8     F   hf     36.440
9     F   hf     19.390
10    F   hf     23.160
11    F   hf     24.290
12    F   hf     18.780
13    F   hf     25.430
14    F   hf     24.300
15    F   hf     33.900
16    F   hf     31.470
17    F   hf     32.010
18    F   hf     18.520
19    F   hf     26.860
20    F   hf     25.410
21    F   hf     29.180
22    F   hf     25.300
23    F   hf     29.640
24    F   hf     20.730
25    F   hf     28.260
26    F chow     27.030
27    F chow     24.800
28    F chow     27.020
29    F chow     28.070
30    F chow     23.550
31    F chow     22.720
32    F chow     24.820
33    F chow     21.600
34    F chow     23.980
35    F chow     26.600
36    F chow     19.240
37    F chow     21.430
38    F chow     22.730
39    F chow     20.100
40    F chow     20.600
41    F chow     21.490
42    F chow     24.730
43    F chow     27.920
44    F chow     27.510
45    F chow     19.880
46    F chow     20.720
47    F chow     24.000
48    F chow     25.080
49    F chow     25.270
50    F chow     22.080
51    F chow     20.520
52    F chow     23.390
53    F chow     19.870
54    F chow     17.950
55    F chow     31.830
56    F chow     21.710
57    F chow     29.990
58    F chow     20.890
59    F chow     29.600
60    F chow     22.770
61    F chow     26.030
62    F chow     36.840
63    F chow     26.250
64    F chow     22.930
65    F chow     28.250
66    F chow     23.840
67    F chow     20.530
68    F chow     24.100
69    F chow     24.790
70    F chow     23.680
71    F chow     21.860
72    F chow     27.250
73    F chow     21.550
74    F chow     24.120
75    F chow     23.070
76    F   hf     20.800
77    F   hf     24.540
78    F   hf     27.280
79    F   hf     22.130
80    F   hf     27.780
81    F   hf     28.010
82    F   hf     19.180
83    F   hf     21.400
84    F   hf     27.530
85    F   hf     28.610
86    F   hf     20.450
87    F   hf     23.000
88    F   hf     28.260
89    F   hf     24.760
90    F   hf     23.820
91    F   hf     21.900
92    F   hf     26.070
93    F   hf     31.150
94    F   hf     27.920
95    F   hf     19.810
96    F   hf     24.940
97    F   hf     22.600
98    F   hf     22.390
99    F   hf     34.930
100   F   hf     29.660
101   F   hf     26.460
102   F chow     20.430
103   F chow     24.820
104   F chow     25.430
105   F chow     22.120
106   F chow     20.990
107   F chow     23.280
108   F chow     25.780
109   F chow     22.000
110   F chow     20.740
111   F chow     21.510
112   F chow     26.850
113   F chow     25.540
114   F chow     22.510
115   F chow     21.920
116   F chow     21.320
117   F chow     23.590
118   F chow     26.140
119   F chow     20.270
120   F chow     29.600
121   F chow     24.770
122   F chow     22.360
123   F chow     21.650
124   F chow     22.080
125   F chow     26.590
126   F chow     24.600
127   F   hf     21.880
128   F   hf     26.500
129   F   hf     24.550
130   F   hf     16.560
131   F   hf     29.180
132   F   hf     26.070
133   F   hf     17.540
134   F   hf     26.180
135   F   hf     25.260
136   F   hf     27.500
137   F   hf     23.140
138   F   hf     31.410
139   F   hf     25.140
140   F   hf     22.120
141   F   hf     17.010
142   F   hf     22.800
143   F   hf     25.370
144   F   hf     28.610
145   F   hf     22.130
146   F   hf     21.660
147   F   hf     24.900
148   F   hf     33.130
149   F   hf     29.580
150   F   hf     23.050
151   F chow     22.190
152   F chow     29.190
153   F chow     25.140
154   F chow     23.190
155   F chow     27.360
156   F chow     23.530
157   F chow     23.540
158   F chow     18.410
159   F chow     28.140
160   F chow     23.340
161   F chow     20.110
162   F chow     18.080
163   F chow     21.030
164   F chow     24.230
165   F chow     19.670
166   F chow     22.660
167   F chow     26.660
168   F chow     20.690
169   F chow     27.420
170   F chow     21.910
171   F chow     16.820
172   F chow     24.470
173   F chow     23.960
174   F chow     23.180
175   F chow     28.800
176   F   hf     23.980
177   F   hf     26.370
178   F   hf     24.050
179   F   hf     31.180
180   F   hf     34.300
181   F   hf     31.630
182   F   hf     23.830
183   F   hf     25.840
184   F   hf     26.840
185   F   hf     36.230
186   F   hf     23.520
187   F   hf     24.650
188   F   hf     24.470
189   F   hf     39.280
190   F   hf     26.420
191   F   hf     18.550
192   F   hf     20.670
193   F   hf     23.430
194   F   hf     20.880
195   F   hf     18.730
196   F   hf     24.640
197   F   hf     25.220
198   F   hf     29.100
199   F   hf     25.340
200   F   hf     34.610
201   F chow     26.370
202   F chow     23.610
203   F chow     26.070
204   F chow     27.750
205   F chow     23.700
206   F chow     23.730
207   F chow     24.490
208   F chow     22.870
209   F chow     29.230
210   F chow     21.460
211   F chow     22.120
212   F chow     33.470
213   F chow     24.960
214   F chow     26.150
215   F chow     24.890
216   F chow     19.410
217   F chow     26.360
218   F chow     26.470
219   F chow     23.190
220   F chow     22.320
221   F chow     20.030
222   F chow     23.510
223   F chow     21.350
224   F chow     21.580
225   F chow     22.270
226   F   hf     21.790
227   F   hf     18.789
228   F   hf     20.290
229   F   hf     26.440
230   F   hf     25.880
231   F   hf     23.480
232   F   hf     22.980
233   F   hf     24.040
234   F   hf     32.960
235   F   hf     23.090
236   F   hf     24.290
237   F   hf     28.720
238   F   hf     29.930
239   F   hf     26.500
240   F   hf     23.260
241   F   hf     19.210
242   F   hf     21.150
243   F   hf     20.230
244   F   hf     18.240
245   F   hf     15.970
246   F   hf     30.810
247   F   hf     25.380
248   F   hf     30.340
249   F   hf     31.530
250   F   hf     22.190
251   F chow     23.090
252   F chow     23.880
253   F chow     24.040
254   F chow     27.150
255   F chow     18.800
256   F chow     28.070
257   F chow     24.460
258   F chow     25.420
259   F chow     20.280
260   F chow     24.060
261   F chow     15.510
262   F chow     22.510
263   F chow     15.940
264   F chow     19.900
265   F chow     19.440
266   F chow     22.180
267   F chow     25.970
268   F chow     25.960
269   F chow     23.120
270   F chow     20.980
271   F chow     24.780
272   F chow     22.560
273   F chow     20.360
274   F chow     16.050
275   F chow     17.950
276   F   hf     37.520
277   F   hf     28.880
278   F   hf     22.620
279   F   hf     22.570
280   F   hf     28.720
281   F   hf     25.110
282   F   hf     25.220
283   F   hf     25.410
284   F   hf     27.220
285   F   hf     23.440
286   F   hf     27.790
287   F   hf     31.100
288   F   hf     25.710
289   F   hf     25.990
290   F   hf     28.550
291   F   hf     24.970
292   F   hf     39.730
293   F   hf     27.230
294   F   hf     27.970
295   F   hf     25.230
296   F   hf     21.800
297   F   hf     25.620
298   F   hf     24.150
299   F   hf     50.490
300   F   hf     30.120
301   F chow     22.710
302   F chow     28.220
303   F chow     21.500
304   F chow     20.300
305   F chow     19.960
306   F chow     19.070
307   F chow     22.350
308   F chow     20.540
309   F chow     30.450
310   F chow     23.540
311   F chow     20.610
312   F chow     20.180
313   F chow     20.590
314   F chow     23.320
315   F chow     26.350
316   F chow     22.910
317   F chow     25.100
318   F chow     28.460
319   F chow     21.310
320   F chow     28.530
321   F chow     28.430
322   F chow     20.810
323   F chow     27.000
324   F chow     24.550
325   F chow     21.180
326   F chow     21.770
327   F chow     23.800
328   F chow     20.990
329   F chow     23.110
330   F chow     24.820
331   F chow     22.590
332   F chow     18.470
333   F chow     21.100
 [ reached 'max' / getOption("max.print") -- omitted 513 rows ]
> control <- filter(dat, Diet == "chow") %>% select(Bodyweight) %>% 
+ unlist()
> treatment <- filter(dat, Diet == "hf") %>% select(Bodyweight) %>% 
+ unlist()
> t.test(control, treatment)

	Welch Two Sample t-test

data:  control and treatment
t = -7.1932, df = 735.02, p-value = 1.563e-12
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -3.906857 -2.231533
sample estimates:
mean of x mean of y 
 27.41281  30.48201 


 ## very small p value < 0.05, reject null, assumed normal distribution. despite t.test more likely to affirm false negative, the very small p value gives confidence due to large population / sample size 


 ## CONFIDENCE INTERVALS - however, p-values may find a significant difference of e.g. 1 microgram difference in bodyweight between groups, but does this 1 microgram matter? is it 'scientifically' significant/relevant? use confidence intervals, don't always rely on p-value to affirm scientific investigation 

> dat <- read.csv("mice_pheno.csv")
> chowPopulation <- filter(dat, Sex == "F", Diet == "chow")
> chowPopulation
    Sex Diet Bodyweight
1     F chow      27.03
2     F chow      24.80
3     F chow      27.02
4     F chow      28.07
5     F chow      23.55
6     F chow      22.72
7     F chow      24.82
8     F chow      21.60
9     F chow      23.98
10    F chow      26.60
11    F chow      19.24
12    F chow      21.43
13    F chow      22.73
14    F chow      20.10
15    F chow      20.60
16    F chow      21.49
17    F chow      24.73
18    F chow      27.92
19    F chow      27.51
20    F chow      19.88
21    F chow      20.72
22    F chow      24.00
23    F chow      25.08
24    F chow      25.27
25    F chow      22.08
26    F chow      20.52
27    F chow      23.39
28    F chow      19.87
29    F chow      17.95
30    F chow      31.83
31    F chow      21.71
32    F chow      29.99
33    F chow      20.89
34    F chow      29.60
35    F chow      22.77
36    F chow      26.03
37    F chow      36.84
38    F chow      26.25
39    F chow      22.93
40    F chow      28.25
41    F chow      23.84
42    F chow      20.53
43    F chow      24.10
44    F chow      24.79
45    F chow      23.68
46    F chow      21.86
47    F chow      27.25
48    F chow      21.55
49    F chow      24.12
50    F chow      23.07
51    F chow      20.43
52    F chow      24.82
53    F chow      25.43
54    F chow      22.12
55    F chow      20.99
56    F chow      23.28
57    F chow      25.78
58    F chow      22.00
59    F chow      20.74
60    F chow      21.51
61    F chow      26.85
62    F chow      25.54
63    F chow      22.51
64    F chow      21.92
65    F chow      21.32
66    F chow      23.59
67    F chow      26.14
68    F chow      20.27
69    F chow      29.60
70    F chow      24.77
71    F chow      22.36
72    F chow      21.65
73    F chow      22.08
74    F chow      26.59
75    F chow      24.60
76    F chow      22.19
77    F chow      29.19
78    F chow      25.14
79    F chow      23.19
80    F chow      27.36
81    F chow      23.53
82    F chow      23.54
83    F chow      18.41
84    F chow      28.14
85    F chow      23.34
86    F chow      20.11
87    F chow      18.08
88    F chow      21.03
89    F chow      24.23
90    F chow      19.67
91    F chow      22.66
92    F chow      26.66
93    F chow      20.69
94    F chow      27.42
95    F chow      21.91
96    F chow      16.82
97    F chow      24.47
98    F chow      23.96
99    F chow      23.18
100   F chow      28.80
101   F chow      26.37
102   F chow      23.61
103   F chow      26.07
104   F chow      27.75
105   F chow      23.70
106   F chow      23.73
107   F chow      24.49
108   F chow      22.87
109   F chow      29.23
110   F chow      21.46
111   F chow      22.12
112   F chow      33.47
113   F chow      24.96
114   F chow      26.15
115   F chow      24.89
116   F chow      19.41
117   F chow      26.36
118   F chow      26.47
119   F chow      23.19
120   F chow      22.32
121   F chow      20.03
122   F chow      23.51
123   F chow      21.35
124   F chow      21.58
125   F chow      22.27
126   F chow      23.09
127   F chow      23.88
128   F chow      24.04
129   F chow      27.15
130   F chow      18.80
131   F chow      28.07
132   F chow      24.46
133   F chow      25.42
134   F chow      20.28
135   F chow      24.06
136   F chow      15.51
137   F chow      22.51
138   F chow      15.94
139   F chow      19.90
140   F chow      19.44
141   F chow      22.18
142   F chow      25.97
143   F chow      25.96
144   F chow      23.12
145   F chow      20.98
146   F chow      24.78
147   F chow      22.56
148   F chow      20.36
149   F chow      16.05
150   F chow      17.95
151   F chow      22.71
152   F chow      28.22
153   F chow      21.50
154   F chow      20.30
155   F chow      19.96
156   F chow      19.07
157   F chow      22.35
158   F chow      20.54
159   F chow      30.45
160   F chow      23.54
161   F chow      20.61
162   F chow      20.18
163   F chow      20.59
164   F chow      23.32
165   F chow      26.35
166   F chow      22.91
167   F chow      25.10
168   F chow      28.46
169   F chow      21.31
170   F chow      28.53
171   F chow      28.43
172   F chow      20.81
173   F chow      27.00
174   F chow      24.55
175   F chow      21.18
176   F chow      21.77
177   F chow      23.80
178   F chow      20.99
179   F chow      23.11
180   F chow      24.82
181   F chow      22.59
182   F chow      18.47
183   F chow      21.10
184   F chow      25.83
185   F chow      16.31
186   F chow      24.79
187   F chow      26.08
188   F chow      32.74
189   F chow      27.26
190   F chow      31.24
191   F chow      33.81
192   F chow      23.52
193   F chow      27.73
194   F chow      28.26
195   F chow      23.30
196   F chow      18.83
197   F chow      27.70
198   F chow      19.79
199   F chow      27.20
200   F chow      25.40
201   F chow      26.75
202   F chow      23.45
203   F chow      24.77
204   F chow      23.39
205   F chow      22.95
206   F chow      21.84
207   F chow      28.40
208   F chow      28.21
209   F chow      33.36
210   F chow      29.13
211   F chow      24.21
212   F chow      22.99
213   F chow      24.68
214   F chow      24.67
215   F chow      25.12
216   F chow      23.95
217   F chow      25.69
218   F chow      28.36
219   F chow      24.96
220   F chow      27.36
221   F chow      26.91
222   F chow      26.58
223   F chow      23.39
224   F chow      20.25
225   F chow      23.22
> mu_chow <- mean(chowPopulation)

 ## filter dataframe column 3 (bodyweight values), instead of using dplyr to select %>% 

> chowPopulation <- chowPopulation %>% select(Bodyweight)
> chowPopulation
    Bodyweight
1        27.03
2        24.80
3        27.02
4        28.07
5        23.55
6        22.72
7        24.82
8        21.60
9        23.98
10       26.60
11       19.24
12       21.43
13       22.73
14       20.10
15       20.60
16       21.49
17       24.73
18       27.92
19       27.51
20       19.88
21       20.72
22       24.00
23       25.08
24       25.27
25       22.08
26       20.52
27       23.39
28       19.87
29       17.95
30       31.83
31       21.71
32       29.99
33       20.89
34       29.60
35       22.77
36       26.03
37       36.84
38       26.25
39       22.93
40       28.25
41       23.84
42       20.53
43       24.10
44       24.79
45       23.68
46       21.86
47       27.25
48       21.55
49       24.12
50       23.07
51       20.43
52       24.82
53       25.43
54       22.12
55       20.99
56       23.28
57       25.78
58       22.00
59       20.74
60       21.51
61       26.85
62       25.54
63       22.51
64       21.92
65       21.32
66       23.59
67       26.14
68       20.27
69       29.60
70       24.77
71       22.36
72       21.65
73       22.08
74       26.59
75       24.60
76       22.19
77       29.19
78       25.14
79       23.19
80       27.36
81       23.53
82       23.54
83       18.41
84       28.14
85       23.34
86       20.11
87       18.08
88       21.03
89       24.23
90       19.67
91       22.66
92       26.66
93       20.69
94       27.42
95       21.91
96       16.82
97       24.47
98       23.96
99       23.18
100      28.80
101      26.37
102      23.61
103      26.07
104      27.75
105      23.70
106      23.73
107      24.49
108      22.87
109      29.23
110      21.46
111      22.12
112      33.47
113      24.96
114      26.15
115      24.89
116      19.41
117      26.36
118      26.47
119      23.19
120      22.32
121      20.03
122      23.51
123      21.35
124      21.58
125      22.27
126      23.09
127      23.88
128      24.04
129      27.15
130      18.80
131      28.07
132      24.46
133      25.42
134      20.28
135      24.06
136      15.51
137      22.51
138      15.94
139      19.90
140      19.44
141      22.18
142      25.97
143      25.96
144      23.12
145      20.98
146      24.78
147      22.56
148      20.36
149      16.05
150      17.95
151      22.71
152      28.22
153      21.50
154      20.30
155      19.96
156      19.07
157      22.35
158      20.54
159      30.45
160      23.54
161      20.61
162      20.18
163      20.59
164      23.32
165      26.35
166      22.91
167      25.10
168      28.46
169      21.31
170      28.53
171      28.43
172      20.81
173      27.00
174      24.55
175      21.18
176      21.77
177      23.80
178      20.99
179      23.11
180      24.82
181      22.59
182      18.47
183      21.10
184      25.83
185      16.31
186      24.79
187      26.08
188      32.74
189      27.26
190      31.24
191      33.81
192      23.52
193      27.73
194      28.26
195      23.30
196      18.83
197      27.70
198      19.79
199      27.20
200      25.40
201      26.75
202      23.45
203      24.77
204      23.39
205      22.95
206      21.84
207      28.40
208      28.21
209      33.36
210      29.13
211      24.21
212      22.99
213      24.68
214      24.67
215      25.12
216      23.95
217      25.69
218      28.36
219      24.96
220      27.36
221      26.91
222      26.58
223      23.39
224      20.25
225      23.22
> mu_chow <- chowPopulation
> mu_chow <- mean(chowPopulation)
> dat <- read.csv("mice_pheno.csv")
> chowPopulation <- dat[dat$Sex == "F" & dat$Diet == "chow", 3]

 dat$Sex highlights the subset of the dat dataset, select F, plus '&' condition to highlight the chow data 


 column in the datafram 'chowPopulation' must be selected, i.e. the bodyweight (how to know what column represents what if i dont select a column?? 

> chowPopulation <- dat[dat$Sex == "F" & dat$Diet == "chow", 2]
> head(chowPopulation)
[1] "chow" "chow" "chow" "chow" "chow" "chow"
> chowPopulation <- dat[dat$Sex == "F" & dat$Diet == "chow", 1]
> head(chowPopulation)
[1] "F" "F" "F" "F" "F" "F"
> chowPopulation <- dat[dat$Sex == "F" & dat$Diet == "chow", 4]
> head(chowPopulation)
NULL

 1 = sex, 2 = diet , 3 = bodyweight 

> head(dat)
  Sex Diet Bodyweight
1   F   hf      31.94
2   F   hf      32.48
3   F   hf      22.82
4   F   hf      19.92
5   F   hf      32.22
6   F   hf      27.50

 look at original dat dataset to see the labelled columns 


  3 = bodyweight 

> head(chowPopulation)
NULL

  3 = bodyweight 

> chowPopulation <- dat[dat$Sex == "F" & dat$Diet == "chow", 3]
> head(chowPopulation)
[1] 27.03 24.80 27.02 28.07 23.55 22.72
> mu_chow <- mean(chowPopulation)
> mu_chow
[1] 23.89338

 ## pretend that the chowPopulation is the entire dataset. take samples from the main population as you would in real life 

> N <- 30
> `?`(sample)
> chow <- sample(chowPopulation, N)
> head(chow)
[1] 20.27 26.25 24.77 22.08 26.47 21.18
> length(dat)
[1] 3
> length(chowPopulation)
[1] 225

 ## collected sample of 30 from chowPopulation of size 225 

> mean(chow)
[1] 24.22667

 # above = random variable, sample pulls randomly hence gives random mean value from sample 

> se <- sd(chow)/sqrt(N)

 ## aka se = sqrt(variance(sigma squared) / N) 


 ## sd (sigma) 

> se
[1] 0.7560065
> pnorm(2) - pnorm(-2)
[1] 0.9544997

 ## i.e. takes the 0.05 p value (?) and says that anything falling within the 95% range of data follows a normal distribition 


 ## calculate tstatistic with diff / se 

> diff <- abs(mean(chow) - mean(chowPopulation))
> diff
[1] 0.3332889
> diff/se
[1] 0.4408545

 ## 0.44 = t statistic for chow sample dataset. tstatistic takes into account sample size (via se formula) and variation from expected population and sample values (diff 


 ## the tstatistic (diff / se) also standardises the data, to mean = 0, and sd of 1 (if you divide by se?) 


 ## as above, the confidence interval describes that 95% of the time, the random variable (mean of random samples) will fall in the normal distribution parameters (?), i.e. 5% of the time will fall in the extremes (?) 


 ## *correction: 95% of the time, the data will fall within 2 standard deviations of the data. therfore, 5% of the time, data will fall on the extreme values that are +2 sd away from the mean, and also -2 sd away. 


 ## tstat = diff / se; tstat describes how many standard errors away the observed difference (diff) is from 0 se (aka no observed difference). we use standard errors because we are describing the observed differences between sample datasets (the sample and pop datasets(?)), not between individual data points in 1 dataset (i.e. used for sd) 


 ## therefore, mean(chow) - mean(chowPopulation) describes the observed difference, divided by the above calculated se value (taking into account sample size), returns a tstatistic value. this tstat value has a 95% likelihood of falling between -2 sd and +2 sd, hence the interval: 


 ## -2 < mean(chow) - mean(chowPopulation) / se < 2 

> `?`(qnorm)
> Q <- qnorm(1 - 0.05/2)

 ## 1-0.05 defines the 95% interval, divide by 2 to define the two tails(?) 


 ## i.e. dividing by 2 defines one end of the tail, i.e. one side of the interval 


 ## i.e. the 5% defines both the right and left tails, so divide by 2 to get one tail aka one interval 


 ## this defines Q as 'one tail', which explains how far away from the mean you should go before passing the 95% of data value threshold (on one end of the tail). it establishes the boundary interval 

> interval <- c(mean(chow) - Q * se, mean(chow) + Q * se)
> interval
[1] 22.74492 25.70841

 ## we know that Q defines the literal boundary / tail interval, but Q has no value. to obtain an actual value to define the interval range, multiply it by se (variance / sqrt(N)), which considers the sample(chow) sample size and sd(chow), which considers the bodyweight value (e.g. grams). this means Q*se makes the unitless Q value into actual bodyweight values. this defines the interval from 22.75g to 25.7g 


 ## as above, we already collected the sample of size 30: chow. there is a 95% chance that the mean sample falls within the 95% confidence interval, i.e. within 2 sd away from the mean. we have yet to confirm this: 

> interval[1]
[1] 22.74492
> interval[1] < mu_chow & interval[2] > mu_chow
[1] TRUE

 ## interval variable is a vector that contains two values: the left and right tails bodyweight values of 22.7 and 25.7 respectively. if the mu_chow (mean of sample chow) falls within the 95% confidence interval, it would be larger than interval[1] (left tail) & smaller than interval[2] (right tail) 


 ## this returned TRUE 

> dat <- read.csv("mice_pheno.csv")
> head(dat)
  Sex Diet Bodyweight
1   F   hf      31.94
2   F   hf      32.48
3   F   hf      22.82
4   F   hf      19.92
5   F   hf      32.22
6   F   hf      27.50
> chowPopulation <- dat[dat$Sex == "F" & dat$Diet == "chow", 3]

 ## ^ select column 3 to filter bodyweight values, selecting dat filter Female + Chow diet 


 ## demonstrate 5% extremes by sampling from the 'entire population' dataset chowPopulation. 5% of the time, the difference between the mean chowPopulation and the sample mean chowPopulation will be extreme, i.e. fall further than 2 sd away from the mean. 

> `?`(mypar)
> B <- 250
> mypar()

 ## (mypar() empty function to optimise graphs) 

> `?`(plot)
> plot(mean(chowPopulation) + c(-7, 7), c(1, 1), type = "n", xlab = "weight", 
+ ylab = "interval", ylim = c(1, B))

 ## ^ generates graph: ylim 1,B i.e. 1, 250 y-axis to host all sample data tstat values. unsure what the c() vector do - centre the line in the middle? 

> `?`(abline)

 ## abline adds the central line through the graph 

> abline(v = mean(chowPopulation))

 ## v= is the x value for a vertical line; add mean chowPopulation value as an anchor / compparison against all other sample mean values; this highlights any deviations of the sample means vs the population mean 

> plot(mean(chowPopulation) + c(-20, 20), c(1, 1), type = "n", 
+ xlab = "weight", ylab = "interval", ylim = c(1, B))
> plot(mean(chowPopulation) + c(-1009, 1000), c(1, 1), type = "n", 
+ xlab = "weight", ylab = "interval", ylim = c(1, B))
> `?`(plot)

 type = n is a a type of plot that generates no plots. this code generates an empty graph to fill in later with no plots/points - the graph will host bars to represent deviations in sample mean (?) vs the population mean 

> plot(mean(chowPopulation) + c(-7, 7), c(1, 1), type = "n", xlab = "weight", 
+ ylab = "interval", ylim = c(1, B))

 ## plot the mean chowPopulation (x-axis), the c vectors describe +7 or -7 away from the mean (24); the x-axis shows range from 17 to 31 

> plot(mean(chowPopulation) + c(-7, 7), c(100, 50), type = "n", 
+ xlab = "weight", ylab = "interval", ylim = c(1, B))
> plot(mean(chowPopulation) + c(-7, 7), c(1, 1), type = "n", xlab = "weight", 
+ ylab = "interval", ylim = c(1, B))

 ## unsure what second c(1,1) vector does 

> abline(v = mean(chowPopulation))
> for (i in 1:B) {
+ }
> N <- 30
> for (i in 1:B) {
+ chow <- sample(chowPopulation, N)
+ se <- sd(chow)/sqrt(N)
+ Q <- qnorm((1 - 0.05/2))
+ interval <- c(mean(chow) - Q * se, mean(chow) + Q * se)
+ covered <- mean(chowPopulation) <= interval[2] & mean(chowPopulation) >= 
+ 
+ interval[1]
+ colour <- ifelse(covered, 1, 2)
+ lines(interval, c(i, i), col = colour)
+ }

 ## generated 250 samples via for loop. the following code was repeated 250 times: sample of 30 was generated, se calculated for that sample (for comparison between other samples), then multiplied against extreme tail probabilities (Q), which highlights the extreme bodyweight sample values from that sample. this generates bodyweight values(?) reflecting the extreme ranges in that sample.  


 ## create  


 ## use interval variable to create vector of left tail and right tail (range) of the sample via mean sample value and se 


 ## graph reflects that there are few extreme sd deviations (expected 5%). these are samples with intervals that do not overlap data with the true chowPopulation mean. i.e. sample data has bodyweight values that are lower/larger than the true chowPopulation mean 


 ## if repeated with sample size 5, CLT no longer applies (Q < - qqnorm(1 -0.05 / 2) --> more orange bars / extreme values from the samples generated  --> higher than 5% expected --> confidence intervals no longer applies as assume normal distribution based on CLT required 


 ## instead of using qqnorm to generate Q tail value, use qt() for samples with small sample sizes 

> `?`(qt)

 ## this gives larger intervals (bc dividing by smaller sqrt(N) size in se calculation), therefore gives larger intervals in graph, but the number of red / extremes are now low around 5% again. 

> txtStop
function() {
  removeTaskCallback('r2txt')
  if( R2txt.vars$closecon ) {
    close( R2txt.vars$con )
  }
  if( R2txt.vars$cmdfile && R2txt.vars$closecon2 ) {
    close( R2txt.vars$con2 )
  }
  options( prompt=R2txt.vars$prompt,
           continue=R2txt.vars$continue )
  if(R2txt.vars$res) {
      sink()
      close(R2txt.vars$outcon)
  }
  evalq( rm(list=ls()), envir=R2txt.vars )
  invisible(NULL)
}
<bytecode: 0x7f7e21866440>
<environment: namespace:TeachingDemos>
txt> txtStart("Ch1_Inference.txt", append = TRUE)
txt> controlPopulation <- filter(dat, Sex == "F" & Diet == "chow") %>% 
txt+ select(Bodyweight) %>% unlist()
txt> controlPopulation <- filter(dat, Sex == "F" & Diet == "chow") %>% 
txt+ select(Bodyweight) %>% unlist()
txt> hfPopulation <- filter(dat, Sex == "F" & Diet == "hf") %>% select(Bodyweight) %>% 
txt+ unlist()
txt> hfPopulation <- filter(dat, Sex == "F" & Diet == "hf") %>% select(Bodyweight) %>% 
txt+ unlist()
txt> mu_hf <- mean(hfPopulation)
txt> mu_hf <- mean(hfPopulation)
txt> mu_chow <- mean(controlPopulation)
txt> mu_chow <- mean(controlPopulation)
txt> mu_control <- mu_chow
txt> mu_control <- mu_chow
txt> pdiff <- (abs(mu_control - mu_hf)/mu_control) * 100
txt> pdiff <- (abs(mu_control - mu_hf)/mu_control) * 100
txt> pdiff
[1] 9.942157
txt> pdiff
txt> set.seed(1)
txt> set.seed(1)
txt> hf <- sample(hfPopulation, 5) %>% t.test()
txt> hf <- sample(hfPopulation, 5) %>% t.test()
txt> hf

	One Sample t-test

data:  .
t = 10.737, df = 4, p-value = 0.0004265
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
 18.91343 32.10657
sample estimates:
mean of x 
    25.51 

txt> hf
txt> hf$p.value
[1] 0.0004264995
txt> hf$p.value
txt> hf <- sample(hfPopulation, 5)
txt> hf <- sample(hfPopulation, 5)
txt> t.test(hf)

	One Sample t-test

data:  hf
t = 10.769, df = 4, p-value = 0.0004216
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
 23.09523 39.14077
sample estimates:
mean of x 
   31.118 

txt> t.test(hf)

 ## need two different values to compare in the t.test! 

txt> txtComment("## need two different values to compare in the t.test!")
txt> control <- sample(controlPopulation, 5) %>% t.test(hf)
txt> control <- sample(controlPopulation, 5) %>% t.test(hf)
txt> control

	Welch Two Sample t-test

data:  . and hf
t = -2.4925, df = 5.731, p-value = 0.04886
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -15.90391556  -0.05608444
sample estimates:
mean of x mean of y 
   23.138    31.118 

txt> control
txt> control <- sample(controlPopulation, 5)
txt> control <- sample(controlPopulation, 5)
txt> t.test(hf, control)

	Welch Two Sample t-test

data:  hf and control
t = 1.1169, df = 7.8716, p-value = 0.297
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -4.60106 13.19706
sample estimates:
mean of x mean of y 
   31.118    26.820 

txt> t.test(hf, control)

 ## p-value > 0.05  because small sample size of 5, i.e. less likely to accept a false positive, or incorrectly reject the null (false negative) 

txt> txtComment("## p-value > 0.05  because small sample size of 5, i.e. less likely to accept a false positive, or incorrectly reject the null (false negative)")

 ## therefore harder to confirm statistical significance in smaller sample sizes (t.test takes this into consideration 

txt> txtComment("## therefore harder to confirm statistical significance in smaller sample sizes (t.test takes this into consideration")

 ## type I error = false negative; type II = false positive 

txt> txtComment("## type I error = false negative; type II = false positive")
txt> `?`(pwr)
No documentation for ‘pwr’ in specified packages and libraries:
you could try ‘??pwr’
txt> `?`(pwr)

 ** simulations. The simulation is as follows: we take a sample of size N
 from both control and treatment groups, we perform a t-test comparing these two, and report if the p-value is less than alpha or not. We write a function that does this: ** 

txt> txtComment("** simulations. The simulation is as follows: we take a sample of size N\n from both control and treatment groups, we perform a t-test comparing these two, and report if the p-value is less than alpha or not. We write a function that does this: **")
txt> N <- 12
txt> N <- 12
txt> B <- 2000
txt> B <- 2000
txt> for (i in 1:B) {
txt+ control <- sample(controlPopulation, N)
txt+ hf <- sample(hfPopulation, N)
txt+ pval <- t.test(control, hf)$p.value
txt+ pval < 0.05
txt+ }
txt> for (i in 1:B) {
txt+ control <- sample(controlPopulation, N)
txt+ hf <- sample(hfPopulation, N)
txt+ pval <- t.test(control, hf)$p.value
txt+ pval < 0.05
txt+ }
txt> reject <- for (i in 1:B) {
txt+ control <- sample(controlPopulation, N)
txt+ hf <- sample(hfPopulation, N)
txt+ pval <- t.test(control, hf)$p.value
txt+ pval < 0.05
txt+ }
txt> reject <- for (i in 1:B) {
txt+ control <- sample(controlPopulation, N)
txt+ hf <- sample(hfPopulation, N)
txt+ pval <- t.test(control, hf)$p.value
txt+ pval < 0.05
txt+ }
txt> head(reject)
NULL
txt> head(reject)
txt> reject
NULL
txt> reject
txt> reject <- function(N, alpha = 0.05) {
txt+ hf <- sample(hfPopulation, N)
txt+ control <- sample(controlPopulation, N)
txt+ pval <- t.test(control, hf)$p.value
txt+ pval < 0.05
txt+ }
txt> reject <- function(N, alpha = 0.05) {
txt+ hf <- sample(hfPopulation, N)
txt+ control <- sample(controlPopulation, N)
txt+ pval <- t.test(control, hf)$p.value
txt+ pval < 0.05
txt+ }
txt> head(reject)
                                             
1 function (N, alpha = 0.05)                 
2 {                                          
3     hf <- sample(hfPopulation, N)          
4     control <- sample(controlPopulation, N)
5     pval <- t.test(control, hf)$p.value    
6     pval < 0.05                            
txt> head(reject)
txt> reject
function(N, alpha = 0.05) {
hf <- sample(hfPopulation, N)
control <- sample(controlPopulation, N)
pval <- t.test(control, hf)$p.value
pval < 0.05
}
txt> reject
txt> reject <- function(N, alpha = 0.05) {
txt+ control <- sample(controlPopulation, N)
txt+ hf <- sample(hfPopulation, N)
txt+ pval <- t.test(hf, control)$p.value
txt+ pval < alpha
txt+ }
txt> reject <- function(N, alpha = 0.05) {
txt+ control <- sample(controlPopulation, N)
txt+ hf <- sample(hfPopulation, N)
txt+ pval <- t.test(hf, control)$p.value
txt+ pval < alpha
txt+ }
txt> head(reject)
                                             
1 function (N, alpha = 0.05)                 
2 {                                          
3     control <- sample(controlPopulation, N)
4     hf <- sample(hfPopulation, N)          
5     pval <- t.test(hf, control)$p.value    
6     pval < alpha                           
txt> head(reject)
txt> reject
function(N, alpha = 0.05) {
control <- sample(controlPopulation, N)
hf <- sample(hfPopulation, N)
pval <- t.test(hf, control)$p.value
pval < alpha
}
txt> reject
txt> reject(12)
[1] FALSE
txt> reject(12)

 ## created a 'function' labelled as 'reject'. run the 'reject' variable with size N as 12 to get a t.test p value of sample sizes of 12 

txt> txtComment("## created a 'function' labelled as 'reject'. run the 'reject' variable with size N as 12 to get a t.test p value of sample sizes of 12")

 ## returned 'FALSE' i.e. the p-value was not < alpha, i.e. it was larger than 0.05, hence accept the null 

txt> txtComment("## returned 'FALSE' i.e. the p-value was not < alpha, i.e. it was larger than 0.05, hence accept the null")

 ## defined 'alpha' inside the function, so it is not in the main global environment as a separate variable 

txt> txtComment("## defined 'alpha' inside the function, so it is not in the main global environment as a separate variable")

 ## repeat the simulation B times 

txt> txtComment("## repeat the simulation B times")
txt> `?`(replicate)
txt> `?`(replicate)
txt> rejections <- replicate(B, reject(N))
txt> rejections <- replicate(B, reject(N))

 ## i.e. replicate 2000 times the function 'reject' (which already repeats the reject function in itself 12 times, outputting 12 FALSE/TRUE values per reject function simulation) 

txt> txtComment("## i.e. replicate 2000 times the function 'reject' (which already repeats the reject function in itself 12 times, outputting 12 FALSE/TRUE values per reject function simulation)")
txt> mean(rejections)
[1] 0.2145
txt> mean(rejections)

 ## power = mean(rejections) 

txt> txtComment("## power = mean(rejections)")

 ## the higher the power, the less likely to get a type II error (reject null incorrectly, false positive) 

txt> txtComment("## the higher the power, the less likely to get a type II error (reject null incorrectly, false positive)")

 ## above simulation was run 2000 times and gave a mean of 21% power, i.e. too low. comfortable threshold at ~80%. this means that with a sample size of 12 in this simulation, the power was too low. this means rejecting the null incorrectly, i.e. false positives, was too likely. this means that the above 'FALSE' return is likely to also be an incorrect rejection of the null. not confident enough to accept the results from this simulation with this small sample size 

txt> txtComment("## above simulation was run 2000 times and gave a mean of 21% power, i.e. too low. comfortable threshold at ~80%. this means that with a sample size of 12 in this simulation, the power was too low. this means rejecting the null incorrectly, i.e. false positives, was too likely. this means that the above 'FALSE' return is likely to also be an incorrect rejection of the null. not confident enough to accept the results from this simulation with this small sample size")

 ## TLDR: low power means unlikely to change in beliefs (ie accept the null / can't rejct null vice versa 

txt> txtComment("## TLDR: low power means unlikely to change in beliefs (ie accept the null / can't rejct null vice versa")

 ## this means a lower power is less likely to reject the null, hence more likely to accept the null when the alternative hypothesis should have been accepted = type II error (false negatives) 

txt> txtComment("## this means a lower power is less likely to reject the null, hence more likely to accept the null when the alternative hypothesis should have been accepted = type II error (false negatives)")

 ## t tests take into account small sample sizes, raise the threshold for a succesful null rejection, i.e. less likely to get a significant p-value. therefore small sample sizes are less likely to get a significant p-value, meaning there are more rejections than with larger sample sizes as we are less confident that there is a significant difference. this also means false negatives are much more likey. 

txt> txtComment("## t tests take into account small sample sizes, raise the threshold for a succesful null rejection, i.e. less likely to get a significant p-value. therefore small sample sizes are less likely to get a significant p-value, meaning there are more rejections than with larger sample sizes as we are less confident that there is a significant difference. this also means false negatives are much more likey.")
txt> `?`(seq)
txt> `?`(seq)
txt> Ns <- seq(5, 50, 5)
txt> Ns <- seq(5, 50, 5)
txt> Ns
 [1]  5 10 15 20 25 30 35 40 45 50
txt> Ns

 ## sequence of 5 to 50 in 5 increments 

txt> txtComment("## sequence of 5 to 50 in 5 increments")
txt> Ns <- seq(5, 50, 2)
txt> Ns <- seq(5, 50, 2)
txt> Ns
 [1]  5  7  9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49
txt> Ns
txt> Ns <- seq(5, 50, 5)
txt> Ns <- seq(5, 50, 5)
txt> Ns
 [1]  5 10 15 20 25 30 35 40 45 50
txt> Ns
txt> `?`(sapply)
txt> `?`(sapply)
txt> power <- sapply(Ns, function(N) {
txt+ rejections <- replicate(B, reject(N))
txt+ mean(rejections)
txt+ })
txt> power <- sapply(Ns, function(N) {
txt+ rejections <- replicate(B, reject(N))
txt+ mean(rejections)
txt+ })
txt> power
 [1] 0.0930 0.1980 0.2865 0.3555 0.4620 0.5485 0.6430 0.6955 0.7745 0.8220
txt> power

 ## loop each number in the Ns sequence 5-50 (increments of 5), through new(?) function 'N'. open funcion(N) and replicate 2000 times an earlier function 'reject'. generate mean value of the 2000 simulations (TRUE/FALSE if pvalue < 0.05 (alpha); this gives the power. repeat the entire simulation again, for each vector in the sequence, until 50 

txt> txtComment("## loop each number in the Ns sequence 5-50 (increments of 5), through new(?) function 'N'. open funcion(N) and replicate 2000 times an earlier function 'reject'. generate mean value of the 2000 simulations (TRUE/FALSE if pvalue < 0.05 (alpha); this gives the power. repeat the entire simulation again, for each vector in the sequence, until 50")
txt> `?`(plot)
txt> `?`(plot)
txt> plot(Ns, power, type = "b")
txt> plot(Ns, power, type = "b")

 ## plot with x-axis defined as sequence 5-50 (Ns), y-axis as power (generated from mean number of significant p values, with type 'b' graph with plots and lines connected 

txt> txtComment("## plot with x-axis defined as sequence 5-50 (Ns), y-axis as power (generated from mean number of significant p values, with type 'b' graph with plots and lines connected")

 ## graph shows stable positive correlation with increases in sample size (Ns x-axis) 

txt> txtComment("## graph shows stable positive correlation with increases in sample size (Ns x-axis)")

 ## i.e. the larger the sample size, the larger the power, and therefore a larger power is less likely to lead to a false negative, and more likely to identify true positives (significant p values to reject the null) 

txt> txtComment("## i.e. the larger the sample size, the larger the power, and therefore a larger power is less likely to lead to a false negative, and more likely to identify true positives (significant p values to reject the null)")

 ## similarly, keeping the sample size the same but changing the p-value threshold (alpha) also changes power. the smaller the p value threshold, the higher the power. i.e. a higher power is less likely to give false negatives (reject the null when it should not 

txt> txtComment("## similarly, keeping the sample size the same but changing the p-value threshold (alpha) also changes power. the smaller the p value threshold, the higher the power. i.e. a higher power is less likely to give false negatives (reject the null when it should not")
txt> N <- 30
txt> N <- 30
txt> alphas <- c(0.1, 0.05, 0.01, 0.001, 1e-04)
txt> alphas <- c(0.1, 0.05, 0.01, 0.001, 1e-04)
txt> power <- sapply(alphas, function(alpha) {
txt+ rejections <- replicate(B, reject(N, alpha = alpha))
txt+ mean(rejections)
txt+ })
txt> power <- sapply(alphas, function(alpha) {
txt+ rejections <- replicate(B, reject(N, alpha = alpha))
txt+ mean(rejections)
txt+ })
txt> plot(alphas, power, xlab = "alpha", type = "b", log = "x")
txt> plot(alphas, power, xlab = "alpha", type = "b", log = "x")

 ## graph shows exponential increase in power with increasingly smaller p value threshold 

txt> txtComment("## graph shows exponential increase in power with increasingly smaller p value threshold")

 ## ** correction, graph shows exponential decrease in power with increasingly smaller alpha (p-value threshold) 

txt> txtComment("## ** correction, graph shows exponential decrease in power with increasingly smaller alpha (p-value threshold)")

 ## i.e. the stricter/smaller the p-value threshold (alpha), the less power there is, i.e. more likely to accept the null. this means less power means less likely to confirm statistical significance. this also means less power is more likely to lead to type I errors: false positives (??)  

txt> txtComment("## i.e. the stricter/smaller the p-value threshold (alpha), the less power there is, i.e. more likely to accept the null. this means less power means less likely to confirm statistical significance. this also means less power is more likely to lead to type I errors: false positives (??) ")

 ** Therefore, a better statistic to report is the effect size with a confidence interval or some statistic which gives the reader a sense of the change in a meaningful scale. We can report the effect size as a percent by dividing the difference and the confidence interval by the control population mean: 

txt> txtComment("** Therefore, a better statistic to report is the effect size with a confidence interval or some statistic which gives the reader a sense of the change in a meaningful scale. We can report the effect size as a percent by dividing the difference and the confidence interval by the control population mean:")
txt> t.test(hf, control)

	Welch Two Sample t-test

data:  hf and control
t = 0.78168, df = 20.789, p-value = 0.4432
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -2.537324  5.590491
sample estimates:
mean of x mean of y 
 25.28825  23.76167 

txt> t.test(hf, control)

 ## extract confidence interval from the t.test and divide it by the control population sample mean, then *100 

txt> txtComment("## extract confidence interval from the t.test and divide it by the control population sample mean, then *100")
txt> t.test(hf, control)$conf.int/mean(control) * 100
[1] -10.67823  23.52735
attr(,"conf.level")
[1] 0.95
txt> t.test(hf, control)$conf.int/mean(control) * 100

 ## a t statistic value is guaranteed to increase with sample size (bc sd naturally decreases and this sd is a denominator in the formula). therefore, calculating effect size is more reliable bc it does not depend on sample size - instead, it depends on sd. the effect size explains how many sd difference there is between two sample groups 

txt> txtComment("## a t statistic value is guaranteed to increase with sample size (bc sd naturally decreases and this sd is a denominator in the formula). therefore, calculating effect size is more reliable bc it does not depend on sample size - instead, it depends on sd. the effect size explains how many sd difference there is between two sample groups")
txt> url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/babies.txt"
txt> url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/babies.txt"
txt> `?`(basename)
txt> `?`(basename)
txt> filename <- basename(url)
txt> filename <- basename(url)
txt> download(url, destfile = filename)
txt> download(url, destfile = filename)
txt> babies <- read.table("babies.txt", header = TRUE)
txt> babies <- read.table("babies.txt", header = TRUE)
txt> head(babies)
  bwt gestation parity age height weight smoke
1 120       284      0  27     62    100     0
2 113       282      0  33     64    135     0
3 128       279      0  28     64    115     1
4 123       999      0  36     69    190     0
5 108       282      0  23     67    125     1
6 136       286      0  25     62     93     0
txt> head(babies)
txt> tail(head)
                    
1 function (x, ...) 
2 UseMethod("head") 
txt> tail(head)
txt> tail(babies)
     bwt gestation parity age height weight smoke
1231 132       270      0  27     65    126     0
1232 113       275      1  27     60    100     0
1233 128       265      0  24     67    120     0
1234 130       291      0  30     65    150     1
1235 125       281      1  21     65    110     0
1236 117       297      0  38     65    129     0
txt> tail(babies)
txt> length(babies)
[1] 7
txt> length(babies)

 ## babies.txt dataset is table with data on babies with smoking vs non-smoking mothers 

txt> txtComment("## babies.txt dataset is table with data on babies with smoking vs non-smoking mothers")

 ** First, let’s split this into two birth weight datasets: one of birth weights to non-smoking mothers and the other of birth weights to smoking mothers. ** 

txt> txtComment("** First, let’s split this into two birth weight datasets: one of birth weights to non-smoking mothers and the other of birth weights to smoking mothers. **")
txt> summary(babies)
      bwt          gestation         parity            age            height          weight        smoke       
 Min.   : 55.0   Min.   :148.0   Min.   :0.0000   Min.   :15.00   Min.   :53.00   Min.   : 87   Min.   :0.0000  
 1st Qu.:108.8   1st Qu.:272.0   1st Qu.:0.0000   1st Qu.:23.00   1st Qu.:62.00   1st Qu.:115   1st Qu.:0.0000  
 Median :120.0   Median :280.0   Median :0.0000   Median :26.00   Median :64.00   Median :126   Median :0.0000  
 Mean   :119.6   Mean   :286.9   Mean   :0.2549   Mean   :27.37   Mean   :64.67   Mean   :154   Mean   :0.4644  
 3rd Qu.:131.0   3rd Qu.:288.0   3rd Qu.:1.0000   3rd Qu.:31.00   3rd Qu.:66.00   3rd Qu.:140   3rd Qu.:1.0000  
 Max.   :176.0   Max.   :999.0   Max.   :1.0000   Max.   :99.00   Max.   :99.00   Max.   :999   Max.   :9.0000  
txt> summary(babies)
txt> bwt.nonsmoke <- filter(babies, smoke == 0) %>% unlist()
txt> bwt.nonsmoke <- filter(babies, smoke == 0) %>% unlist()
txt> head(bwt.nonsmoke)
bwt1 bwt2 bwt3 bwt4 bwt5 bwt6 
 120  113  123  136  138  132 
txt> head(bwt.nonsmoke)
txt> bwt.nonsmoke <- filter(babies, smoke == 0)
txt> bwt.nonsmoke <- filter(babies, smoke == 0)
txt> head(bwt.nonsmoke)
  bwt gestation parity age height weight smoke
1 120       284      0  27     62    100     0
2 113       282      0  33     64    135     0
3 123       999      0  36     69    190     0
4 136       286      0  25     62     93     0
5 138       244      0  33     62    178     0
6 132       245      0  23     65    140     0
txt> head(bwt.nonsmoke)
txt> bwt.nonsmoke <- filter(babies, smoke == 0) %>% unlist()
txt> bwt.nonsmoke <- filter(babies, smoke == 0) %>% unlist()
txt> head(bwt.nonsmoke)
bwt1 bwt2 bwt3 bwt4 bwt5 bwt6 
 120  113  123  136  138  132 
txt> head(bwt.nonsmoke)
txt> bwt.nonsmoke <- filter(babies, smoke == 0) %>% select(bwt) %>% 
txt+ unlist()
txt> bwt.nonsmoke <- filter(babies, smoke == 0) %>% select(bwt) %>% 
txt+ unlist()
txt> head(bwt.nonsmoke)
bwt1 bwt2 bwt3 bwt4 bwt5 bwt6 
 120  113  123  136  138  132 
txt> head(bwt.nonsmoke)
txt> bwt.smoke <- filter(babies, smoke == 1) %>% select(bwt) %>% unlist()
txt> bwt.smoke <- filter(babies, smoke == 1) %>% select(bwt) %>% unlist()
txt> library(rafalib)
txt> library(rafalib)
txt> txtComment()

 ## mean difference in body weight (bwt): 

txt> txtComment("## mean difference in body weight (bwt):")
txt> mean(bwt.smoke) - mean(bwt.nonsmoke)
[1] -8.937666
txt> mean(bwt.smoke) - mean(bwt.nonsmoke)
txt> mean(bwt.smoke) - mean(bwt.nonsmoke) %>% abs()
[1] -8.937666
txt> mean(bwt.smoke) - mean(bwt.nonsmoke) %>% abs()
txt> abs(mean(bwt.smoke) - mean(bwt.nonsmoke))
[1] 8.937666
txt> abs(mean(bwt.smoke) - mean(bwt.nonsmoke))
txt> `?`(popsd)
txt> `?`(popsd)
txt> popsd(bwt.nonsmoke)
[1] 17.38696
txt> popsd(bwt.nonsmoke)
txt> popsd(bwt.smoke)
[1] 18.08024
txt> popsd(bwt.smoke)
txt> set.seed(1)
txt> set.seed(1)
txt> N <- 25
txt> N <- 25
txt> dat.ns <- sample(bwt.nonsmoke, N)
txt> dat.ns <- sample(bwt.nonsmoke, N)
txt> dat.s <- sample(bwt.smoke, N)
txt> dat.s <- sample(bwt.smoke, N)
txt> tval <- t.test(dat.ns, dat.s)$p.value
txt> tval <- t.test(dat.ns, dat.s)$p.value
txt> tval
[1] 0.1036286
txt> tval
txt> txtStop
function() {
  removeTaskCallback('r2txt')
  if( R2txt.vars$closecon ) {
    close( R2txt.vars$con )
  }
  if( R2txt.vars$cmdfile && R2txt.vars$closecon2 ) {
    close( R2txt.vars$con2 )
  }
  options( prompt=R2txt.vars$prompt,
           continue=R2txt.vars$continue )
  if(R2txt.vars$res) {
      sink()
      close(R2txt.vars$outcon)
  }
  evalq( rm(list=ls()), envir=R2txt.vars )
  invisible(NULL)
}
<bytecode: 0x7f7e21866440>
<environment: namespace:TeachingDemos>
txt> txtStop

 ## t-test p-value (aka tval) gives the probability that there is a difference between two groups. the tval*pnorm can represent the p-value probability of getting a value from the left (i.e. one) side of the tail. a two-tailed / two-sided t-test gives the probability p-value of getting value from both tail ends. as pnorm*tval only gives probability of getting a value from the LEFT side of the tail, do pnorm*(-abs(tval)) to get the RIGHT side of the tail 


 ## to get both tails (i.e. two-sided t-test), add both: pnorm*tval + pnorm(-abs(tval)) = 2*pnorm(-abs(tval)) 

> View(babies.txt)
Error in View : object 'babies.txt' not found
> View(babies)
Error in View : object 'babies' not found
> url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/babies.txt"
> filename <- basename(url)
> getwd()
[1] "/Users/aliyyahali/Desktop/R/git/PH525x-notes"
> url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/babies.txt"
> filename <- basename(url)
> download(url, destfile = filename)
> babies <- read.table("babies.txt", header = TRUE)
> View(babies)
> bwt.nonsmoke <- filter(babies, smoke == 0) %>% select(bwt) %>% 
+ unlist()
> head(bwt.nonsmoke)
bwt1 bwt2 bwt3 bwt4 bwt5 bwt6 
 120  113  123  136  138  132 
> bwt.smoke <- filter(babies, smoke == 1) %>% select(bwt) %>% unlist()
> mean(bwt.nonsmoke) - mean(bwt.smoke)
[1] 8.937666
> popsd(bwt.nonsmoke)
[1] 17.38696
> popsd(bwt.smoke)
[1] 18.08024
> set.seed(1)
> dat.ns <- sample(bwt.nonsmoke, 25)
> dat.s <- sample(bwt.smoke, 25)
> tval <- t.test(dat.ns, dat.s)$p.value
> tval
[1] 0.1036286
> mean(dat.s) - mean(dat.ns)
[1] -8.48
> se <- sqrt(var(dat.s)/length(dat.s) + sqrt(var(dat.ns)/length(dat.ns)))
> se
[1] 4.210214
> clt <- qnorm(0.995) * se
> se
[1] 4.210214
> clt <- qnorm(0.995) * se
> clt
[1] 10.84479
> qt(dat.s, dat.ns)
bwt404 bwt412  bwt20  bwt44 bwt377 bwt343  bwt70 bwt121  bwt40 bwt172  bwt25 
   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN 
bwt375 bwt248 bwt198 bwt378  bwt39 bwt435 bwt298 bwt390 bwt280 bwt160  bwt14 
   NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN 
bwt130  bwt45 bwt402 
   NaN    NaN    NaN 
> length(dat.ns)
[1] 25
> length(dat.s)
[1] 25
> N <- length(dat.ns) + length(dat.s)
> qt(0.995, N - 2 * se)
[1] 2.699357
> `?`(qt)
> qt(0.995, N - 2)
[1] 2.682204
> N <- length(dat.ns) + length(dat.s)
> qt <- qt(0.995, N - 2)
> se <- sqrt(var(dat.s)/length(dat.s) + sqrt(var(dat.ns)/length(dat.ns)))
> qt * se
[1] 11.29265
> set.seed(1)
> smoke <- sample(dat.s, 5)
> nonsmoke <- sample(dat.ns, 5)
> t.test(smoke, nonsmoke)

	Welch Two Sample t-test

data:  smoke and nonsmoke
t = -1.4369, df = 7.3979, p-value = 0.1917
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -50.98021  12.18021
sample estimates:
mean of x mean of y 
    109.8     129.2 

> t.test(smoke, nonsmoke)$p.value
[1] 0.1916537
> `?`(replicate)
> smoke <- replicate(10000, sample(dat.s, 5))
> smoke
       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25]
bwt404  109  118  138   80  134  121   94   94  118   125   100   121   141   134   107    98   107    80   100   125   109   130   138   125    98
       [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38] [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49]
bwt404   125   134   100   146    80   108   104   100    94   130    80    98    87    87   130   125   141   100   118    94   108   138   101   146
       [,50] [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62] [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73]
bwt404   141   146   120   100   125   104   121   138   154    98    80   125   104   107    98   119   100   154   118   141   134   146   100   123
       [,74] [,75] [,76] [,77] [,78] [,79] [,80] [,81] [,82] [,83] [,84] [,85] [,86] [,87] [,88] [,89] [,90] [,91] [,92] [,93] [,94] [,95] [,96] [,97]
bwt404   120   154    87   154   100   118   109    94   138   154   120   121   138   108   100   107   134   146   154   146   134   130    80   141
       [,98] [,99] [,100] [,101] [,102] [,103] [,104] [,105] [,106] [,107] [,108] [,109] [,110] [,111] [,112] [,113] [,114] [,115] [,116] [,117] [,118]
bwt404   138   123    107    138     94    121    101    104    119    101    138    134     80    109    118     94     87    100    107     80    121
       [,119] [,120] [,121] [,122] [,123] [,124] [,125] [,126] [,127] [,128] [,129] [,130] [,131] [,132] [,133] [,134] [,135] [,136] [,137] [,138]
bwt404    125    118    107    125    130    100    125    101    100    125    134    146    109    134    119    134    108     80     80    121
       [,139] [,140] [,141] [,142] [,143] [,144] [,145] [,146] [,147] [,148] [,149] [,150] [,151] [,152] [,153] [,154] [,155] [,156] [,157] [,158]
bwt404    134     94    100    154    100    154    118    100    123    134    134    100    100    104    125    138    118    130     98    146
       [,159] [,160] [,161] [,162] [,163] [,164] [,165] [,166] [,167] [,168] [,169] [,170] [,171] [,172] [,173] [,174] [,175] [,176] [,177] [,178]
bwt404    107    146     94     94    107     94    100    100    101    125    146    123    101    108    100    138    123     98    118    104
       [,179] [,180] [,181] [,182] [,183] [,184] [,185] [,186] [,187] [,188] [,189] [,190] [,191] [,192] [,193] [,194] [,195] [,196] [,197] [,198]
bwt404    123    138    109    118    119    141    119    130    108     80    118    141    123    134    120    130    101    134    130    138
       [,199] [,200] [,201] [,202] [,203] [,204] [,205] [,206] [,207] [,208] [,209] [,210] [,211] [,212] [,213] [,214] [,215] [,216] [,217] [,218]
bwt404    130    100     87    118     94     98    104    130     94    134     98    154    146    125    107    118    130     98    138    123
       [,219] [,220] [,221] [,222] [,223] [,224] [,225] [,226] [,227] [,228] [,229] [,230] [,231] [,232] [,233] [,234] [,235] [,236] [,237] [,238]
bwt404    118    100    119    125    123    101    109    107     94    120     87    130    134    154    100     80    141    134    141    123
       [,239] [,240] [,241] [,242] [,243] [,244] [,245] [,246] [,247] [,248] [,249] [,250] [,251] [,252] [,253] [,254] [,255] [,256] [,257] [,258]
bwt404     80    154    104    100     98    154    154    118     87    125    134    138     87    125    109    104    108    120    138    121
       [,259] [,260] [,261] [,262] [,263] [,264] [,265] [,266] [,267] [,268] [,269] [,270] [,271] [,272] [,273] [,274] [,275] [,276] [,277] [,278]
bwt404    120    121    134    125    134    141    154    134    134    108    107    121    125    107    123     94    109     87    134    104
       [,279] [,280] [,281] [,282] [,283] [,284] [,285] [,286] [,287] [,288] [,289] [,290] [,291] [,292] [,293] [,294] [,295] [,296] [,297] [,298]
bwt404     80    120    101     98    134    125    120    141    107    121    104    125    119     87    120    125    134    107    121     94
       [,299] [,300] [,301] [,302] [,303] [,304] [,305] [,306] [,307] [,308] [,309] [,310] [,311] [,312] [,313] [,314] [,315] [,316] [,317] [,318]
bwt404     94    119    134    104    104    119    104    108     98    118    101    108     94     94    100    121    154    134    134    134
       [,319] [,320] [,321] [,322] [,323] [,324] [,325] [,326] [,327] [,328] [,329] [,330] [,331] [,332] [,333] [,334] [,335] [,336] [,337] [,338]
bwt404     94     80    130    138    100     87    146    130    107    120    130    146    146    146    120    121    104     98    108    119
       [,339] [,340] [,341] [,342] [,343] [,344] [,345] [,346] [,347] [,348] [,349] [,350] [,351] [,352] [,353] [,354] [,355] [,356] [,357] [,358]
bwt404    119    108     80    123    134    104     87    101    130    101    121    118    125    107    118    107    123    141    125     80
       [,359] [,360] [,361] [,362] [,363] [,364] [,365] [,366] [,367] [,368] [,369] [,370] [,371] [,372] [,373] [,374] [,375] [,376] [,377] [,378]
bwt404    146    120     80    109    108    108    118    130     80    100    100    138     87    125     87     98    134    100    154    120
       [,379] [,380] [,381] [,382] [,383] [,384] [,385] [,386] [,387] [,388] [,389] [,390] [,391] [,392] [,393] [,394] [,395] [,396] [,397] [,398]
bwt404     80    123    125     94    125    125    119    134     87    138    138    104    123    121    108    109    120    154    125    120
       [,399] [,400] [,401] [,402] [,403] [,404] [,405] [,406] [,407] [,408] [,409] [,410] [,411] [,412] [,413] [,414] [,415] [,416] [,417] [,418]
bwt404     94    130    107    108    125     98    100     98    107     98     98     98    100    146    146    118    101    101    100    108
       [,419] [,420] [,421] [,422] [,423] [,424] [,425] [,426] [,427] [,428] [,429] [,430] [,431] [,432] [,433] [,434] [,435] [,436] [,437] [,438]
bwt404    108    123    134    125    109    138    100    123    125    109    130    134    100    130    146     94    100    120    134    134
       [,439] [,440] [,441] [,442] [,443] [,444] [,445] [,446] [,447] [,448] [,449] [,450] [,451] [,452] [,453] [,454] [,455] [,456] [,457] [,458]
bwt404    138    100    134    123    125    134    138    121    141    146    134     94    134     94    100    119    134    119    121    118
       [,459] [,460] [,461] [,462] [,463] [,464] [,465] [,466] [,467] [,468] [,469] [,470] [,471] [,472] [,473] [,474] [,475] [,476] [,477] [,478]
bwt404    119    120     87    107     87    100    107    121    154     80    118    100     98     87    123    154    134    101    118    154
       [,479] [,480] [,481] [,482] [,483] [,484] [,485] [,486] [,487] [,488] [,489] [,490] [,491] [,492] [,493] [,494] [,495] [,496] [,497] [,498]
bwt404    118    108    138    134    121    119    130    104    121     98    118    101    125     80    118     87    100    154    146    146
       [,499] [,500] [,501] [,502] [,503] [,504] [,505] [,506] [,507] [,508] [,509] [,510] [,511] [,512] [,513] [,514] [,515] [,516] [,517] [,518]
bwt404    154     80    154    134    100    130    130    146    109    134    100     94    109    108    120    134    123    141    108    100
       [,519] [,520] [,521] [,522] [,523] [,524] [,525] [,526] [,527] [,528] [,529] [,530] [,531] [,532] [,533] [,534] [,535] [,536] [,537] [,538]
bwt404    154    108     87    146    138    104    146     94    123    125    130    109    101    109    130    154     87    138    138    130
       [,539] [,540] [,541] [,542] [,543] [,544] [,545] [,546] [,547] [,548] [,549] [,550] [,551] [,552] [,553] [,554] [,555] [,556] [,557] [,558]
bwt404    125    120    123    130    100    100    141     87    154     80    138    154    134    154    100    134    125    101     80    100
       [,559] [,560] [,561] [,562] [,563] [,564] [,565] [,566] [,567] [,568] [,569] [,570] [,571] [,572] [,573] [,574] [,575] [,576] [,577] [,578]
bwt404    125    134    123    121    125    104    141    138    141    120    154    146    134    134    125    108    138    119    121    146
       [,579] [,580] [,581] [,582] [,583] [,584] [,585] [,586] [,587] [,588] [,589] [,590] [,591] [,592] [,593] [,594] [,595] [,596] [,597] [,598]
bwt404    100    118    130    107    100    100    154    121     98    154    104    123    125    134    154    138    100     80    138     87
       [,599] [,600] [,601] [,602] [,603] [,604] [,605] [,606] [,607] [,608] [,609] [,610] [,611] [,612] [,613] [,614] [,615] [,616] [,617] [,618]
bwt404    138    134     87    125    130     98    118    100     98    141    125    125    119    104     80    154    119    120    107    141
       [,619] [,620] [,621] [,622] [,623] [,624] [,625] [,626] [,627] [,628] [,629] [,630] [,631] [,632] [,633] [,634] [,635] [,636] [,637] [,638]
bwt404    101    101    141    108     87     87    101    104    118    125     80    119    141    134    125    119    100    141    101    101
       [,639] [,640] [,641] [,642] [,643] [,644] [,645] [,646] [,647] [,648] [,649] [,650] [,651] [,652] [,653] [,654] [,655] [,656] [,657] [,658]
bwt404    138    118    107    104    154    119     87    101    130     94    100    125    123    109    121    118     98    100    146    130
       [,659] [,660] [,661] [,662] [,663] [,664] [,665] [,666] [,667] [,668] [,669] [,670] [,671] [,672] [,673] [,674] [,675] [,676] [,677] [,678]
bwt404    104     94    118    146     87    146    121    101    125    100    141    125    104    100    107     87    100     94    134    134
       [,679] [,680] [,681] [,682] [,683] [,684] [,685] [,686] [,687] [,688] [,689] [,690] [,691] [,692] [,693] [,694] [,695] [,696] [,697] [,698]
bwt404    101    101    134    104    125     94    130    130    141    119    146    130    104    121    121    104     80     80    125    130
       [,699] [,700] [,701] [,702] [,703] [,704] [,705] [,706] [,707] [,708] [,709] [,710] [,711] [,712] [,713] [,714] [,715] [,716] [,717] [,718]
bwt404     87    123    101    138    125    134     80    109    108    119    101    100    119    123    104    123    104    118    130    154
       [,719] [,720] [,721] [,722] [,723] [,724] [,725] [,726] [,727] [,728] [,729] [,730] [,731] [,732] [,733] [,734] [,735] [,736] [,737] [,738]
bwt404    125    118    138    134    125    123    119     94     87    138     98    108    101    120    138    125    123    134    100    107
       [,739] [,740] [,741] [,742] [,743] [,744] [,745] [,746] [,747] [,748] [,749] [,750] [,751] [,752] [,753] [,754] [,755] [,756] [,757] [,758]
bwt404    108    100    125     80    138    118    134    123    130    109    123    125    141     80    100    104     87    146    101    138
       [,759] [,760] [,761] [,762] [,763] [,764] [,765] [,766] [,767] [,768] [,769] [,770] [,771] [,772] [,773] [,774] [,775] [,776] [,777] [,778]
bwt404    134    125    107     94    141     94    154    125    154    134    118    138    104     80    121    100     87    121    125    146
       [,779] [,780] [,781] [,782] [,783] [,784] [,785] [,786] [,787] [,788] [,789] [,790] [,791] [,792] [,793] [,794] [,795] [,796] [,797] [,798]
bwt404    100    108    141    134    154    100    108    120    121    141    130    108    134     98    108    138     98    123    121    141
       [,799] [,800] [,801] [,802] [,803] [,804] [,805] [,806] [,807] [,808] [,809] [,810] [,811] [,812] [,813] [,814] [,815] [,816] [,817] [,818]
bwt404    118    134    134     94    134    123    141    125    109     87    120    119    125    101    109    146    138    108    120    125
       [,819] [,820] [,821] [,822] [,823] [,824] [,825] [,826] [,827] [,828] [,829] [,830] [,831] [,832] [,833] [,834] [,835] [,836] [,837] [,838]
bwt404    134     87    130    146    100    118    107    154    134    146    130     98    100    100     87    123    123    154    154    154
       [,839] [,840] [,841] [,842] [,843] [,844] [,845] [,846] [,847] [,848] [,849] [,850] [,851] [,852] [,853] [,854] [,855] [,856] [,857] [,858]
bwt404    134    125    141    130    146    101    121    108    109    138    120    121    123    119    123    123    123    134    104    134
       [,859] [,860] [,861] [,862] [,863] [,864] [,865] [,866] [,867] [,868] [,869] [,870] [,871] [,872] [,873] [,874] [,875] [,876] [,877] [,878]
bwt404    134    100    100    101    134    120    100    100     98    125    121    154     80    154     87    134    100    104    119    118
       [,879] [,880] [,881] [,882] [,883] [,884] [,885] [,886] [,887] [,888] [,889] [,890] [,891] [,892] [,893] [,894] [,895] [,896] [,897] [,898]
bwt404    134    146    120    118    100    121    134    130    138    118     80    104    101    125    109    100    119    125    120    123
       [,899] [,900] [,901] [,902] [,903] [,904] [,905] [,906] [,907] [,908] [,909] [,910] [,911] [,912] [,913] [,914] [,915] [,916] [,917] [,918]
bwt404    107    141     98    141    104    134    107    134    125    107    125     98    101    154    146    108    109    130    154     80
       [,919] [,920] [,921] [,922] [,923] [,924] [,925] [,926] [,927] [,928] [,929] [,930] [,931] [,932] [,933] [,934] [,935] [,936] [,937] [,938]
bwt404    119     87    119    134    154    107    119    146    130    101    109    101    109    100    120    125    118     80    134    130
       [,939] [,940] [,941] [,942] [,943] [,944] [,945] [,946] [,947] [,948] [,949] [,950] [,951] [,952] [,953] [,954] [,955] [,956] [,957] [,958]
bwt404    125    118    146    100    141    146    141    134    141    109    104    108     80    146    100    146    130    130    125    101
       [,959] [,960] [,961] [,962] [,963] [,964] [,965] [,966] [,967] [,968] [,969] [,970] [,971] [,972] [,973] [,974] [,975] [,976] [,977] [,978]
bwt404     80    100    120    123    120    119    130    121    154    100    118    107    146     87    109    125    125    121    121    104
       [,979] [,980] [,981] [,982] [,983] [,984] [,985] [,986] [,987] [,988] [,989] [,990] [,991] [,992] [,993] [,994] [,995] [,996] [,997] [,998]
bwt404    146    130    120    134    100    134     94     98     98    108    123     80    104    138    125     98    125    101    108    141
       [,999] [,1000]
bwt404    100      87
 [ reached 'max' / getOption("max.print") -- omitted 4 rows and 9000 columns ]
> length(smoke)
[1] 50000
> set.seed(1)
> smoke <- replicate(10000, sample(dat.s, 5))
> nonsmoke <- replicate(10000, sample(dat.ns, 5))
> t.test(smoke, nonsmoke)$p.value
[1] 0
> t.test(smoke, nonsmoke)

	Welch Two Sample t-test

data:  smoke and nonsmoke
t = -76.547, df = 99094, p-value < 2.2e-16
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -8.807035 -8.367285
sample estimates:
mean of x mean of y 
 116.6537  125.2409 

> set.seed(1)
> set.seed(1)
> set.seed(1)
> set.seed(1)
> pval <- replicate(10000, {
+ smoke <- sample(dat.s, 5)
+ nonsmoke <- sample(dat.ns, 5)
+ t.test(smoke, nonsmoke)$pvalue
+ })
> pval
[[1]]
NULL

[[2]]
NULL

[[3]]
NULL

[[4]]
NULL

[[5]]
NULL

[[6]]
NULL

[[7]]
NULL

[[8]]
NULL

[[9]]
NULL

[[10]]
NULL

[[11]]
NULL

[[12]]
NULL

[[13]]
NULL

[[14]]
NULL

[[15]]
NULL

[[16]]
NULL

[[17]]
NULL

[[18]]
NULL

[[19]]
NULL

[[20]]
NULL

[[21]]
NULL

[[22]]
NULL

[[23]]
NULL

[[24]]
NULL

[[25]]
NULL

[[26]]
NULL

[[27]]
NULL

[[28]]
NULL

[[29]]
NULL

[[30]]
NULL

[[31]]
NULL

[[32]]
NULL

[[33]]
NULL

[[34]]
NULL

[[35]]
NULL

[[36]]
NULL

[[37]]
NULL

[[38]]
NULL

[[39]]
NULL

[[40]]
NULL

[[41]]
NULL

[[42]]
NULL

[[43]]
NULL

[[44]]
NULL

[[45]]
NULL

[[46]]
NULL

[[47]]
NULL

[[48]]
NULL

[[49]]
NULL

[[50]]
NULL

[[51]]
NULL

[[52]]
NULL

[[53]]
NULL

[[54]]
NULL

[[55]]
NULL

[[56]]
NULL

[[57]]
NULL

[[58]]
NULL

[[59]]
NULL

[[60]]
NULL

[[61]]
NULL

[[62]]
NULL

[[63]]
NULL

[[64]]
NULL

[[65]]
NULL

[[66]]
NULL

[[67]]
NULL

[[68]]
NULL

[[69]]
NULL

[[70]]
NULL

[[71]]
NULL

[[72]]
NULL

[[73]]
NULL

[[74]]
NULL

[[75]]
NULL

[[76]]
NULL

[[77]]
NULL

[[78]]
NULL

[[79]]
NULL

[[80]]
NULL

[[81]]
NULL

[[82]]
NULL

[[83]]
NULL

[[84]]
NULL

[[85]]
NULL

[[86]]
NULL

[[87]]
NULL

[[88]]
NULL

[[89]]
NULL

[[90]]
NULL

[[91]]
NULL

[[92]]
NULL

[[93]]
NULL

[[94]]
NULL

[[95]]
NULL

[[96]]
NULL

[[97]]
NULL

[[98]]
NULL

[[99]]
NULL

[[100]]
NULL

[[101]]
NULL

[[102]]
NULL

[[103]]
NULL

[[104]]
NULL

[[105]]
NULL

[[106]]
NULL

[[107]]
NULL

[[108]]
NULL

[[109]]
NULL

[[110]]
NULL

[[111]]
NULL

[[112]]
NULL

[[113]]
NULL

[[114]]
NULL

[[115]]
NULL

[[116]]
NULL

[[117]]
NULL

[[118]]
NULL

[[119]]
NULL

[[120]]
NULL

[[121]]
NULL

[[122]]
NULL

[[123]]
NULL

[[124]]
NULL

[[125]]
NULL

[[126]]
NULL

[[127]]
NULL

[[128]]
NULL

[[129]]
NULL

[[130]]
NULL

[[131]]
NULL

[[132]]
NULL

[[133]]
NULL

[[134]]
NULL

[[135]]
NULL

[[136]]
NULL

[[137]]
NULL

[[138]]
NULL

[[139]]
NULL

[[140]]
NULL

[[141]]
NULL

[[142]]
NULL

[[143]]
NULL

[[144]]
NULL

[[145]]
NULL

[[146]]
NULL

[[147]]
NULL

[[148]]
NULL

[[149]]
NULL

[[150]]
NULL

[[151]]
NULL

[[152]]
NULL

[[153]]
NULL

[[154]]
NULL

[[155]]
NULL

[[156]]
NULL

[[157]]
NULL

[[158]]
NULL

[[159]]
NULL

[[160]]
NULL

[[161]]
NULL

[[162]]
NULL

[[163]]
NULL

[[164]]
NULL

[[165]]
NULL

[[166]]
NULL

[[167]]
NULL

[[168]]
NULL

[[169]]
NULL

[[170]]
NULL

[[171]]
NULL

[[172]]
NULL

[[173]]
NULL

[[174]]
NULL

[[175]]
NULL

[[176]]
NULL

[[177]]
NULL

[[178]]
NULL

[[179]]
NULL

[[180]]
NULL

[[181]]
NULL

[[182]]
NULL

[[183]]
NULL

[[184]]
NULL

[[185]]
NULL

[[186]]
NULL

[[187]]
NULL

[[188]]
NULL

[[189]]
NULL

[[190]]
NULL

[[191]]
NULL

[[192]]
NULL

[[193]]
NULL

[[194]]
NULL

[[195]]
NULL

[[196]]
NULL

[[197]]
NULL

[[198]]
NULL

[[199]]
NULL

[[200]]
NULL

[[201]]
NULL

[[202]]
NULL

[[203]]
NULL

[[204]]
NULL

[[205]]
NULL

[[206]]
NULL

[[207]]
NULL

[[208]]
NULL

[[209]]
NULL

[[210]]
NULL

[[211]]
NULL

[[212]]
NULL

[[213]]
NULL

[[214]]
NULL

[[215]]
NULL

[[216]]
NULL

[[217]]
NULL

[[218]]
NULL

[[219]]
NULL

[[220]]
NULL

[[221]]
NULL

[[222]]
NULL

[[223]]
NULL

[[224]]
NULL

[[225]]
NULL

[[226]]
NULL

[[227]]
NULL

[[228]]
NULL

[[229]]
NULL

[[230]]
NULL

[[231]]
NULL

[[232]]
NULL

[[233]]
NULL

[[234]]
NULL

[[235]]
NULL

[[236]]
NULL

[[237]]
NULL

[[238]]
NULL

[[239]]
NULL

[[240]]
NULL

[[241]]
NULL

[[242]]
NULL

[[243]]
NULL

[[244]]
NULL

[[245]]
NULL

[[246]]
NULL

[[247]]
NULL

[[248]]
NULL

[[249]]
NULL

[[250]]
NULL

[[251]]
NULL

[[252]]
NULL

[[253]]
NULL

[[254]]
NULL

[[255]]
NULL

[[256]]
NULL

[[257]]
NULL

[[258]]
NULL

[[259]]
NULL

[[260]]
NULL

[[261]]
NULL

[[262]]
NULL

[[263]]
NULL

[[264]]
NULL

[[265]]
NULL

[[266]]
NULL

[[267]]
NULL

[[268]]
NULL

[[269]]
NULL

[[270]]
NULL

[[271]]
NULL

[[272]]
NULL

[[273]]
NULL

[[274]]
NULL

[[275]]
NULL

[[276]]
NULL

[[277]]
NULL

[[278]]
NULL

[[279]]
NULL

[[280]]
NULL

[[281]]
NULL

[[282]]
NULL

[[283]]
NULL

[[284]]
NULL

[[285]]
NULL

[[286]]
NULL

[[287]]
NULL

[[288]]
NULL

[[289]]
NULL

[[290]]
NULL

[[291]]
NULL

[[292]]
NULL

[[293]]
NULL

[[294]]
NULL

[[295]]
NULL

[[296]]
NULL

[[297]]
NULL

[[298]]
NULL

[[299]]
NULL

[[300]]
NULL

[[301]]
NULL

[[302]]
NULL

[[303]]
NULL

[[304]]
NULL

[[305]]
NULL

[[306]]
NULL

[[307]]
NULL

[[308]]
NULL

[[309]]
NULL

[[310]]
NULL

[[311]]
NULL

[[312]]
NULL

[[313]]
NULL

[[314]]
NULL

[[315]]
NULL

[[316]]
NULL

[[317]]
NULL

[[318]]
NULL

[[319]]
NULL

[[320]]
NULL

[[321]]
NULL

[[322]]
NULL

[[323]]
NULL

[[324]]
NULL

[[325]]
NULL

[[326]]
NULL

[[327]]
NULL

[[328]]
NULL

[[329]]
NULL

[[330]]
NULL

[[331]]
NULL

[[332]]
NULL

[[333]]
NULL

[[334]]
NULL

[[335]]
NULL

[[336]]
NULL

[[337]]
NULL

[[338]]
NULL

[[339]]
NULL

[[340]]
NULL

[[341]]
NULL

[[342]]
NULL

[[343]]
NULL

[[344]]
NULL

[[345]]
NULL

[[346]]
NULL

[[347]]
NULL

[[348]]
NULL

[[349]]
NULL

[[350]]
NULL

[[351]]
NULL

[[352]]
NULL

[[353]]
NULL

[[354]]
NULL

[[355]]
NULL

[[356]]
NULL

[[357]]
NULL

[[358]]
NULL

[[359]]
NULL

[[360]]
NULL

[[361]]
NULL

[[362]]
NULL

[[363]]
NULL

[[364]]
NULL

[[365]]
NULL

[[366]]
NULL

[[367]]
NULL

[[368]]
NULL

[[369]]
NULL

[[370]]
NULL

[[371]]
NULL

[[372]]
NULL

[[373]]
NULL

[[374]]
NULL

[[375]]
NULL

[[376]]
NULL

[[377]]
NULL

[[378]]
NULL

[[379]]
NULL

[[380]]
NULL

[[381]]
NULL

[[382]]
NULL

[[383]]
NULL

[[384]]
NULL

[[385]]
NULL

[[386]]
NULL

[[387]]
NULL

[[388]]
NULL

[[389]]
NULL

[[390]]
NULL

[[391]]
NULL

[[392]]
NULL

[[393]]
NULL

[[394]]
NULL

[[395]]
NULL

[[396]]
NULL

[[397]]
NULL

[[398]]
NULL

[[399]]
NULL

[[400]]
NULL

[[401]]
NULL

[[402]]
NULL

[[403]]
NULL

[[404]]
NULL

[[405]]
NULL

[[406]]
NULL

[[407]]
NULL

[[408]]
NULL

[[409]]
NULL

[[410]]
NULL

[[411]]
NULL

[[412]]
NULL

[[413]]
NULL

[[414]]
NULL

[[415]]
NULL

[[416]]
NULL

[[417]]
NULL

[[418]]
NULL

[[419]]
NULL

[[420]]
NULL

[[421]]
NULL

[[422]]
NULL

[[423]]
NULL

[[424]]
NULL

[[425]]
NULL

[[426]]
NULL

[[427]]
NULL

[[428]]
NULL

[[429]]
NULL

[[430]]
NULL

[[431]]
NULL

[[432]]
NULL

[[433]]
NULL

[[434]]
NULL

[[435]]
NULL

[[436]]
NULL

[[437]]
NULL

[[438]]
NULL

[[439]]
NULL

[[440]]
NULL

[[441]]
NULL

[[442]]
NULL

[[443]]
NULL

[[444]]
NULL

[[445]]
NULL

[[446]]
NULL

[[447]]
NULL

[[448]]
NULL

[[449]]
NULL

[[450]]
NULL

[[451]]
NULL

[[452]]
NULL

[[453]]
NULL

[[454]]
NULL

[[455]]
NULL

[[456]]
NULL

[[457]]
NULL

[[458]]
NULL

[[459]]
NULL

[[460]]
NULL

[[461]]
NULL

[[462]]
NULL

[[463]]
NULL

[[464]]
NULL

[[465]]
NULL

[[466]]
NULL

[[467]]
NULL

[[468]]
NULL

[[469]]
NULL

[[470]]
NULL

[[471]]
NULL

[[472]]
NULL

[[473]]
NULL

[[474]]
NULL

[[475]]
NULL

[[476]]
NULL

[[477]]
NULL

[[478]]
NULL

[[479]]
NULL

[[480]]
NULL

[[481]]
NULL

[[482]]
NULL

[[483]]
NULL

[[484]]
NULL

[[485]]
NULL

[[486]]
NULL

[[487]]
NULL

[[488]]
NULL

[[489]]
NULL

[[490]]
NULL

[[491]]
NULL

[[492]]
NULL

[[493]]
NULL

[[494]]
NULL

[[495]]
NULL

[[496]]
NULL

[[497]]
NULL

[[498]]
NULL

[[499]]
NULL

[[500]]
NULL

[[501]]
NULL

[[502]]
NULL

[[503]]
NULL

[[504]]
NULL

[[505]]
NULL

[[506]]
NULL

[[507]]
NULL

[[508]]
NULL

[[509]]
NULL

[[510]]
NULL

[[511]]
NULL

[[512]]
NULL

[[513]]
NULL

[[514]]
NULL

[[515]]
NULL

[[516]]
NULL

[[517]]
NULL

[[518]]
NULL

[[519]]
NULL

[[520]]
NULL

[[521]]
NULL

[[522]]
NULL

[[523]]
NULL

[[524]]
NULL

[[525]]
NULL

[[526]]
NULL

[[527]]
NULL

[[528]]
NULL

[[529]]
NULL

[[530]]
NULL

[[531]]
NULL

[[532]]
NULL

[[533]]
NULL

[[534]]
NULL

[[535]]
NULL

[[536]]
NULL

[[537]]
NULL

[[538]]
NULL

[[539]]
NULL

[[540]]
NULL

[[541]]
NULL

[[542]]
NULL

[[543]]
NULL

[[544]]
NULL

[[545]]
NULL

[[546]]
NULL

[[547]]
NULL

[[548]]
NULL

[[549]]
NULL

[[550]]
NULL

[[551]]
NULL

[[552]]
NULL

[[553]]
NULL

[[554]]
NULL

[[555]]
NULL

[[556]]
NULL

[[557]]
NULL

[[558]]
NULL

[[559]]
NULL

[[560]]
NULL

[[561]]
NULL

[[562]]
NULL

[[563]]
NULL

[[564]]
NULL

[[565]]
NULL

[[566]]
NULL

[[567]]
NULL

[[568]]
NULL

[[569]]
NULL

[[570]]
NULL

[[571]]
NULL

[[572]]
NULL

[[573]]
NULL

[[574]]
NULL

[[575]]
NULL

[[576]]
NULL

[[577]]
NULL

[[578]]
NULL

[[579]]
NULL

[[580]]
NULL

[[581]]
NULL

[[582]]
NULL

[[583]]
NULL

[[584]]
NULL

[[585]]
NULL

[[586]]
NULL

[[587]]
NULL

[[588]]
NULL

[[589]]
NULL

[[590]]
NULL

[[591]]
NULL

[[592]]
NULL

[[593]]
NULL

[[594]]
NULL

[[595]]
NULL

[[596]]
NULL

[[597]]
NULL

[[598]]
NULL

[[599]]
NULL

[[600]]
NULL

[[601]]
NULL

[[602]]
NULL

[[603]]
NULL

[[604]]
NULL

[[605]]
NULL

[[606]]
NULL

[[607]]
NULL

[[608]]
NULL

[[609]]
NULL

[[610]]
NULL

[[611]]
NULL

[[612]]
NULL

[[613]]
NULL

[[614]]
NULL

[[615]]
NULL

[[616]]
NULL

[[617]]
NULL

[[618]]
NULL

[[619]]
NULL

[[620]]
NULL

[[621]]
NULL

[[622]]
NULL

[[623]]
NULL

[[624]]
NULL

[[625]]
NULL

[[626]]
NULL

[[627]]
NULL

[[628]]
NULL

[[629]]
NULL

[[630]]
NULL

[[631]]
NULL

[[632]]
NULL

[[633]]
NULL

[[634]]
NULL

[[635]]
NULL

[[636]]
NULL

[[637]]
NULL

[[638]]
NULL

[[639]]
NULL

[[640]]
NULL

[[641]]
NULL

[[642]]
NULL

[[643]]
NULL

[[644]]
NULL

[[645]]
NULL

[[646]]
NULL

[[647]]
NULL

[[648]]
NULL

[[649]]
NULL

[[650]]
NULL

[[651]]
NULL

[[652]]
NULL

[[653]]
NULL

[[654]]
NULL

[[655]]
NULL

[[656]]
NULL

[[657]]
NULL

[[658]]
NULL

[[659]]
NULL

[[660]]
NULL

[[661]]
NULL

[[662]]
NULL

[[663]]
NULL

[[664]]
NULL

[[665]]
NULL

[[666]]
NULL

[[667]]
NULL

[[668]]
NULL

[[669]]
NULL

[[670]]
NULL

[[671]]
NULL

[[672]]
NULL

[[673]]
NULL

[[674]]
NULL

[[675]]
NULL

[[676]]
NULL

[[677]]
NULL

[[678]]
NULL

[[679]]
NULL

[[680]]
NULL

[[681]]
NULL

[[682]]
NULL

[[683]]
NULL

[[684]]
NULL

[[685]]
NULL

[[686]]
NULL

[[687]]
NULL

[[688]]
NULL

[[689]]
NULL

[[690]]
NULL

[[691]]
NULL

[[692]]
NULL

[[693]]
NULL

[[694]]
NULL

[[695]]
NULL

[[696]]
NULL

[[697]]
NULL

[[698]]
NULL

[[699]]
NULL

[[700]]
NULL

[[701]]
NULL

[[702]]
NULL

[[703]]
NULL

[[704]]
NULL

[[705]]
NULL

[[706]]
NULL

[[707]]
NULL

[[708]]
NULL

[[709]]
NULL

[[710]]
NULL

[[711]]
NULL

[[712]]
NULL

[[713]]
NULL

[[714]]
NULL

[[715]]
NULL

[[716]]
NULL

[[717]]
NULL

[[718]]
NULL

[[719]]
NULL

[[720]]
NULL

[[721]]
NULL

[[722]]
NULL

[[723]]
NULL

[[724]]
NULL

[[725]]
NULL

[[726]]
NULL

[[727]]
NULL

[[728]]
NULL

[[729]]
NULL

[[730]]
NULL

[[731]]
NULL

[[732]]
NULL

[[733]]
NULL

[[734]]
NULL

[[735]]
NULL

[[736]]
NULL

[[737]]
NULL

[[738]]
NULL

[[739]]
NULL

[[740]]
NULL

[[741]]
NULL

[[742]]
NULL

[[743]]
NULL

[[744]]
NULL

[[745]]
NULL

[[746]]
NULL

[[747]]
NULL

[[748]]
NULL

[[749]]
NULL

[[750]]
NULL

[[751]]
NULL

[[752]]
NULL

[[753]]
NULL

[[754]]
NULL

[[755]]
NULL

[[756]]
NULL

[[757]]
NULL

[[758]]
NULL

[[759]]
NULL

[[760]]
NULL

[[761]]
NULL

[[762]]
NULL

[[763]]
NULL

[[764]]
NULL

[[765]]
NULL

[[766]]
NULL

[[767]]
NULL

[[768]]
NULL

[[769]]
NULL

[[770]]
NULL

[[771]]
NULL

[[772]]
NULL

[[773]]
NULL

[[774]]
NULL

[[775]]
NULL

[[776]]
NULL

[[777]]
NULL

[[778]]
NULL

[[779]]
NULL

[[780]]
NULL

[[781]]
NULL

[[782]]
NULL

[[783]]
NULL

[[784]]
NULL

[[785]]
NULL

[[786]]
NULL

[[787]]
NULL

[[788]]
NULL

[[789]]
NULL

[[790]]
NULL

[[791]]
NULL

[[792]]
NULL

[[793]]
NULL

[[794]]
NULL

[[795]]
NULL

[[796]]
NULL

[[797]]
NULL

[[798]]
NULL

[[799]]
NULL

[[800]]
NULL

[[801]]
NULL

[[802]]
NULL

[[803]]
NULL

[[804]]
NULL

[[805]]
NULL

[[806]]
NULL

[[807]]
NULL

[[808]]
NULL

[[809]]
NULL

[[810]]
NULL

[[811]]
NULL

[[812]]
NULL

[[813]]
NULL

[[814]]
NULL

[[815]]
NULL

[[816]]
NULL

[[817]]
NULL

[[818]]
NULL

[[819]]
NULL

[[820]]
NULL

[[821]]
NULL

[[822]]
NULL

[[823]]
NULL

[[824]]
NULL

[[825]]
NULL

[[826]]
NULL

[[827]]
NULL

[[828]]
NULL

[[829]]
NULL

[[830]]
NULL

[[831]]
NULL

[[832]]
NULL

[[833]]
NULL

[[834]]
NULL

[[835]]
NULL

[[836]]
NULL

[[837]]
NULL

[[838]]
NULL

[[839]]
NULL

[[840]]
NULL

[[841]]
NULL

[[842]]
NULL

[[843]]
NULL

[[844]]
NULL

[[845]]
NULL

[[846]]
NULL

[[847]]
NULL

[[848]]
NULL

[[849]]
NULL

[[850]]
NULL

[[851]]
NULL

[[852]]
NULL

[[853]]
NULL

[[854]]
NULL

[[855]]
NULL

[[856]]
NULL

[[857]]
NULL

[[858]]
NULL

[[859]]
NULL

[[860]]
NULL

[[861]]
NULL

[[862]]
NULL

[[863]]
NULL

[[864]]
NULL

[[865]]
NULL

[[866]]
NULL

[[867]]
NULL

[[868]]
NULL

[[869]]
NULL

[[870]]
NULL

[[871]]
NULL

[[872]]
NULL

[[873]]
NULL

[[874]]
NULL

[[875]]
NULL

[[876]]
NULL

[[877]]
NULL

[[878]]
NULL

[[879]]
NULL

[[880]]
NULL

[[881]]
NULL

[[882]]
NULL

[[883]]
NULL

[[884]]
NULL

[[885]]
NULL

[[886]]
NULL

[[887]]
NULL

[[888]]
NULL

[[889]]
NULL

[[890]]
NULL

[[891]]
NULL

[[892]]
NULL

[[893]]
NULL

[[894]]
NULL

[[895]]
NULL

[[896]]
NULL

[[897]]
NULL

[[898]]
NULL

[[899]]
NULL

[[900]]
NULL

[[901]]
NULL

[[902]]
NULL

[[903]]
NULL

[[904]]
NULL

[[905]]
NULL

[[906]]
NULL

[[907]]
NULL

[[908]]
NULL

[[909]]
NULL

[[910]]
NULL

[[911]]
NULL

[[912]]
NULL

[[913]]
NULL

[[914]]
NULL

[[915]]
NULL

[[916]]
NULL

[[917]]
NULL

[[918]]
NULL

[[919]]
NULL

[[920]]
NULL

[[921]]
NULL

[[922]]
NULL

[[923]]
NULL

[[924]]
NULL

[[925]]
NULL

[[926]]
NULL

[[927]]
NULL

[[928]]
NULL

[[929]]
NULL

[[930]]
NULL

[[931]]
NULL

[[932]]
NULL

[[933]]
NULL

[[934]]
NULL

[[935]]
NULL

[[936]]
NULL

[[937]]
NULL

[[938]]
NULL

[[939]]
NULL

[[940]]
NULL

[[941]]
NULL

[[942]]
NULL

[[943]]
NULL

[[944]]
NULL

[[945]]
NULL

[[946]]
NULL

[[947]]
NULL

[[948]]
NULL

[[949]]
NULL

[[950]]
NULL

[[951]]
NULL

[[952]]
NULL

[[953]]
NULL

[[954]]
NULL

[[955]]
NULL

[[956]]
NULL

[[957]]
NULL

[[958]]
NULL

[[959]]
NULL

[[960]]
NULL

[[961]]
NULL

[[962]]
NULL

[[963]]
NULL

[[964]]
NULL

[[965]]
NULL

[[966]]
NULL

[[967]]
NULL

[[968]]
NULL

[[969]]
NULL

[[970]]
NULL

[[971]]
NULL

[[972]]
NULL

[[973]]
NULL

[[974]]
NULL

[[975]]
NULL

[[976]]
NULL

[[977]]
NULL

[[978]]
NULL

[[979]]
NULL

[[980]]
NULL

[[981]]
NULL

[[982]]
NULL

[[983]]
NULL

[[984]]
NULL

[[985]]
NULL

[[986]]
NULL

[[987]]
NULL

[[988]]
NULL

[[989]]
NULL

[[990]]
NULL

[[991]]
NULL

[[992]]
NULL

[[993]]
NULL

[[994]]
NULL

[[995]]
NULL

[[996]]
NULL

[[997]]
NULL

[[998]]
NULL

[[999]]
NULL

[[1000]]
NULL

 [ reached 'max' / getOption("max.print") -- omitted 9000 entries ]
> set.seed(1)
> pval <- replicate(10000, {
+ smoke <- sample(dat.s, 5)
+ nonsmoke <- sample(dat.ns, 5)
+ t.test(smoke, nonsmoke)$pvalue %>% unlist()
+ })
> pval <- unlist(pval)
> mean(pval < 0.05)
[1] NaN
> set.seed(1)
> pval <- replicate(10000, {
+ smoke <- sample(dat.s, 5)
+ nonsmoke <- sample(dat.ns, 5)
+ t.test(smoke, nonsmoke)$pvalue %>% unlist()
+ })
> head(pval)
[[1]]
NULL

[[2]]
NULL

[[3]]
NULL

[[4]]
NULL

[[5]]
NULL

[[6]]
NULL

> set.seed(1)
> pval <- replicate(10000, {
+ smoke <- sample(dat.s, 5)
+ nonsmoke <- sample(dat.ns, 5)
+ t.test(smoke, nonsmoke)$pvalue
+ })
> head(pval)
[[1]]
NULL

[[2]]
NULL

[[3]]
NULL

[[4]]
NULL

[[5]]
NULL

[[6]]
NULL

> set.seed(1)
> set.seed(1)
> smoke <- sample(dat.s, 5)
> nonsmoke <- sample(dat.ns, 5)
> t.test(smoke, nonsmoke)$p.value
[1] 0.1916537
> set.seed(1)
> pval <- replicate(10000, {
+ smoke <- sample(dat.s, 5)
+ nonsmoke <- sample(dat.ns, 5)
+ t.test(smoke, nonsmoke)$p.value
+ })
> mean(pval < 0.05)
[1] 0.0677
> N <- 30
> set.seed(1)
> length(smoke)
[1] 5
> length(dat.s)
[1] 25
> N <- 30
> set.seed(1)
> pval <- replicate(10000, {
+ smoke <- sample(bwt.smoke, N)
+ nonsmoke <- sample(bwt.nonsmoke, N)
+ t.test(smoke, nonsmoke)$p.value
+ })
> mean(pval < 0.05)
[1] 0.481
> N <- 5
> set.seed(1)
> pval <- replicate(10000, {
+ smoke <- sample(bwt.smoke, N)
+ nonsmoke <- sample(bwt.nonsmoke, N)
+ t.test(smoke, nonsmoke)$p.value
+ })
> mean(pval < 0.05)
[1] 0.0977
> N <- 30
> set.seed(1)
> pval <- replicate(10000, {
+ smoke <- sample(bwt.smoke, N)
+ nonsmoke <- sample(bwt.nonsmoke, N)
+ t.test(smoke, nonsmoke)$p.value
+ })
> mean(pval < 0.05)
[1] 0.481
> N <- 60
> set.seed(1)
> pval <- replicate(10000, {
+ smoke <- sample(bwt.smoke, N)
+ nonsmoke <- sample(bwt.nonsmoke, N)
+ t.test(smoke, nonsmoke)$p.value
+ })
> mean(pval < 0.05)
[1] 0.7972
> N <- 90
> set.seed(1)
> pval <- replicate(10000, {
+ smoke <- sample(bwt.smoke, N)
+ nonsmoke <- sample(bwt.nonsmoke, N)
+ t.test(smoke, nonsmoke)$p.value
+ })
> mean(pval < 0.05)
[1] 0.937
> N <- 120
> set.seed(1)
> pval <- replicate(10000, {
+ smoke <- sample(bwt.smoke, N)
+ nonsmoke <- sample(bwt.nonsmoke, N)
+ t.test(smoke, nonsmoke)$p.value
+ })
> mean(pval < 0.05)
[1] 0.9844
> N <- 5
> alpha <- 0.01
> set.seed(1)
> pval <- replicate(10000, {
+ smoke <- sample(bwt.smoke, N)
+ nonsmoke <- sample(bwt.nonsmoke, N)
+ t.test(smoke, nonsmoke)$p.value
+ })
> mean(pval < alpha)
[1] 0.0197
> N <- 30
> alpha <- 0.01
> set.seed(1)
> pval <- replicate(10000, {
+ smoke <- sample(bwt.smoke, N)
+ nonsmoke <- sample(bwt.nonsmoke, N)
+ t.test(smoke, nonsmoke)$p.value
+ })
> mean(pval < alpha)
[1] 0.2424
> N <- 60
> alpha <- 0.01
> set.seed(1)
> pval <- replicate(10000, {
+ smoke <- sample(bwt.smoke, N)
+ nonsmoke <- sample(bwt.nonsmoke, N)
+ t.test(smoke, nonsmoke)$p.value
+ })
> mean(pval < alpha)
[1] 0.5628
> N <- 90
> alpha <- 0.01
> set.seed(1)
> pval <- replicate(10000, {
+ smoke <- sample(bwt.smoke, N)
+ nonsmoke <- sample(bwt.nonsmoke, N)
+ t.test(smoke, nonsmoke)$p.value
+ })
> mean(pval < alpha)
[1] 0.7975
> N <- 120
> alpha <- 0.01
> set.seed(1)
> pval <- replicate(10000, {
+ smoke <- sample(bwt.smoke, N)
+ nonsmoke <- sample(bwt.nonsmoke, N)
+ t.test(smoke, nonsmoke)$p.value
+ })
> mean(pval < alpha)
[1] 0.9257
> mean(pval < alpha)
[1] 0.9257
